{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78ad6e7",
   "metadata": {},
   "source": [
    "# SQL Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏôÄ ÏÉÅÌò∏ÏûëÏö©ÌïòÎäî ÏóêÏù¥Ï†ÑÌä∏\n",
    "\n",
    "Ïù¥ ÌäúÌÜ†Î¶¨ÏñºÏóêÏÑúÎäî **SQL Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê ÎåÄÌïú ÏßàÎ¨∏Ïóê ÎãµÌï† Ïàò ÏûàÎäî ÏóêÏù¥Ï†ÑÌä∏**Î•º Îã®Í≥ÑÎ≥ÑÎ°ú Íµ¨Ï∂ïÌïòÎäî Î∞©Î≤ïÏùÑ ÏÜåÍ∞úÌï©ÎãàÎã§.  \n",
    "\n",
    "SQL ÏøºÎ¶¨Î•º Ïã§ÌñâÌïòÎäî ÏóêÏù¥Ï†ÑÌä∏Ïùò ÌùêÎ¶ÑÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§.\n",
    "\n",
    "1. **Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïä§ÌÇ§Îßà ÌååÏïÖ**: ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÌÖåÏù¥Î∏î Î™©Î°ùÏùÑ Í∞ÄÏ†∏ÏòµÎãàÎã§.\n",
    "2. **Í¥ÄÎ†® ÌÖåÏù¥Î∏î ÏÑ†ÌÉù**: ÏßàÎ¨∏Í≥º Ïó∞Í¥ÄÎêú ÌÖåÏù¥Î∏îÏùÑ ÏÑ†ÌÉùÌï©ÎãàÎã§.\n",
    "3. **DDL Ï°∞Ìöå**: ÏÑ†ÌÉùÎêú ÌÖåÏù¥Î∏îÏùò Ïä§ÌÇ§Îßà Ï†ïÏùò(DDL)Î•º Í∞ÄÏ†∏ÏòµÎãàÎã§.\n",
    "4. **ÏøºÎ¶¨ ÏÉùÏÑ±**: ÏßàÎ¨∏Í≥º DDL Ï†ïÎ≥¥Ïóê Í∏∞Î∞òÌïòÏó¨ SQL ÏøºÎ¶¨Î•º ÏûëÏÑ±Ìï©ÎãàÎã§.\n",
    "5. **ÏøºÎ¶¨ Ï†êÍ≤Ä**: LLMÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏùºÎ∞òÏ†ÅÏù∏ Ïò§Î•òÎ•º Í≤ÄÌÜ†ÌïòÍ≥† ÏøºÎ¶¨Î•º Í∞úÏÑ†Ìï©ÎãàÎã§.\n",
    "6. **ÏøºÎ¶¨ Ïã§Ìñâ Î∞è Ïò§Î•ò Ï≤òÎ¶¨**: Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏóîÏßÑÏóê ÏøºÎ¶¨Î•º Ïã§ÌñâÌïòÍ≥†, Ïò§Î•ò Î∞úÏÉù Ïãú ÏàòÏ†ïÌïòÏó¨ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏøºÎ¶¨Î•º ÏàòÌñâÌï©ÎãàÎã§.\n",
    "7. **ÏùëÎãµ ÏÉùÏÑ±**: ÏøºÎ¶¨ Í≤∞Í≥ºÎ•º Í∏∞Î∞òÏúºÎ°ú ÏµúÏ¢Ö ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§.\n",
    "\n",
    "![](./assets/langgraph-sql-agent.png)\n",
    "\n",
    "---\n",
    "\n",
    "**Ï£ºÏöî ÎÇ¥Ïö©**\n",
    "\n",
    "- **Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§**: SQLite Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÑ§Ï†ï Î∞è `chinook` ÏÉòÌîå Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Î°úÎìú  \n",
    "- **Ïú†Ìã∏Î¶¨Ìã∞ Ìï®Ïàò**: ÏóêÏù¥Ï†ÑÌä∏ Íµ¨ÌòÑÏùÑ ÏúÑÌïú Ïú†Ìã∏Î¶¨Ìã∞ Ìï®Ïàò Ï†ïÏùò  \n",
    "- **ÎèÑÍµ¨ Ï†ïÏùò**: Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏôÄ ÏÉÅÌò∏ÏûëÏö©ÌïòÍ∏∞ ÏúÑÌïú ÎèÑÍµ¨ Ï†ïÏùò  \n",
    "- **ÏõåÌÅ¨ÌîåÎ°úÏö∞ Ï†ïÏùò**: ÏóêÏù¥Ï†ÑÌä∏Ïùò ÏõåÌÅ¨ÌîåÎ°úÏö∞(Í∑∏ÎûòÌîÑ) Ï†ïÏùò  \n",
    "- **Í∑∏ÎûòÌîÑ ÏãúÍ∞ÅÌôî**: Ï†ïÏùòÎêú Í∑∏ÎûòÌîÑ ÏãúÍ∞ÅÌôî  \n",
    "- **ÏóêÏù¥Ï†ÑÌä∏ Ïã§Ìñâ**: ÏóêÏù¥Ï†ÑÌä∏ Ïã§Ìñâ Î∞è Í≤∞Í≥º ÌôïÏù∏  \n",
    "- **ÌèâÍ∞Ä**: ÏóêÏù¥Ï†ÑÌä∏ ÌèâÍ∞Ä Î∞è ÏÑ±Îä• ÎπÑÍµê  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8000125",
   "metadata": {},
   "source": [
    "## ÌôòÍ≤Ω ÏÑ§Ï†ï\n",
    "\n",
    "Î®ºÏ†Ä, ÌïÑÏöîÌïú Ìå®ÌÇ§ÏßÄÎ•º ÏÑ§ÏπòÌïòÍ≥† API ÌÇ§Î•º ÏÑ§Ï†ïÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af24e6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API ÌÇ§Î•º ÌôòÍ≤ΩÎ≥ÄÏàòÎ°ú Í¥ÄÎ¶¨ÌïòÍ∏∞ ÏúÑÌïú ÏÑ§Ï†ï ÌååÏùº\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API ÌÇ§ Ï†ïÎ≥¥ Î°úÎìú\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a46d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏïàÎÖïÌïòÏÑ∏Ïöî! LangfuseÏûÖÎãàÎã§. Ïñ¥ÎñªÍ≤å ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?\n"
     ]
    }
   ],
   "source": [
    "from langfuse.openai import OpenAI  # OpenAI ÎåÄÏã† Ïù¥Í±∏ ÏÇ¨Ïö©\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "    base_url=os.environ.get(\"OPENROUTER_BASE_URL\"),  # ÏÇ¨ÎÇ¥ ÌîÑÎ°ùÏãú Ïì∞Î©¥ Ïó¨Í∏∞\n",
    ")\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"ÏïàÎÖï Langfuse\"}],\n",
    ")\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57903b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith Ï∂îÏ†ÅÏùÑ ÏãúÏûëÌï©ÎãàÎã§.\n",
      "[ÌîÑÎ°úÏ†ùÌä∏Î™Ö]\n",
      "LangGraph-Use-Cases\n"
     ]
    }
   ],
   "source": [
    "# LangSmith Ï∂îÏ†ÅÏùÑ ÏÑ§Ï†ïÌï©ÎãàÎã§.\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# ÌîÑÎ°úÏ†ùÌä∏ Ïù¥Î¶ÑÏùÑ ÏûÖÎ†•Ìï©ÎãàÎã§.\n",
    "logging.langsmith(\"LangGraph-Use-Cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3743ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏÇ¨Ïö©ÌïòÎäî Î™®Îç∏Î™Ö: qwen/qwen3-next-80b-a3b-instruct\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "MODEL_NAME = \"qwen/qwen3-next-80b-a3b-instruct\"\n",
    "# MODEL_NAME = get_model_name(LLMs.GPT4o)\n",
    "print(f\"ÏÇ¨Ïö©ÌïòÎäî Î™®Îç∏Î™Ö: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22810c3",
   "metadata": {},
   "source": [
    "## Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÑ§Ï†ï\n",
    "\n",
    "Ïù¥ ÌäúÌÜ†Î¶¨ÏñºÏóêÏÑúÎäî SQLite Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§. SQLiteÎäî ÏÑ§Ï†ïÍ≥º ÏÇ¨Ïö©Ïù¥ Í∞ÑÌé∏Ìïú Í≤ΩÎüâ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏûÖÎãàÎã§. \n",
    "\n",
    "Ïù¥Î≤à ÌäúÌÜ†Î¶¨ÏñºÏóêÏÑúÎäî ÏÉòÌîå Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïù∏ `chinook` Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î•º Î°úÎìúÌï† ÏòàÏ†ïÏù¥Î©∞, Ïù¥Îäî ÎîîÏßÄÌÑ∏ ÎØ∏ÎîîÏñ¥ Ïä§ÌÜ†Ïñ¥Î•º ÎÇòÌÉÄÎÇ¥Îäî ÏÉòÌîå Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏûÖÎãàÎã§. \n",
    "\n",
    "Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê ÎåÄÌïú ÏûêÏÑ∏Ìïú Ï†ïÎ≥¥Îäî [Ïó¨Í∏∞](https://www.sqlitetutorial.net/sqlite-sample-database/)ÏóêÏÑú ÌôïÏù∏Ìï† Ïàò ÏûàÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea4a58",
   "metadata": {},
   "source": [
    "Î®ºÏ†Ä, Ïã§ÏäµÏóê ÌôúÏö©Ìï† `chinook` Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î•º Îã§Ïö¥Î°úÎìú Î∞õÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fc78225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as Chinook.db\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"Chinook.db\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"File downloaded and saved as Chinook.db\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e66ea",
   "metadata": {},
   "source": [
    "Îã§ÏùåÏùÄ Îã§Ïö¥Î°úÎìú Î∞õÏùÄ `chinook` Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î•º ÏÇ¨Ïö©ÌïòÏó¨ `SQLDatabase` ÎèÑÍµ¨Î•º ÏÉùÏÑ±ÌïòÍ≥† ÏÉòÌîå ÏøºÎ¶¨Ïù∏ `\"SELECT * FROM Artist LIMIT 5;\"`Î•º Ïã§ÌñâÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ea943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains')]\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# SQLite Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌååÏùºÏóêÏÑú SQLDatabase Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "\n",
    "# DB dialect Ï∂úÎ†•(sqlite)\n",
    "print(db.dialect)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÌÖåÏù¥Î∏î Ïù¥Î¶Ñ Î™©Î°ù Ï∂úÎ†•\n",
    "print(db.get_usable_table_names())\n",
    "\n",
    "# SQL ÏøºÎ¶¨ Ïã§Ìñâ\n",
    "db.run(\"SELECT * FROM Artist LIMIT 5;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ea840",
   "metadata": {},
   "source": [
    "## Ïú†Ìã∏Î¶¨Ìã∞ Ìï®Ïàò\n",
    "\n",
    "ÏóêÏù¥Ï†ÑÌä∏ Íµ¨ÌòÑÏùÑ ÎèïÍ∏∞ ÏúÑÌï¥ Î™á Í∞ÄÏßÄ Ïú†Ìã∏Î¶¨Ìã∞ Ìï®ÏàòÎ•º Ï†ïÏùòÌï©ÎãàÎã§. \n",
    "\n",
    "ÌäπÌûà, `ToolNode`Î•º **Ïò§Î•ò Ï≤òÎ¶¨** ÏôÄ **ÏóêÏù¥Ï†ÑÌä∏Ïóê Ïò§Î•òÎ•º Ï†ÑÎã¨ÌïòÎäî Í∏∞Îä•** ÏùÑ Ìè¨Ìï®ÌïòÏó¨ ÎûòÌïëÌï©ÎãàÎã§. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnableWithFallbacks\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Ïò§Î•ò Ï≤òÎ¶¨ Ìï®Ïàò\n",
    "def handle_tool_error(state) -> dict:\n",
    "    # Ïò§Î•ò Ï†ïÎ≥¥ Ï°∞Ìöå\n",
    "    error = state.get(\"error\")\n",
    "    # ÎèÑÍµ¨ Ï†ïÎ≥¥ Ï°∞Ìöå\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    # ToolMessage Î°ú ÎûòÌïë ÌõÑ Î∞òÌôò\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Here is the error: {repr(error)}\\n\\nPlease fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# Ïò§Î•òÎ•º Ï≤òÎ¶¨ÌïòÍ≥† ÏóêÏù¥Ï†ÑÌä∏Ïóê Ïò§Î•òÎ•º Ï†ÑÎã¨ÌïòÍ∏∞ ÏúÑÌïú ToolNode ÏÉùÏÑ±\n",
    "def create_tool_node_with_fallback(tools: list) -> RunnableWithFallbacks[Any, dict]:\n",
    "    \"\"\"\n",
    "    Create a ToolNode with a fallback to handle errors and surface them to the agent.\n",
    "    \"\"\"\n",
    "    # Ïò§Î•ò Î∞úÏÉù Ïãú ÎåÄÏ≤¥ ÎèôÏûëÏùÑ Ï†ïÏùòÌïòÏó¨ ToolNodeÏóê Ï∂îÍ∞Ä\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7a514",
   "metadata": {},
   "source": [
    "## SQL ÏøºÎ¶¨ Ïã§Ìñâ ÎèÑÍµ¨ \n",
    "\n",
    "ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏôÄ ÏÉÅÌò∏ÏûëÏö©Ìï† Ïàò ÏûàÎèÑÎ°ù Î™á Í∞ÄÏßÄ ÎèÑÍµ¨Î•º Ï†ïÏùòÌï©ÎãàÎã§.\n",
    "\n",
    "1. `list_tables_tool`: Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÌÖåÏù¥Î∏îÏùÑ Í∞ÄÏ†∏ÏòµÎãàÎã§.\n",
    "2. `get_schema_tool`: ÌÖåÏù¥Î∏îÏùò DDLÏùÑ Í∞ÄÏ†∏ÏòµÎãàÎã§.\n",
    "3. `db_query_tool`: ÏøºÎ¶¨Î•º Ïã§ÌñâÌïòÍ≥† Í≤∞Í≥ºÎ•º Í∞ÄÏ†∏Ïò§Í±∞ÎÇò ÏøºÎ¶¨Í∞Ä Ïã§Ìå®Ìï† Í≤ΩÏö∞ Ïò§Î•ò Î©îÏãúÏßÄÎ•º Î∞òÌôòÌï©ÎãàÎã§.\n",
    "\n",
    "**Ï∞∏Í≥†**\n",
    "\n",
    "- DDL(Îç∞Ïù¥ÌÑ∞ Ï†ïÏùò Ïñ∏Ïñ¥, **Data Definition Language**)ÏùÄ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïùò Íµ¨Ï°∞ÏôÄ Ïä§ÌÇ§ÎßàÎ•º Ï†ïÏùòÌïòÍ±∞ÎÇò ÏàòÏ†ïÌïòÎäî Îç∞ ÏÇ¨Ïö©ÎêòÎäî SQL Î™ÖÎ†πÏñ¥Îì§ÏùÑ ÏßÄÏπ≠Ìï©ÎãàÎã§. Ï£ºÎ°ú ÌÖåÏù¥Î∏î, Ïù∏Îç±Ïä§, Î∑∞, Ïä§ÌÇ§Îßà Îì±Ïùò Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Í∞ùÏ≤¥Î•º ÏÉùÏÑ±, ÏàòÏ†ï, ÏÇ≠Ï†úÌï† Îïå ÏÇ¨Ïö©Îê©ÎãàÎã§.\n",
    "\n",
    "Ï£ºÏöî DDL Î™ÖÎ†πÏñ¥\n",
    "\n",
    "- **`CREATE`**: Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Í∞ùÏ≤¥Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.\n",
    "  - Ïòà: `CREATE TABLE users (id INT, name VARCHAR(100));`\n",
    "- **`ALTER`**: Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Í∞ùÏ≤¥Î•º ÏàòÏ†ïÌï©ÎãàÎã§.\n",
    "  - Ïòà: `ALTER TABLE users ADD COLUMN email VARCHAR(100);`\n",
    "- **`DROP`**: Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Í∞ùÏ≤¥Î•º ÏÇ≠Ï†úÌï©ÎãàÎã§.\n",
    "  - Ïòà: `DROP TABLE users;`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be594e8c",
   "metadata": {},
   "source": [
    "### Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏøºÎ¶¨ Í¥ÄÎ†® ÎèÑÍµ¨\n",
    "\n",
    "Îã§ÏùåÏùÄ SQL databaseÏôÄ ÏÉÅÌò∏ÏûëÏö©ÌïòÍ∏∞ ÏúÑÌïú `SQLDatabaseToolkit` ÎèÑÍµ¨ Î™©Î°ùÏûÖÎãàÎã§.\n",
    "\n",
    "**QuerySQLDataBaseTool**\n",
    "\n",
    "- **Í∏∞Îä•**: SQL query Ïã§Ìñâ Î∞è Í≤∞Í≥º Î∞òÌôò\n",
    "- **Input**: Ï†ïÌôïÌïú SQL query\n",
    "- **Output**: Database Í≤∞Í≥º ÎòêÎäî error message\n",
    "- **Error Ï≤òÎ¶¨**:\n",
    "  - Query Ïò§Î•ò Î∞úÏÉù Ïãú Ïû¨ÏûëÏÑ± Î∞è Ïû¨ÏãúÎèÑ\n",
    "  - `Unknown column` Ïò§Î•ò Ïãú `sql_db_schema`Î°ú Ï†ïÌôïÌïú table fields ÌôïÏù∏\n",
    "\n",
    "**InfoSQLDatabaseTool**\n",
    "\n",
    "- **Í∏∞Îä•**: Table schema Î∞è sample data Ï°∞Ìöå\n",
    "- **Input**: ÏΩ§ÎßàÎ°ú Íµ¨Î∂ÑÎêú table Î™©Î°ù\n",
    "- **ÏÇ¨Ïö© ÏòàÏãú**: `table1, table2, table3`\n",
    "- **Ï£ºÏùòÏÇ¨Ìï≠**: `sql_db_list_tables`Î°ú table Ï°¥Ïû¨ Ïó¨Î∂Ä ÏÇ¨Ï†Ñ ÌôïÏù∏ ÌïÑÏöî\n",
    "\n",
    "**ListSQLDatabaseTool**\n",
    "\n",
    "- **Í∏∞Îä•**: Database ÎÇ¥ table Î™©Î°ù Ï°∞Ìöå\n",
    "\n",
    "**QuerySQLCheckerTool**\n",
    "\n",
    "- **Í∏∞Îä•**: Query Ïã§Ìñâ Ï†Ñ Ïú†Ìö®ÏÑ± Í≤ÄÏÇ¨\n",
    "- **Í≤ÄÏÇ¨ Ìï≠Î™©**:\n",
    "  - NULL Í∞íÍ≥º NOT IN ÏÇ¨Ïö©\n",
    "  - UNION vs UNION ALL Ï†ÅÏ†àÏÑ±\n",
    "  - BETWEEN Î≤îÏúÑ ÏÑ§Ï†ï\n",
    "  - Data type ÏùºÏπò Ïó¨Î∂Ä\n",
    "  - Identifier Ïù∏Ïö© Ï†ÅÏ†àÏÑ±\n",
    "  - Function argument Ïàò\n",
    "  - Data type casting\n",
    "  - Join column Ï†ïÌôïÏÑ±\n",
    "- **ÌäπÏßï**: GPT-4 model Í∏∞Î∞ò Í≤ÄÏ¶ù ÏàòÌñâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5816528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ÏïàÎÖïÌïòÏÑ∏Ïöî! üòä  \\nÏñ¥Îñ§ ÎèÑÏõÄÏù¥ ÌïÑÏöîÌïòÏã†Í∞ÄÏöî? ÏßàÎ¨∏Ïù¥ ÏûàÏúºÏã†Í∞ÄÏöî, ÏïÑÎãàÎ©¥ Í∑∏ÎÉ• Ïù∏ÏÇ¨ÎìúÎ¶¥Íπå ÌïòÏÖ®ÎÇòÏöî?  \\nÏñ∏Ï†úÎì†ÏßÄ ÎßêÌï¥Ï£ºÏÑ∏Ïöî!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 10, 'total_tokens': 56, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'qwen/qwen3-next-80b-a3b-instruct', 'system_fingerprint': '', 'id': 'gen-1763221434-yV3jUiUSMjzrk1nguMGT', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--d86babcf-2358-4f72-a5a6-3b2c7a4fe4c1-0', usage_metadata={'input_tokens': 10, 'output_tokens': 46, 'total_tokens': 56, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "llm=ChatOpenAI(model=MODEL_NAME, base_url= os.getenv(\"OPENROUTER_BASE_URL\"),api_key=os.getenv(\"OPENROUTER_API_KEY\"))\n",
    "llm.invoke(\"ÏïàÎÖï\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d301860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDatabaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x1798e2d50>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x1798e2d50>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x1798e2d50>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x1798e2d50>, llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x148921590>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x148921a90>, root_client=<openai.OpenAI object at 0x148931f40>, root_async_client=<openai.AsyncOpenAI object at 0x148932120>, model_name='qwen/qwen3-next-80b-a3b-instruct', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True), llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['dialect', 'query'], input_types={}, partial_variables={}, template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x148921590>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x148921a90>, root_client=<openai.OpenAI object at 0x148931f40>, root_async_client=<openai.AsyncOpenAI object at 0x148932120>, model_name='qwen/qwen3-next-80b-a3b-instruct', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True), output_parser=StrOutputParser(), llm_kwargs={}))]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# SQLDatabaseToolkit ÏÉùÏÑ±\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=ChatOpenAI(model=MODEL_NAME))\n",
    "\n",
    "# SQLDatabaseToolkitÏóêÏÑú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÎèÑÍµ¨ Î™©Î°ù\n",
    "tools = toolkit.get_tools()\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a0eeb",
   "metadata": {},
   "source": [
    "ÏïÑÎûòÎäî `list_tables_tool` Í≥º `get_schema_tool` Ïóê ÎåÄÌïú Ïã§Ìñâ ÏòàÏãúÏûÖÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb31d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "\n",
      "CREATE TABLE \"Artist\" (\n",
      "\t\"ArtistId\" INTEGER NOT NULL, \n",
      "\t\"Name\" NVARCHAR(120), \n",
      "\tPRIMARY KEY (\"ArtistId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Artist table:\n",
      "ArtistId\tName\n",
      "1\tAC/DC\n",
      "2\tAccept\n",
      "3\tAerosmith\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÌÖåÏù¥Î∏îÏùÑ ÎÇòÏó¥ÌïòÎäî ÎèÑÍµ¨ ÏÑ†ÌÉù\n",
    "list_tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\n",
    "\n",
    "# ÌäπÏ†ï ÌÖåÏù¥Î∏îÏùò DDLÏùÑ Í∞ÄÏ†∏Ïò§Îäî ÎèÑÍµ¨ ÏÑ†ÌÉù\n",
    "get_schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïùò Î™®Îì† ÌÖåÏù¥Î∏î Î™©Î°ù Ï∂úÎ†•\n",
    "print(list_tables_tool.invoke(\"\"))\n",
    "\n",
    "# Artist ÌÖåÏù¥Î∏îÏùò DDL Ï†ïÎ≥¥ Ï∂úÎ†•\n",
    "print(get_schema_tool.invoke(\"Artist\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7d7e2",
   "metadata": {},
   "source": [
    "Îã§ÏùåÏùÄ `db_query_tool` ÏùÑ Ï†ïÏùòÌï©ÎãàÎã§. \n",
    "\n",
    "`db_query_tool`Ïùò Í≤ΩÏö∞, Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê ÎåÄÌï¥ ÏøºÎ¶¨Î•º Ïã§ÌñâÌïòÍ≥† Í≤∞Í≥ºÎ•º Î∞òÌôòÌï©ÎãàÎã§.\n",
    "\n",
    "ÎßåÏïΩ, error Í∞Ä Î∞úÏÉùÌïòÎ©¥ Ïò§Î•ò Î©îÏãúÏßÄÎ•º Î∞òÌôòÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Query Ïã§Ìñâ ÎèÑÍµ¨\n",
    "@tool\n",
    "def db_query_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Run SQL queries against a database and return results\n",
    "    Returns an error message if the query is incorrect\n",
    "    If an error is returned, rewrite the query, check, and retry\n",
    "    \"\"\"\n",
    "    # ÏøºÎ¶¨ Ïã§Ìñâ\n",
    "    result = db.run_no_throw(query)\n",
    "\n",
    "    # Ïò§Î•ò: Í≤∞Í≥ºÍ∞Ä ÏóÜÏúºÎ©¥ Ïò§Î•ò Î©îÏãúÏßÄ Î∞òÌôò\n",
    "    if not result:\n",
    "        return \"Error: Query failed. Please rewrite your query and try again.\"\n",
    "    # Ï†ïÏÉÅ: ÏøºÎ¶¨ Ïã§Ìñâ Í≤∞Í≥º Î∞òÌôò\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c1cab",
   "metadata": {},
   "source": [
    "Ï†ïÏÉÅ Ïã§ÌñâÎêú Í≤ΩÏö∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e6af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Ant√¥nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\n"
     ]
    }
   ],
   "source": [
    "# Artist ÌÖåÏù¥Î∏îÏóêÏÑú ÏÉÅÏúÑ 10Í∞ú Ìñâ ÏÑ†ÌÉù Î∞è Ïã§Ìñâ Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(db_query_tool.invoke(\"SELECT * FROM Artist LIMIT 10;\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cd6fd1",
   "metadata": {},
   "source": [
    "Ïò§Î•òÍ∞Ä Î∞úÏÉùÌïú Í≤ΩÏö∞ ÏòàÏãú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769c8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (sqlite3.OperationalError) near \"10\": syntax error\n",
      "[SQL: SELECT * FROM Artist LIMITS 10;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "# Artist ÌÖåÏù¥Î∏îÏóêÏÑú ÏÉÅÏúÑ 10Í∞ú Ìñâ ÏÑ†ÌÉù Î∞è Ïã§Ìñâ Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(db_query_tool.invoke(\"SELECT * FROM Artist LIMITS 10;\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd597b",
   "metadata": {},
   "source": [
    "### SQL ÏøºÎ¶¨ Ï†êÍ≤Ä(SQL Query Checker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46308526",
   "metadata": {},
   "source": [
    "Îã§ÏùåÏùÄ, SQL ÏøºÎ¶¨ÏóêÏÑú ÏùºÎ∞òÏ†ÅÏù∏ Ïã§ÏàòÎ•º Ï†êÍ≤ÄÌïòÍ∏∞ ÏúÑÌï¥ LLMÏùÑ ÌôúÏö©Ìï† ÏòàÏ†ïÏûÖÎãàÎã§. \n",
    "\n",
    "Ïù¥Îäî ÏóÑÎ∞ÄÌûà ÎßêÌïòÎ©¥ ÎèÑÍµ¨Îäî ÏïÑÎãàÏßÄÎßå, Ïù¥ÌõÑ ÏõåÌÅ¨ÌîåÎ°úÏö∞Ïóê ÎÖ∏ÎìúÎ°ú Ï∂îÍ∞ÄÎê† Í≤ÉÏûÖÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f608b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# SQL ÏøºÎ¶¨Ïùò ÏùºÎ∞òÏ†ÅÏù∏ Ïã§ÏàòÎ•º Ï†êÍ≤ÄÌïòÍ∏∞ ÏúÑÌïú ÏãúÏä§ÌÖú Î©îÏãúÏßÄ Ï†ïÏùò\n",
    "query_check_system = \"\"\"You are a SQL expert with a strong attention to detail.\n",
    "Double check the SQLite query for common mistakes, including:\n",
    "- Using NOT IN with NULL values\n",
    "- Using UNION when UNION ALL should have been used\n",
    "- Using BETWEEN for exclusive ranges\n",
    "- Data type mismatch in predicates\n",
    "- Properly quoting identifiers\n",
    "- Using the correct number of arguments for functions\n",
    "- Casting to the correct data type\n",
    "- Using the proper columns for joins\n",
    "\n",
    "If there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\n",
    "\n",
    "You will call the appropriate tool to execute the query after running this check.\"\"\"\n",
    "\n",
    "# ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±\n",
    "query_check_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", query_check_system), (\"placeholder\", \"{messages}\")]\n",
    ")\n",
    "\n",
    "# Query Checker Ï≤¥Ïù∏ ÏÉùÏÑ±\n",
    "query_check = query_check_prompt | ChatOpenAI(\n",
    "    model=MODEL_NAME, temperature=0, base_url= os.getenv(\"OPENROUTER_BASE_URL\"),api_key=os.getenv(\"OPENROUTER_API_KEY\")\n",
    "# ).bind_tools([db_query_tool])\n",
    ").bind_tools([db_query_tool], tool_choice=\"db_query_tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd06a6a",
   "metadata": {},
   "source": [
    "ÏûòÎ™ªÎêú ÏøºÎ¶¨Î•º ÎÇ†Î†§ Ìò∏Ï∂úÌïòÏó¨ Í≤∞Í≥ºÍ∞Ä Ïûò ÏàòÏ†ïÎêòÏóàÎäîÏßÄ ÌôïÏù∏Ìï©ÎãàÎã§.\n",
    "\n",
    "**Ï∞∏Í≥†**\n",
    "\n",
    "- `LIMIT` ÎåÄÏã† `LIMITS` ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏøºÎ¶¨Î•º ÎÇ†Î†∏ÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2355b32f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_check' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÏøºÎ¶¨ Ï†êÍ≤Ä ÎÖ∏Îìú Ïã§Ìñâ\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response = \u001b[43mquery_check\u001b[49m.invoke(\n\u001b[32m      3\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [(\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSELECT * FROM Artist LIMITS 10;\u001b[39m\u001b[33m\"\u001b[39m)]}\n\u001b[32m      4\u001b[39m )\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# print(response.tool_calls)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.tool_calls[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'query_check' is not defined"
     ]
    }
   ],
   "source": [
    "# ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÏøºÎ¶¨ Ï†êÍ≤Ä ÎÖ∏Îìú Ïã§Ìñâ\n",
    "response = query_check.invoke(\n",
    "    {\"messages\": [(\"user\", \"SELECT * FROM Artist LIMITS 10;\")]}\n",
    ")\n",
    "# print(response.tool_calls)\n",
    "print(response.tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c8ce9",
   "metadata": {},
   "source": [
    "Í≤∞Í≥ºÎäî Ïûò ÏàòÏ†ïÎêòÏóàÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db713316",
   "metadata": {},
   "source": [
    "## Í∑∏ÎûòÌîÑ Ï†ïÏùò\n",
    "\n",
    "ÏóêÏù¥Ï†ÑÌä∏Ïùò ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Ï†ïÏùòÌï©ÎãàÎã§. \n",
    "\n",
    "ÏóêÏù¥Ï†ÑÌä∏Îäî Î®ºÏ†Ä `list_tables_tool`ÏùÑ Í∞ïÏ†úÎ°ú Ìò∏Ï∂úÌïòÏó¨ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÌÖåÏù¥Î∏îÏùÑ Í∞ÄÏ†∏Ïò® ÌõÑ, ÌäúÌÜ†Î¶¨Ïñº Ï¥àÎ∞òÏóê Ïñ∏Í∏âÎêú Îã®Í≥ÑÎ•º Îî∞Î¶ÖÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32474a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "# ÏóêÏù¥Ï†ÑÌä∏Ïùò ÏÉÅÌÉú Ï†ïÏùò\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "# ÏÉàÎ°úÏö¥ Í∑∏ÎûòÌîÑ Ï†ïÏùò\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "\n",
    "# Ï≤´ Î≤àÏß∏ ÎèÑÍµ¨ Ìò∏Ï∂úÏùÑ ÏúÑÌïú ÎÖ∏Îìú Ï∂îÍ∞Ä\n",
    "def first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"sql_db_list_tables\",\n",
    "                        \"args\": {},\n",
    "                        \"id\": \"initial_tool_call_abc123\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# ÏøºÎ¶¨Ïùò Ï†ïÌôïÏÑ±ÏùÑ Î™®Îç∏Î°ú Ï†êÍ≤ÄÌïòÍ∏∞ ÏúÑÌïú Ìï®Ïàò Ï†ïÏùò\n",
    "def model_check_query(state: State) -> dict[str, list[AIMessage]]:\n",
    "    \"\"\"\n",
    "    Use this tool to check that your query is correct before you run it\n",
    "    \"\"\"\n",
    "    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n",
    "\n",
    "\n",
    "# Ï≤´ Î≤àÏß∏ ÎèÑÍµ¨ Ìò∏Ï∂ú ÎÖ∏Îìú Ï∂îÍ∞Ä\n",
    "workflow.add_node(\"first_tool_call\", first_tool_call)\n",
    "\n",
    "# Ï≤´ Î≤àÏß∏ Îëê ÎèÑÍµ¨Î•º ÏúÑÌïú ÎÖ∏Îìú Ï∂îÍ∞Ä\n",
    "workflow.add_node(\n",
    "    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n",
    ")\n",
    "workflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n",
    "\n",
    "# ÏßàÎ¨∏Í≥º ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÌÖåÏù¥Î∏îÏùÑ Í∏∞Î∞òÏúºÎ°ú Í¥ÄÎ†® ÌÖåÏù¥Î∏îÏùÑ ÏÑ†ÌÉùÌïòÎäî Î™®Îç∏ ÎÖ∏Îìú Ï∂îÍ∞Ä\n",
    "model_get_schema = ChatOpenAI(model=MODEL_NAME, temperature=0,base_url= os.getenv(\"OPENROUTER_BASE_URL\"),api_key=os.getenv(\"OPENROUTER_API_KEY\")).bind_tools(\n",
    "    [get_schema_tool]\n",
    ")\n",
    "workflow.add_node(\n",
    "    \"model_get_schema\",\n",
    "    lambda state: {\n",
    "        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# ÏµúÏ¢Ö ÏÉÅÌÉúÎ•º ÎÇòÌÉÄÎÇ¥Îäî ÎèÑÍµ¨ ÏÑ§Î™Ö\n",
    "class SubmitFinalAnswer(BaseModel):\n",
    "    \"\"\"ÏøºÎ¶¨ Í≤∞Í≥ºÎ•º Í∏∞Î∞òÏúºÎ°ú ÏÇ¨Ïö©ÏûêÏóêÍ≤å ÏµúÏ¢Ö ÎãµÎ≥Ä Ï†úÏ∂ú\"\"\"\n",
    "\n",
    "    final_answer: str = Field(..., description=\"The final answer to the user\")\n",
    "\n",
    "\n",
    "# ÏßàÎ¨∏Í≥º Ïä§ÌÇ§ÎßàÎ•º Í∏∞Î∞òÏúºÎ°ú ÏøºÎ¶¨Î•º ÏÉùÏÑ±ÌïòÍ∏∞ ÏúÑÌïú Î™®Îç∏ ÎÖ∏Îìú Ï∂îÍ∞Ä\n",
    "QUERY_GEN_INSTRUCTION = \"\"\"You are a SQL expert with a strong attention to detail.\n",
    "\n",
    "You can define SQL queries, analyze queries results and interpretate query results to response an answer.\n",
    "\n",
    "Read the messages bellow and identify the user question, table schemas, query statement and query result, or error if they exist.\n",
    "\n",
    "1. If there's not any query result that make sense to answer the question, create a syntactically correct SQLite query to answer the user question. DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "2. If you create a query, response ONLY the query statement. For example, \"SELECT id, name FROM pets;\"\n",
    "\n",
    "3. If a query was already executed, but there was an error. Response with the same error message you found. For example: \"Error: Pets table doesn't exist\"\n",
    "\n",
    "4. If a query was already executed successfully interpretate the response and answer the question following this pattern: Answer: <<question answer>>. For example: \"Answer: There three cats registered as adopted\"\n",
    "\"\"\"\n",
    "\n",
    "query_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", QUERY_GEN_INSTRUCTION), (\"placeholder\", \"{messages}\")]\n",
    ")\n",
    "query_gen = query_gen_prompt | ChatOpenAI(model=MODEL_NAME, temperature=0,base_url= os.getenv(\"OPENROUTER_BASE_URL\"),api_key=os.getenv(\"OPENROUTER_API_KEY\")).bind_tools(\n",
    "    [SubmitFinalAnswer, model_check_query]\n",
    ")\n",
    "\n",
    "\n",
    "# Ï°∞Í±¥Î∂Ä ÏóêÏßÄ Ï†ïÏùò\n",
    "def should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    last_message = messages[-1]\n",
    "    if last_message.content.startswith(\"Answer:\"):\n",
    "        return END\n",
    "    if last_message.content.startswith(\"Error:\"):\n",
    "        return \"query_gen\"\n",
    "    else:\n",
    "        return \"correct_query\"\n",
    "\n",
    "\n",
    "# ÏøºÎ¶¨ ÏÉùÏÑ± ÎÖ∏Îìú Ï†ïÏùò\n",
    "def query_gen_node(state: State):\n",
    "    message = query_gen.invoke(state)\n",
    "\n",
    "    # LLMÏù¥ ÏûòÎ™ªÎêú ÎèÑÍµ¨Î•º Ìò∏Ï∂úÌï† Í≤ΩÏö∞ Ïò§Î•ò Î©îÏãúÏßÄÎ•º Î∞òÌôò\n",
    "    tool_messages = []\n",
    "    message.pretty_print()\n",
    "    if message.tool_calls:\n",
    "        for tc in message.tool_calls:\n",
    "            if tc[\"name\"] != \"SubmitFinalAnswer\":\n",
    "                tool_messages.append(\n",
    "                    ToolMessage(\n",
    "                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n",
    "                        tool_call_id=tc[\"id\"],\n",
    "                    )\n",
    "                )\n",
    "    else:\n",
    "        tool_messages = []\n",
    "    return {\"messages\": [message] + tool_messages}\n",
    "\n",
    "\n",
    "# ÏøºÎ¶¨ ÏÉùÏÑ± ÎÖ∏Îìú Ï∂îÍ∞Ä\n",
    "workflow.add_node(\"query_gen\", query_gen_node)\n",
    "\n",
    "# ÏøºÎ¶¨Î•º Ïã§ÌñâÌïòÍ∏∞ Ï†ÑÏóê Î™®Îç∏Î°ú Ï†êÍ≤ÄÌïòÎäî ÎÖ∏Îìú Ï∂îÍ∞Ä\n",
    "workflow.add_node(\"correct_query\", model_check_query)\n",
    "\n",
    "# ÏøºÎ¶¨Î•º Ïã§ÌñâÌïòÍ∏∞ ÏúÑÌïú ÎÖ∏Îìú Ï∂îÍ∞Ä\n",
    "workflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n",
    "\n",
    "# ÎÖ∏Îìú Í∞ÑÏùò Ïó£ÏßÄ ÏßÄÏ†ï\n",
    "workflow.add_edge(START, \"first_tool_call\")\n",
    "workflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\n",
    "workflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\n",
    "workflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\n",
    "workflow.add_edge(\"get_schema_tool\", \"query_gen\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"query_gen\",\n",
    "    should_continue,\n",
    ")\n",
    "workflow.add_edge(\"correct_query\", \"execute_query\")\n",
    "workflow.add_edge(\"execute_query\", \"query_gen\")\n",
    "\n",
    "# Ïã§Ìñâ Í∞ÄÎä•Ìïú ÏõåÌÅ¨ÌîåÎ°úÏö∞Î°ú Ïª¥ÌååÏùº\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7f2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app, xray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e48ae3",
   "metadata": {},
   "source": [
    "## Í∑∏ÎûòÌîÑ Ïã§Ìñâ\n",
    "\n",
    "ÏóêÏù¥Ï†ÑÌä∏Î•º Ïã§ÌñâÌïòÏó¨ SQL Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏôÄ ÏÉÅÌò∏ÏûëÏö©ÌïòÎäî Ï†ÑÏ≤¥ ÌîÑÎ°úÏÑ∏Ïä§Î•º ÏßÑÌñâÌï©ÎãàÎã§.\n",
    "\n",
    "ÏóêÏù¥Ï†ÑÌä∏Îäî ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏Ïóê Îî∞Îùº Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú Ï†ïÎ≥¥Î•º Í≤ÄÏÉâÌïòÍ≥†, ÏøºÎ¶¨Î•º ÏÉùÏÑ± Î∞è Ïã§ÌñâÌïòÏó¨ Í≤∞Í≥ºÎ•º Î∞òÌôòÌï©ÎãàÎã§. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca79a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph, stream_graph\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "\n",
    "def run_graph(\n",
    "    message: str, recursive_limit: int = 30, node_names=[], stream: bool = False\n",
    "):\n",
    "    # config ÏÑ§Ï†ï(Ïû¨Í∑Ä ÏµúÎåÄ ÌöüÏàò, thread_id)\n",
    "    config = RunnableConfig(\n",
    "        recursion_limit=recursive_limit, configurable={\"thread_id\": random_uuid()}\n",
    "    )\n",
    "\n",
    "    # ÏßàÎ¨∏ ÏûÖÎ†•\n",
    "    inputs = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        if stream:\n",
    "            # Í∑∏ÎûòÌîÑ Ïã§Ìñâ\n",
    "            stream_graph(app, inputs, config, node_names=node_names)\n",
    "        else:\n",
    "            invoke_graph(app, inputs, config, node_names=node_names)\n",
    "        output = app.get_state(config).values\n",
    "        return output\n",
    "    except GraphRecursionError as recursion_error:\n",
    "        print(f\"GraphRecursionError: {recursion_error}\")\n",
    "        output = app.get_state(config).values\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d2282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mfirst_tool_call\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (initial_tool_call_abc123)\n",
      " Call ID: initial_tool_call_abc123\n",
      "  Args:\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mlist_tables_tool\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mmodel_get_schema\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ï†ÄÎäî Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î•º ÌÉêÏÉâÌïòÍ≥† ÏøºÎ¶¨Ìï† Ïàò ÏûàÎäî AI Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏ÏûÖÎãàÎã§. ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÌÖåÏù¥Î∏îÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track. Ïñ¥Îñ§ Ï†ïÎ≥¥Î•º Ï∞æÍ≥† Í≥ÑÏã†Í∞ÄÏöî?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mget_schema_tool\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ï†ÄÎäî Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î•º ÌÉêÏÉâÌïòÍ≥† ÏøºÎ¶¨Ìï† Ïàò ÏûàÎäî AI Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏ÏûÖÎãàÎã§. ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÌÖåÏù¥Î∏îÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track. Ïñ¥Îñ§ Ï†ïÎ≥¥Î•º Ï∞æÍ≥† Í≥ÑÏã†Í∞ÄÏöî?\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mquery_gen\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ï†ÄÎäî Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î•º ÌÉêÏÉâÌïòÍ≥† ÏøºÎ¶¨Ìï† Ïàò ÏûàÎäî AI Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏ÏûÖÎãàÎã§. ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÌÖåÏù¥Î∏îÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track. Ïñ¥Îñ§ Ï†ïÎ≥¥Î•º Ï∞æÍ≥† Í≥ÑÏã†Í∞ÄÏöî?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mcorrect_query\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  db_query_tool (call_1bd60dd564b44d7d97d0a3)\n",
      " Call ID: call_1bd60dd564b44d7d97d0a3\n",
      "  Args:\n",
      "    query: SELECT name FROM Artist\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mexecute_query\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: db_query_tool\n",
      "\n",
      "[('AC/DC',), ('Accept',), ('Aerosmith',), ('Alanis Morissette',), ('Alice In Chains',), ('Ant√¥nio Carlos Jobim',), ('Apocalyptica',), ('Audioslave',), ('BackBeat',), ('Billy Cobham',), ('Black Label Society',), ('Black Sabbath',), ('Body Count',), ('Bruce Dickinson',), ('Buddy Guy',), ('Caetano Veloso',), ('Chico Buarque',), ('Chico Science & Na√ß√£o Zumbi',), ('Cidade Negra',), ('Cl√°udio Zoli',), ('Various Artists',), ('Led Zeppelin',), ('Frank Zappa & Captain Beefheart',), ('Marcos Valle',), ('Milton Nascimento & Bebeto',), ('Azymuth',), ('Gilberto Gil',), ('Jo√£o Gilberto',), ('Bebel Gilberto',), ('Jorge Vercilo',), ('Baby Consuelo',), ('Ney Matogrosso',), ('Luiz Melodia',), ('Nando Reis',), ('Pedro Lu√≠s & A Parede',), ('O Rappa',), ('Ed Motta',), ('Banda Black Rio',), ('Fernanda Porto',), ('Os Cariocas',), ('Elis Regina',), ('Milton Nascimento',), ('A Cor Do Som',), ('Kid Abelha',), ('Sandra De S√°',), ('Jorge Ben',), ('Hermeto Pascoal',), ('Bar√£o Vermelho',), ('Edson, DJ Marky & DJ Patife Featuring Fernanda Porto',), ('Metallica',), ('Queen',), ('Kiss',), ('Spyro Gyra',), ('Green Day',), ('David Coverdale',), ('Gonzaguinha',), ('Os Mutantes',), ('Deep Purple',), ('Santana',), ('Santana Feat. Dave Matthews',), ('Santana Feat. Everlast',), ('Santana Feat. Rob Thomas',), ('Santana Feat. Lauryn Hill & Cee-Lo',), ('Santana Feat. The Project G&B',), ('Santana Feat. Man√°',), ('Santana Feat. Eagle-Eye Cherry',), ('Santana Feat. Eric Clapton',), ('Miles Davis',), ('Gene Krupa',), ('Toquinho & Vin√≠cius',), ('Vin√≠cius De Moraes & Baden Powell',), ('Vin√≠cius De Moraes',), ('Vin√≠cius E Qurteto Em Cy',), ('Vin√≠cius E Odette Lara',), ('Vinicius, Toquinho & Quarteto Em Cy',), ('Creedence Clearwater Revival',), ('C√°ssia Eller',), ('Def Leppard',), ('Dennis Chambers',), ('Djavan',), ('Eric Clapton',), ('Faith No More',), ('Falamansa',), ('Foo Fighters',), ('Frank Sinatra',), ('Funk Como Le Gusta',), ('Godsmack',), (\"Guns N' Roses\",), ('Incognito',), ('Iron Maiden',), ('James Brown',), ('Jamiroquai',), ('JET',), ('Jimi Hendrix',), ('Joe Satriani',), ('Jota Quest',), ('Jo√£o Suplicy',), ('Judas Priest',), ('Legi√£o Urbana',), ('Lenny Kravitz',), ('Lulu Santos',), ('Marillion',), ('Marisa Monte',), ('Marvin Gaye',), ('Men At Work',), ('Mot√∂rhead',), ('Mot√∂rhead & Girlschool',), ('M√¥nica Marianno',), ('M√∂tley Cr√ºe',), ('Nirvana',), ('O Ter√ßo',), ('Olodum',), ('Os Paralamas Do Sucesso',), ('Ozzy Osbourne',), ('Page & Plant',), ('Passengers',), (\"Paul D'Ianno\",), ('Pearl Jam',), ('Peter Tosh',), ('Pink Floyd',), ('Planet Hemp',), ('R.E.M. Feat. Kate Pearson',), ('R.E.M. Feat. KRS-One',), ('R.E.M.',), ('Raimundos',), ('Raul Seixas',), ('Red Hot Chili Peppers',), ('Rush',), ('Simply Red',), ('Skank',), ('Smashing Pumpkins',), ('Soundgarden',), ('Stevie Ray Vaughan & Double Trouble',), ('Stone Temple Pilots',), ('System Of A Down',), ('Terry Bozzio, Tony Levin & Steve Stevens',), ('The Black Crowes',), ('The Clash',), ('The Cult',), ('The Doors',), ('The Police',), ('The Rolling Stones',), ('The Tea Party',), ('The Who',), ('Tim Maia',), ('Tit√£s',), ('Battlestar Galactica',), ('Heroes',), ('Lost',), ('U2',), ('UB40',), ('Van Halen',), ('Velvet Revolver',), ('Whitesnake',), ('Zeca Pagodinho',), ('The Office',), ('Dread Zeppelin',), ('Battlestar Galactica (Classic)',), ('Aquaman',), ('Christina Aguilera featuring BigElf',), (\"Aerosmith & Sierra Leone's Refugee Allstars\",), ('Los Lonely Boys',), ('Corinne Bailey Rae',), ('Dhani Harrison & Jakob Dylan',), ('Jackson Browne',), ('Avril Lavigne',), ('Big & Rich',), (\"Youssou N'Dour\",), ('Black Eyed Peas',), ('Jack Johnson',), ('Ben Harper',), ('Snow Patrol',), ('Matisyahu',), ('The Postal Service',), ('Jaguares',), ('The Flaming Lips',), (\"Jack's Mannequin & Mick Fleetwood\",), ('Regina Spektor',), ('Scorpions',), ('House Of Pain',), ('Xis',), ('Nega Gizza',), ('Gustavo & Andres Veiga & Salazar',), ('Rodox',), ('Charlie Brown Jr.',), ('Pedro Lu√≠s E A Parede',), ('Los Hermanos',), ('Mundo Livre S/A',), ('Otto',), ('Instituto',), ('Na√ß√£o Zumbi',), ('DJ Dolores & Orchestra Santa Massa',), ('Seu Jorge',), ('Sabotage E Instituto',), ('Stereo Maracana',), ('Cake',), ('Aisha Duo',), ('Habib Koit√© and Bamada',), ('Karsh Kale',), ('The Posies',), ('Luciana Souza/Romero Lubambo',), ('Aaron Goldberg',), ('Nicolaus Esterhazy Sinfonia',), ('Temple of the Dog',), ('Chris Cornell',), ('Alberto Turco & Nova Schola Gregoriana',), ('Richard Marlow & The Choir of Trinity College, Cambridge',), ('English Concert & Trevor Pinnock',), ('Anne-Sophie Mutter, Herbert Von Karajan & Wiener Philharmoniker',), ('Hilary Hahn, Jeffrey Kahane, Los Angeles Chamber Orchestra & Margaret Batjer',), ('Wilhelm Kempff',), ('Yo-Yo Ma',), ('Scholars Baroque Ensemble',), ('Academy of St. Martin in the Fields & Sir Neville Marriner',), ('Academy of St. Martin in the Fields Chamber Ensemble & Sir Neville Marriner',), ('Berliner Philharmoniker, Claudio Abbado & Sabine Meyer',), ('Royal Philharmonic Orchestra & Sir Thomas Beecham',), ('Orchestre R√©volutionnaire et Romantique & John Eliot Gardiner',), ('Britten Sinfonia, Ivor Bolton & Lesley Garrett',), ('Chicago Symphony Chorus, Chicago Symphony Orchestra & Sir Georg Solti',), ('Sir Georg Solti & Wiener Philharmoniker',), ('Academy of St. Martin in the Fields, John Birch, Sir Neville Marriner & Sylvia McNair',), ('London Symphony Orchestra & Sir Charles Mackerras',), ('Barry Wordsworth & BBC Concert Orchestra',), ('Herbert Von Karajan, Mirella Freni & Wiener Philharmoniker',), ('Eugene Ormandy',), ('Luciano Pavarotti',), ('Leonard Bernstein & New York Philharmonic',), ('Boston Symphony Orchestra & Seiji Ozawa',), ('Aaron Copland & London Symphony Orchestra',), ('Ton Koopman',), ('Sergei Prokofiev & Yuri Temirkanov',), ('Chicago Symphony Orchestra & Fritz Reiner',), ('Orchestra of The Age of Enlightenment',), ('Emanuel Ax, Eugene Ormandy & Philadelphia Orchestra',), ('James Levine',), ('Berliner Philharmoniker & Hans Rosbaud',), ('Maurizio Pollini',), ('Academy of St. Martin in the Fields, Sir Neville Marriner & William Bennett',), ('Gustav Mahler',), ('Felix Schmidt, London Symphony Orchestra & Rafael Fr√ºhbeck de Burgos',), ('Edo de Waart & San Francisco Symphony',), ('Antal Dor√°ti & London Symphony Orchestra',), ('Choir Of Westminster Abbey & Simon Preston',), ('Michael Tilson Thomas & San Francisco Symphony',), ('Chor der Wiener Staatsoper, Herbert Von Karajan & Wiener Philharmoniker',), (\"The King's Singers\",), ('Berliner Philharmoniker & Herbert Von Karajan',), ('Sir Georg Solti, Sumi Jo & Wiener Philharmoniker',), (\"Christopher O'Riley\",), ('Fretwork',), ('Amy Winehouse',), ('Calexico',), ('Otto Klemperer & Philharmonia Orchestra',), ('Yehudi Menuhin',), ('Philharmonia Orchestra & Sir Neville Marriner',), ('Academy of St. Martin in the Fields, Sir Neville Marriner & Thurston Dart',), ('Les Arts Florissants & William Christie',), ('The 12 Cellists of The Berlin Philharmonic',), ('Adrian Leaper & Doreen de Feis',), ('Roger Norrington, London Classical Players',), (\"Charles Dutoit & L'Orchestre Symphonique de Montr√©al\",), ('Equale Brass Ensemble, John Eliot Gardiner & Munich Monteverdi Orchestra and Choir',), (\"Kent Nagano and Orchestre de l'Op√©ra de Lyon\",), ('Julian Bream',), ('Martin Roscoe',), ('G√∂teborgs Symfoniker & Neeme J√§rvi',), ('Itzhak Perlman',), ('Michele Campanella',), ('Gerald Moore',), ('Mela Tenenbaum, Pro Musica Prague & Richard Kapp',), ('Emerson String Quartet',), ('C. Monteverdi, Nigel Rogers - Chiaroscuro; London Baroque; London Cornett & Sackbu',), ('Nash Ensemble',), ('Philip Glass Ensemble',)]\n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      " {\"query\": \"SELECT COUNT(*) FROM Artist\"}}\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mquery_gen\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      " {\"query\": \"SELECT COUNT(*) FROM Artist\"}}\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mcorrect_query\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  db_query_tool (call_7e1bd66550024eb6bf95c40a)\n",
      " Call ID: call_7e1bd66550024eb6bf95c40a\n",
      "  Args:\n",
      "    query: SELECT COUNT(*) FROM Artist\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mexecute_query\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: db_query_tool\n",
      "\n",
      "[(275,)]\n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: There are 275 artists registered in the database.\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mquery_gen\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: There are 275 artists registered in the database.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "output = run_graph(\n",
    "    # \"Customer Ïª¨Îüº ÏïåÎ†§Ï§ò\",\n",
    "    # \"Andrew Adam ÏßÅÏõêÏùò Ïù∏Ï†ÅÏ†ïÎ≥¥Î•º Î™®Îëê Ï°∞ÌöåÌï¥Ï§ò\",\n",
    "    \"ÎÑåÎàÑÍµ¨Ïïº?\",\n",
    "    stream=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d13fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mfirst_tool_call\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (initial_tool_call_abc123)\n",
      " Call ID: initial_tool_call_abc123\n",
      "  Args:\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mlist_tables_tool\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mmodel_get_schema\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_62a2f8d7f8f24ee7ba9a2f67)\n",
      " Call ID: call_62a2f8d7f8f24ee7ba9a2f67\n",
      "  Args:\n",
      "    table_names: Customer, Invoice\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mget_schema_tool\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE \"Customer\" (\n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"FirstName\" NVARCHAR(40) NOT NULL, \n",
      "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"Company\" NVARCHAR(80), \n",
      "\t\"Address\" NVARCHAR(70), \n",
      "\t\"City\" NVARCHAR(40), \n",
      "\t\"State\" NVARCHAR(40), \n",
      "\t\"Country\" NVARCHAR(40), \n",
      "\t\"PostalCode\" NVARCHAR(10), \n",
      "\t\"Phone\" NVARCHAR(24), \n",
      "\t\"Fax\" NVARCHAR(24), \n",
      "\t\"Email\" NVARCHAR(60) NOT NULL, \n",
      "\t\"SupportRepId\" INTEGER, \n",
      "\tPRIMARY KEY (\"CustomerId\"), \n",
      "\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Customer table:\n",
      "CustomerId\tFirstName\tLastName\tCompany\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\tSupportRepId\n",
      "1\tLu√≠s\tGon√ßalves\tEmbraer - Empresa Brasileira de Aeron√°utica S.A.\tAv. Brigadeiro Faria Lima, 2170\tS√£o Jos√© dos Campos\tSP\tBrazil\t12227-000\t+55 (12) 3923-5555\t+55 (12) 3923-5566\tluisg@embraer.com.br\t3\n",
      "2\tLeonie\tK√∂hler\tNone\tTheodor-Heuss-Stra√üe 34\tStuttgart\tNone\tGermany\t70174\t+49 0711 2842222\tNone\tleonekohler@surfeu.de\t5\n",
      "3\tFran√ßois\tTremblay\tNone\t1498 rue B√©langer\tMontr√©al\tQC\tCanada\tH2G 1A7\t+1 (514) 721-4711\tNone\tftremblay@gmail.com\t3\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE \"Invoice\" (\n",
      "\t\"InvoiceId\" INTEGER NOT NULL, \n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
      "\t\"BillingAddress\" NVARCHAR(70), \n",
      "\t\"BillingCity\" NVARCHAR(40), \n",
      "\t\"BillingState\" NVARCHAR(40), \n",
      "\t\"BillingCountry\" NVARCHAR(40), \n",
      "\t\"BillingPostalCode\" NVARCHAR(10), \n",
      "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
      "\tPRIMARY KEY (\"InvoiceId\"), \n",
      "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Invoice table:\n",
      "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
      "1\t2\t2009-01-01 00:00:00\tTheodor-Heuss-Stra√üe 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
      "2\t4\t2009-01-02 00:00:00\tUllev√•lsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
      "3\t8\t2009-01-03 00:00:00\tGr√©trystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
      "*/\n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_910e7ee41d684abe8bf95c)\n",
      " Call ID: call_910e7ee41d684abe8bf95c\n",
      "  Args:\n",
      "    state: {'messages': [{'role': 'user', 'content': '2009ÎÖÑÎèÑÏóê Ïñ¥Îäê Íµ≠Í∞ÄÏùò Í≥†Í∞ùÏù¥ Í∞ÄÏû• ÎßéÏù¥ ÏßÄÏ∂úÌñàÏùÑÍπåÏöî? Í∑∏Î¶¨Í≥† ÏñºÎßàÎ•º ÏßÄÏ∂úÌñàÏùÑÍπåÏöî? Ìï¥Îãπ Í≥†Í∞ùÏúºÎ°ú Ïó∞ÎèÑÎ≥Ñ ÏßÄÏ∂úÍ∏àÏï°ÏùÑ barchartÎ°ú Í∑∏Î†§Ï§ò'}]}\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mquery_gen\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_910e7ee41d684abe8bf95c)\n",
      " Call ID: call_910e7ee41d684abe8bf95c\n",
      "  Args:\n",
      "    state: {'messages': [{'role': 'user', 'content': '2009ÎÖÑÎèÑÏóê Ïñ¥Îäê Íµ≠Í∞ÄÏùò Í≥†Í∞ùÏù¥ Í∞ÄÏû• ÎßéÏù¥ ÏßÄÏ∂úÌñàÏùÑÍπåÏöî? Í∑∏Î¶¨Í≥† ÏñºÎßàÎ•º ÏßÄÏ∂úÌñàÏùÑÍπåÏöî? Ìï¥Îãπ Í≥†Í∞ùÏúºÎ°ú Ïó∞ÎèÑÎ≥Ñ ÏßÄÏ∂úÍ∏àÏï°ÏùÑ barchartÎ°ú Í∑∏Î†§Ï§ò'}]}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Error: The wrong tool was called: model_check_query. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT \n",
      "    c.Country,\n",
      "    SUM(i.Total) AS TotalSpent\n",
      "FROM \n",
      "    Customer c\n",
      "JOIN \n",
      "    Invoice i ON c.CustomerId = i.CustomerId\n",
      "WHERE \n",
      "    strftime('%Y', i.InvoiceDate) = '2009'\n",
      "GROUP BY \n",
      "    c.Country\n",
      "ORDER BY \n",
      "    TotalSpent DESC\n",
      "LIMIT 1;\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mquery_gen\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT \n",
      "    c.Country,\n",
      "    SUM(i.Total) AS TotalSpent\n",
      "FROM \n",
      "    Customer c\n",
      "JOIN \n",
      "    Invoice i ON c.CustomerId = i.CustomerId\n",
      "WHERE \n",
      "    strftime('%Y', i.InvoiceDate) = '2009'\n",
      "GROUP BY \n",
      "    c.Country\n",
      "ORDER BY \n",
      "    TotalSpent DESC\n",
      "LIMIT 1;\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mcorrect_query\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  db_query_tool (call_b7b03315a4844bd9acc8ff4d)\n",
      " Call ID: call_b7b03315a4844bd9acc8ff4d\n",
      "  Args:\n",
      "    query: SELECT \n",
      "    c.Country,\n",
      "    SUM(i.Total) AS TotalSpent\n",
      "FROM \n",
      "    Customer c\n",
      "JOIN \n",
      "    Invoice i ON c.CustomerId = i.CustomerId\n",
      "WHERE \n",
      "    strftime('%Y', i.InvoiceDate) = '2009'\n",
      "GROUP BY \n",
      "    c.Country\n",
      "ORDER BY \n",
      "    TotalSpent DESC\n",
      "LIMIT 1;\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mexecute_query\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: db_query_tool\n",
      "\n",
      "[('USA', 103.95)]\n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      " {\"query\": \"SELECT \\n    strftime('%Y', i.InvoiceDate) AS Year,\\n    SUM(i.Total) AS TotalSpent\\nFROM \\n    Customer c\\nJOIN \\n    Invoice i ON c.CustomerId = i.CustomerId\\nWHERE \\n    c.Country = 'USA'\\nGROUP BY \\n    Year\\nORDER BY \\n    Year;\"}}\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mquery_gen\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      " {\"query\": \"SELECT \\n    strftime('%Y', i.InvoiceDate) AS Year,\\n    SUM(i.Total) AS TotalSpent\\nFROM \\n    Customer c\\nJOIN \\n    Invoice i ON c.CustomerId = i.CustomerId\\nWHERE \\n    c.Country = 'USA'\\nGROUP BY \\n    Year\\nORDER BY \\n    Year;\"}}\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mcorrect_query\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  db_query_tool (call_1e4d934c588c4769b7b60d70)\n",
      " Call ID: call_1e4d934c588c4769b7b60d70\n",
      "  Args:\n",
      "    query: SELECT \n",
      "    strftime('%Y', i.InvoiceDate) AS Year,\n",
      "    SUM(i.Total) AS TotalSpent\n",
      "FROM \n",
      "    Customer c\n",
      "JOIN \n",
      "    Invoice i ON c.CustomerId = i.CustomerId\n",
      "WHERE \n",
      "    c.Country = 'USA'\n",
      "GROUP BY \n",
      "    Year\n",
      "ORDER BY \n",
      "    Year;\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mexecute_query\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: db_query_tool\n",
      "\n",
      "[('2009', 103.95), ('2010', 102.98), ('2011', 103.01), ('2012', 127.98), ('2013', 85.14)]\n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: 2009ÎÖÑÎèÑÏóê Í∞ÄÏû• ÎßéÏù¥ ÏßÄÏ∂úÌïú Íµ≠Í∞ÄÎäî ÎØ∏Íµ≠(USA)Ïù¥Î©∞, Ï¥ù 103.95Îã¨Îü¨Î•º ÏßÄÏ∂úÌñàÏäµÎãàÎã§. ÎØ∏Íµ≠ Í≥†Í∞ùÏùò Ïó∞ÎèÑÎ≥Ñ ÏßÄÏ∂úÍ∏àÏï°ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§: 2009ÎÖÑ(103.95Îã¨Îü¨), 2010ÎÖÑ(102.98Îã¨Îü¨), 2011ÎÖÑ(103.01Îã¨Îü¨), 2012ÎÖÑ(127.98Îã¨Îü¨), 2013ÎÖÑ(85.14Îã¨Îü¨). Ïù¥ Îç∞Ïù¥ÌÑ∞Î•º Î∞îÌÉïÏúºÎ°ú ÎßâÎåÄ Í∑∏ÎûòÌîÑÎ•º Í∑∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§.\n",
      "\n",
      "==================================================\n",
      "üîÑ Node: \u001b[1;36mquery_gen\u001b[0m üîÑ\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: 2009ÎÖÑÎèÑÏóê Í∞ÄÏû• ÎßéÏù¥ ÏßÄÏ∂úÌïú Íµ≠Í∞ÄÎäî ÎØ∏Íµ≠(USA)Ïù¥Î©∞, Ï¥ù 103.95Îã¨Îü¨Î•º ÏßÄÏ∂úÌñàÏäµÎãàÎã§. ÎØ∏Íµ≠ Í≥†Í∞ùÏùò Ïó∞ÎèÑÎ≥Ñ ÏßÄÏ∂úÍ∏àÏï°ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§: 2009ÎÖÑ(103.95Îã¨Îü¨), 2010ÎÖÑ(102.98Îã¨Îü¨), 2011ÎÖÑ(103.01Îã¨Îü¨), 2012ÎÖÑ(127.98Îã¨Îü¨), 2013ÎÖÑ(85.14Îã¨Îü¨). Ïù¥ Îç∞Ïù¥ÌÑ∞Î•º Î∞îÌÉïÏúºÎ°ú ÎßâÎåÄ Í∑∏ÎûòÌîÑÎ•º Í∑∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "output = run_graph(\n",
    "    \"2009ÎÖÑÎèÑÏóê Ïñ¥Îäê Íµ≠Í∞ÄÏùò Í≥†Í∞ùÏù¥ Í∞ÄÏû• ÎßéÏù¥ ÏßÄÏ∂úÌñàÏùÑÍπåÏöî? Í∑∏Î¶¨Í≥† ÏñºÎßàÎ•º ÏßÄÏ∂úÌñàÏùÑÍπåÏöî? Ìï¥Îãπ Í≥†Í∞ùÏúºÎ°ú Ïó∞ÎèÑÎ≥Ñ ÏßÄÏ∂úÍ∏àÏï°ÏùÑ barchartÎ°ú Í∑∏Î†§Ï§ò\",\n",
    "    # \"2009ÎÖÑÎèÑÏóê Ïñ¥Îäê Íµ≠Í∞ÄÏùò Í≥†Í∞ùÏù¥ Í∞ÄÏû• ÎßéÏù¥ ÏßÄÏ∂úÌñàÏùÑÍπåÏöî? Í∑∏Î¶¨Í≥† ÏñºÎßàÎ•º ÏßÄÏ∂úÌñàÏùÑÍπåÏöî? ÌïúÍ∏ÄÎ°ú ÎãµÎ≥ÄÌïòÏÑ∏Ïöî. \",\n",
    "    stream=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe744388",
   "metadata": {},
   "source": [
    "## LangSmith Evaluator Î•º ÌôúÏö©Ìïú SQL Agent ÌèâÍ∞Ä\n",
    "\n",
    "Ïù¥Ï†ú ÏÉùÏÑ±Ìïú Agent Ïùò SQL ÏøºÎ¶¨ ÏùëÎãµÏùÑ ÌèâÍ∞ÄÌï©ÎãàÎã§. ÏøºÎ¶¨ ÏùëÎãµÏùÑ ÌèâÍ∞ÄÌïòÍ∏∞ ÏúÑÌïú ÌèâÍ∞ÄÏö© Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.\n",
    "\n",
    "Îã§ÏùåÏúºÎ°úÎäî ÌèâÍ∞ÄÏûêÎ•º Ï†ïÏùòÌïòÍ≥† ÌèâÍ∞ÄÎ•º ÏßÑÌñâÌï©ÎãàÎã§.\n",
    "\n",
    "Ïù¥Îïå ÌôúÏö©ÌïòÎäî ÌèâÍ∞ÄÏûêÎäî LLM-as-judge Ïù¥Î©∞, ÏÇ¨Ïö©ÌïòÎäî ÌîÑÎ°¨ÌîÑÌä∏Îäî Í∏∞Î≥∏ hub ÏóêÏÑú Ï†úÍ≥µÌïòÎäî ÌîÑÎ°¨ÌîÑÌä∏Î•º ÌôúÏö©Ìï©ÎãàÎã§.\n",
    "\n",
    "Îã§Îßå, Î≥¥Îã§ Ï†ïÌôïÌïú ÌèâÍ∞ÄÎ•º ÏúÑÌï¥ÏÑú Í∞ÅÏûê ÌîÑÎ°¨ÌîÑÌä∏Î•º ÌäúÎãùÌïòÏó¨ ÏÇ¨Ïö©ÌïòÎäî Í≤ÉÏùÑ Í∂åÏû•Ìï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63565cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "# ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî\n",
    "client = Client()\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ± Î∞è ÏóÖÎ°úÎìú\n",
    "examples = [\n",
    "    (\n",
    "        \"Which country's customers spent the most? And how much did they spend?\",\n",
    "        \"The country whose customers spent the most is the USA, with a total spending of 523.06.\",\n",
    "    ),\n",
    "    (\n",
    "        \"What was the most purchased track of 2013?\",\n",
    "        \"The most purchased track of 2013 was Hot Girl.\",\n",
    "    ),\n",
    "    (\n",
    "        \"How many albums does the artist Led Zeppelin have?\",\n",
    "        \"Led Zeppelin has 14 albums\",\n",
    "    ),\n",
    "    (\n",
    "        \"What is the total price for the album ‚ÄúBig Ones‚Äù?\",\n",
    "        \"The total price for the album 'Big Ones' is 14.85\",\n",
    "    ),\n",
    "    (\n",
    "        \"Which sales agent made the most in sales in 2009?\",\n",
    "        \"Steve Johnson made the most sales in 2009\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "dataset_name = \"SQL Agent Response\"\n",
    "\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    inputs, outputs = zip(\n",
    "        *[({\"input\": text}, {\"output\": label}) for text, label in examples]\n",
    "    )\n",
    "    client.create_examples(inputs=inputs, outputs=outputs, dataset_id=dataset.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e01f99b",
   "metadata": {},
   "source": [
    "Îã§ÏùåÏúºÎ°úÎäî Ïö∞Î¶¨Í∞Ä ÎßåÎì† ÏóêÏù¥Ï†ÑÌä∏Ïùò SQL ÏøºÎ¶¨ ÏùëÎãµÏùÑ ÏòàÏ∏°ÌïòÍ∏∞ ÏúÑÌïú Ìï®ÏàòÎ•º Ï†ïÏùòÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏóêÏù¥Ï†ÑÌä∏Ïùò SQL ÏøºÎ¶¨ ÏùëÎãµÏùÑ ÏòàÏ∏°ÌïòÍ∏∞ ÏúÑÌïú Ìï®Ïàò Ï†ïÏùò\n",
    "def predict_sql_agent_answer(example: dict):\n",
    "    \"\"\"Use this for answer evaluation\"\"\"\n",
    "    config = RunnableConfig(configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "    inputs = {\n",
    "        \"messages\": [HumanMessage(content=example[\"input\"])],\n",
    "    }\n",
    "    # Í∑∏ÎûòÌîÑÎ•º Ïã§ÌñâÌïòÏó¨ Î©îÏãúÏßÄ Í≤∞Í≥º Ï°∞Ìöå\n",
    "    messages = app.invoke(inputs, config)\n",
    "    answer = messages[\"messages\"][-1].content\n",
    "    # Í≤∞Í≥º Î∞òÌôò\n",
    "    return {\"response\": answer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfecdfb1",
   "metadata": {},
   "source": [
    "SQL ÏøºÎ¶¨ ÏùëÎãµÏùÑ ÌèâÍ∞ÄÌïòÍ∏∞ ÏúÑÌïú ÌîÑÎ°¨ÌîÑÌä∏ÏôÄ ÌèâÍ∞ÄÏûê(LLM-as-judge) Î•º Ï†ïÏùòÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Grade prompt\n",
    "grade_prompt_answer_accuracy = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
    "\n",
    "\n",
    "# ÎãµÎ≥Ä ÌèâÍ∞ÄÏûê LLM-as-judge Ï†ïÏùò\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    # input: ÏßàÎ¨∏\n",
    "    input_question = example.inputs[\"input\"]\n",
    "    # output: Ï∞∏Ï°∞ ÎãµÎ≥Ä\n",
    "    reference = example.outputs[\"output\"]\n",
    "    # ÏòàÏ∏° ÎãµÎ≥Ä\n",
    "    prediction = run.outputs[\"response\"]\n",
    "\n",
    "    # LLM ÌèâÍ∞ÄÏûê Ï¥àÍ∏∞Ìôî\n",
    "    llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "\n",
    "    # ÌèâÍ∞ÄÏûê Ïã§Ìñâ\n",
    "    score = answer_grader.invoke(\n",
    "        {\n",
    "            \"question\": input_question,\n",
    "            \"correct_answer\": reference,\n",
    "            \"student_answer\": prediction,\n",
    "        }\n",
    "    )\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    # Ï†êÏàò Î∞òÌôò\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72159566",
   "metadata": {},
   "source": [
    "Ïù¥Ï†ú, ÌèâÍ∞ÄÎ•º ÏàòÌñâÌïòÍ≥† Í≤∞Í≥ºÎ•º ÌôïÏù∏Ìï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005efae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'sql-agent-eval-3766971d' at:\n",
      "https://smith.langchain.com/o/74a885b2-b5ec-4752-ae95-0c0894e0a2fd/datasets/8495175e-53f3-43bb-a289-b3c34f516517/compare?selectedSessions=5628e334-7081-466e-8b6e-d32a571df3e8\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8670626b0547688e34cc6e95d202a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_kFi71rHWuNLfjzJLWI3BpFTX)\n",
      " Call ID: call_kFi71rHWuNLfjzJLWI3BpFTX\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'How many albums does the artist Led Zeppelin have?', 'type': 'human'}, {'content': 'CREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/\\n\\n\\nCREATE TABLE \"Artist\" (\\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Artist table:\\nArtistId\\tName\\n1\\tAC/DC\\n2\\tAccept\\n3\\tAerosmith\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT COUNT(*) \n",
      "FROM Album \n",
      "JOIN Artist ON Album.ArtistId = Artist.ArtistId \n",
      "WHERE Artist.Name = 'Led Zeppelin';\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: Led Zeppelin has 14 albums.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_AOnag0GH30GeFIPS9srRNlsx)\n",
      " Call ID: call_AOnag0GH30GeFIPS9srRNlsx\n",
      "  Args:\n",
      "    state: {'messages': [{'content': \"Which country's customers spent the most? And how much did they spend?\", 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': 'CREATE TABLE \"Customer\" (\\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"FirstName\" NVARCHAR(40) NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"Company\" NVARCHAR(80), \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60) NOT NULL, \\n\\t\"SupportRepId\" INTEGER, \\n\\tPRIMARY KEY (\"CustomerId\"), \\n\\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Customer table:\\nCustomerId\\tFirstName\\tLastName\\tCompany\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\tSupportRepId\\n1\\tLu√≠s\\tGon√ßalves\\tEmbraer - Empresa Brasileira de Aeron√°utica S.A.\\tAv. Brigadeiro Faria Lima, 2170\\tS√£o Jos√© dos Campos\\tSP\\tBrazil\\t12227-000\\t+55 (12) 3923-5555\\t+55 (12) 3923-5566\\tluisg@embraer.com.br\\t3\\n2\\tLeonie\\tK√∂hler\\tNone\\tTheodor-Heuss-Stra√üe 34\\tStuttgart\\tNone\\tGermany\\t70174\\t+49 0711 2842222\\tNone\\tleonekohler@surfeu.de\\t5\\n3\\tFran√ßois\\tTremblay\\tNone\\t1498 rue B√©langer\\tMontr√©al\\tQC\\tCanada\\tH2G 1A7\\t+1 (514) 721-4711\\tNone\\tftremblay@gmail.com\\t3\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Stra√üe 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllev√•lsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGr√©trystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT c.Country, SUM(i.Total) AS TotalSpent\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY TotalSpent DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: The country's customers who spent the most are from the USA, with a total spending of 523.06.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_SSr5b4SSfThbzYTqrZW9hK64)\n",
      " Call ID: call_SSr5b4SSfThbzYTqrZW9hK64\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'Which sales agent made the most in sales in 2009?', 'type': 'human'}, {'content': 'Invoice, Employee', 'type': 'ai'}, {'content': 'CREATE TABLE \"Employee\" (\\n\\t\"EmployeeId\" INTEGER NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"FirstName\" NVARCHAR(20) NOT NULL, \\n\\t\"Title\" NVARCHAR(30), \\n\\t\"ReportsTo\" INTEGER, \\n\\t\"BirthDate\" DATETIME, \\n\\t\"HireDate\" DATETIME, \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60), \\n\\tPRIMARY KEY (\"EmployeeId\"), \\n\\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Employee table:\\nEmployeeId\\tLastName\\tFirstName\\tTitle\\tReportsTo\\tBirthDate\\tHireDate\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\n1\\tAdams\\tAndrew\\tGeneral Manager\\tNone\\t1962-02-18 00:00:00\\t2002-08-14 00:00:00\\t11120 Jasper Ave NW\\tEdmonton\\tAB\\tCanada\\tT5K 2N1\\t+1 (780) 428-9482\\t+1 (780) 428-3457\\tandrew@chinookcorp.com\\n2\\tEdwards\\tNancy\\tSales Manager\\t1\\t1958-12-08 00:00:00\\t2002-05-01 00:00:00\\t825 8 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 2T3\\t+1 (403) 262-3443\\t+1 (403) 262-3322\\tnancy@chinookcorp.com\\n3\\tPeacock\\tJane\\tSales Support Agent\\t2\\t1973-08-29 00:00:00\\t2002-04-01 00:00:00\\t1111 6 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 5M5\\t+1 (403) 262-3443\\t+1 (403) 262-6712\\tjane@chinookcorp.com\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Stra√üe 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllev√•lsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGr√©trystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/', 'type': 'ai'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\n",
      "FROM Employee e\n",
      "JOIN Customer c ON e.EmployeeId = c.SupportRepId\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "WHERE strftime('%Y', i.InvoiceDate) = '2009'\n",
      "GROUP BY e.EmployeeId\n",
      "ORDER BY TotalSales DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_SqcqIDGqkVEumI6GpiPqDVfW)\n",
      " Call ID: call_SqcqIDGqkVEumI6GpiPqDVfW\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'What was the most purchased track of 2013?', 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': 'CREATE TABLE \"InvoiceLine\" (\\n\\t\"InvoiceLineId\" INTEGER NOT NULL, \\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\t\"Quantity\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceLineId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\n)\\n\\n/*\\n3 rows from InvoiceLine table:\\nInvoiceLineId\\tInvoiceId\\tTrackId\\tUnitPrice\\tQuantity\\n1\\t1\\t2\\t0.99\\t1\\n2\\t1\\t4\\t0.99\\t1\\n3\\t2\\t6\\t0.99\\t1\\n*/\\n\\n\\nCREATE TABLE \"Track\" (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL, \\n\\t\"AlbumId\" INTEGER, \\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"GenreId\" INTEGER, \\n\\t\"Composer\" NVARCHAR(220), \\n\\t\"Milliseconds\" INTEGER NOT NULL, \\n\\t\"Bytes\" INTEGER, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"TrackId\"), \\n\\tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), \\n\\tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), \\n\\tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\\n)\\n\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tAlbumId\\tMediaTypeId\\tGenreId\\tComposer\\tMilliseconds\\tBytes\\tUnitPrice\\n1\\tFor Those About To Rock (We Salute You)\\t1\\t1\\t1\\tAngus Young, Malcolm Young, Brian Johnson\\t343719\\t11170334\\t0.99\\n2\\tBalls to the Wall\\t2\\t2\\t1\\tNone\\t342562\\t5510424\\t0.99\\n3\\tFast As a Shark\\t3\\t2\\t1\\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\\t230619\\t3990994\\t0.99\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT Track.Name, SUM(InvoiceLine.Quantity) AS TotalQuantity\n",
      "FROM InvoiceLine\n",
      "JOIN Track ON InvoiceLine.TrackId = Track.TrackId\n",
      "JOIN Invoice ON InvoiceLine.InvoiceId = Invoice.InvoiceId\n",
      "WHERE strftime('%Y', Invoice.InvoiceDate) = '2013'\n",
      "GROUP BY Track.Name\n",
      "ORDER BY TotalQuantity DESC\n",
      "LIMIT 1;\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 29248, Requested 769. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 116, in query_gen_node\n",
      "    message = query_gen.invoke(state)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3246, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 29248, Requested 769. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'query_gen' and id '8ef4bcd7-833b-0fdc-a08e-fbbec81b73b9'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run bddf907e-9bd2-4e76-8aa8-c7873c73ac9c: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_zQuFyATV6PWqrWfvKCJdtYOd)\n",
      " Call ID: call_zQuFyATV6PWqrWfvKCJdtYOd\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'What is the total price for the album ‚ÄúBig Ones‚Äù?', 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': 'CREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Stra√üe 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllev√•lsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGr√©trystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/\\n\\n\\nCREATE TABLE \"InvoiceLine\" (\\n\\t\"InvoiceLineId\" INTEGER NOT NULL, \\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\t\"Quantity\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceLineId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\n)\\n\\n/*\\n3 rows from InvoiceLine table:\\nInvoiceLineId\\tInvoiceId\\tTrackId\\tUnitPrice\\tQuantity\\n1\\t1\\t2\\t0.99\\t1\\n2\\t1\\t4\\t0.99\\t1\\n3\\t2\\t6\\t0.99\\t1\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT SUM(InvoiceLine.UnitPrice * InvoiceLine.Quantity) AS TotalPrice\n",
      "FROM Album\n",
      "JOIN Track ON Album.AlbumId = Track.AlbumId\n",
      "JOIN InvoiceLine ON Track.TrackId = InvoiceLine.TrackId\n",
      "WHERE Album.Title = 'Big Ones';\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 816. Please try again in 1.632s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 116, in query_gen_node\n",
      "    message = query_gen.invoke(state)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3246, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 816. Please try again in 1.632s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'query_gen' and id 'a238f910-9187-d7d0-8ffc-f5221d78ae58'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 546d8fef-63b9-4107-bfcc-108dd90caef0: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '306173af-1d6d-273e-d411-9a146836f76f'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run fea938bb-ab63-4b30-952e-b1cbe06cd6b4: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 48. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 48. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id 'd7325bc7-84f2-e74a-4da0-a2a39b6da7b4'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 85b08131-95b1-4d31-82c5-ca5a0a6594db: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id 'c2ae72c3-308c-0cda-b1b3-57bff89d7dd4'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 03c4222b-9f4a-4590-83a2-4158e19c0d8f: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 41. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 41. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '6c610192-30ce-3e68-c89e-297942c7ccfb'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 2b0ebee0-8092-471b-bd64-f4a94631b387: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_B34aZ7xNaDyfkqAv6JhBKlT6)\n",
      " Call ID: call_B34aZ7xNaDyfkqAv6JhBKlT6\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'What is the total price for the album ‚ÄúBig Ones‚Äù?', 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': 'CREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Stra√üe 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllev√•lsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGr√©trystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/\\n\\n\\nCREATE TABLE \"InvoiceLine\" (\\n\\t\"InvoiceLineId\" INTEGER NOT NULL, \\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\t\"Quantity\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceLineId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\n)\\n\\n/*\\n3 rows from InvoiceLine table:\\nInvoiceLineId\\tInvoiceId\\tTrackId\\tUnitPrice\\tQuantity\\n1\\t1\\t2\\t0.99\\t1\\n2\\t1\\t4\\t0.99\\t1\\n3\\t2\\t6\\t0.99\\t1\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT SUM(InvoiceLine.UnitPrice * InvoiceLine.Quantity) AS TotalPrice\n",
      "FROM Album\n",
      "JOIN Track ON Album.AlbumId = Track.AlbumId\n",
      "JOIN InvoiceLine ON Track.TrackId = InvoiceLine.TrackId\n",
      "WHERE Album.Title = 'Big Ones';\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 218. Please try again in 436ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 46, in model_check_query\n",
      "    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n",
      "                         ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3246, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 218. Please try again in 436ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'correct_query' and id 'ff24bcc6-2c21-1ce5-ec9d-b0618d8a3bda'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 922998f1-39b5-42e5-aa14-e970305fec0b: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '80e9002f-dca9-89e2-b44e-f80469ab3635'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 44c343fb-822d-4928-91f7-48e787d73f51: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 48. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 48. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '10626b35-1a76-a0d0-58b7-8cf4be266f06'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 8ef50427-d301-4cc5-b964-3807d54c6d36: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '546dd548-75af-9d80-5ba0-100003d7a06d'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run de4c2291-2e7b-404e-9b90-04aabe748155: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 41. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 41. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '537a2945-8e90-8221-a747-478f2c39bb63'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 6bdf6064-872b-410f-8579-bdba8020b679: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 44. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1923, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3085, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2674, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1213, in _generate\n",
      "    raise e\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1208, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-suC36uLpYlp38Dn0ySfZsGJE on tokens per min (TPM): Limit 30000, Used 30000, Requested 44. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id 'b8d5ad40-f02c-b0ef-8c90-cec4bae2785a'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 430cb219-ed22-4aa4-a2fa-c79423afb2c5: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1619, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"/Users/daehwankim/Documents/langgraph-tutorial-main/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_96710/3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# ÌèâÍ∞ÄÏö© Îç∞Ïù¥ÌÑ∞ÏÖã Ïù¥Î¶Ñ\n",
    "dataset_name = \"SQL Agent Response\"\n",
    "\n",
    "try:\n",
    "    # ÌèâÍ∞Ä ÏßÑÌñâ\n",
    "    experiment_results = evaluate(\n",
    "        predict_sql_agent_answer,  # ÌèâÍ∞ÄÏãú ÌôúÏö©Ìï† ÏòàÏ∏° Ìï®Ïàò\n",
    "        data=dataset_name,  # ÌèâÍ∞ÄÏö© Îç∞Ïù¥ÌÑ∞ÏÖã Ïù¥Î¶Ñ\n",
    "        evaluators=[answer_evaluator],  # ÌèâÍ∞ÄÏûê Î™©Î°ù\n",
    "        num_repetitions=3,  # Ïã§Ìóò Î∞òÎ≥µ ÌöüÏàò ÏÑ§Ï†ï\n",
    "        experiment_prefix=\"sql-agent-eval\",\n",
    "        metadata={\n",
    "            \"version\": \"chinook db, sql-agent-eval: gpt-4.1-mini\"\n",
    "        },  # Ïã§Ìóò Î©îÌÉÄÎç∞Ïù¥ÌÑ∞\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239741fd",
   "metadata": {},
   "source": [
    "ÌèâÍ∞Ä Í≤∞Í≥ºÎäî ÏÉùÏÑ±Îêú URL ÏóêÏÑú Í∞ÅÏûê ÌôïÏù∏Ìï† Ïàò ÏûàÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c9d2ff",
   "metadata": {},
   "source": [
    "![](./assets/langgraph-sql-agent-evaluation.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
