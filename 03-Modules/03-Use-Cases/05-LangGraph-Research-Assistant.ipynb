{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750a91b5",
   "metadata": {},
   "source": [
    "# STORM ê°œë…ì„ ë„ì…í•œ ì—°êµ¬ë¥¼ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì˜ ëª©ì ì€ LangGraphë¥¼ í™œìš©í•˜ì—¬ ì—°êµ¬ ìë™í™” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ì„œ ë‹¤ë£¹ë‹ˆë‹¤. \n",
    "\n",
    "ì—°êµ¬ëŠ” ì¢…ì¢… ë¶„ì„ê°€ì—ê²Œ ìœ„ì„ë˜ëŠ” ë…¸ë™ ì§‘ì•½ì ì¸ ì‘ì—…ì…ë‹ˆë‹¤. AIëŠ” ì´ëŸ¬í•œ ì—°êµ¬ ê³¼ì •ì„ ì§€ì›í•  ìˆ˜ ìˆëŠ” ìƒë‹¹í•œ ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ì‚¬ìš©ì ë§ì¶¤í˜• AI ê¸°ë°˜ ì—°êµ¬ ë° ë³´ê³ ì„œ ìƒì„± ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ê²½ëŸ‰ì˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì—¬ ì—°êµ¬ ê³¼ì •ì„ ë§ì¶¤í™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì—°êµ¬ ì£¼ì œë¥¼ ì œê³µí•˜ê³ , ì‹œìŠ¤í…œì€ ê° í•˜ìœ„ ì£¼ì œì— ì§‘ì¤‘í•˜ëŠ” AI ë¶„ì„ê°€ íŒ€ì„ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "\n",
    "ì´ ê³¼ì •ì—ì„œ `Human-in-the-loop`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°êµ¬ê°€ ì‹œì‘ë˜ê¸° ì „ì— í•˜ìœ„ ì£¼ì œë¥¼ ì„¸ë¶„í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "[STORM ë…¼ë¬¸](https://arxiv.org/abs/2402.14207)ì— ë”°ë¥´ë©´, **ìœ ì‚¬í•œ ì£¼ì œ ì¡°íšŒ**ì™€ **ë‹¤ì–‘í•œ ê´€ì ì˜ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜**ì„ í†µí•´ ì°¸ê³  ì¶œì²˜ ì‚¬ìš© ë¹ˆë„ì™€ ì •ë³´ ë°€ë„ë¥¼ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "**ì£¼ë¡œ ë‹¤ë£¨ëŠ” ë‚´ìš©**\n",
    "- **LangGraphì˜ ì£¼ìš” í…Œë§ˆ**: Memory, Human-in-the-loop, Controllability\n",
    "- **ì—°êµ¬ ìë™í™”ì˜ ëª©í‘œ**: ì‚¬ìš©ì ë§ì¶¤í˜• ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ êµ¬ì¶•\n",
    "- **ì†ŒìŠ¤ ì„ íƒ**: ì—°êµ¬ë¥¼ ìœ„í•œ ì…ë ¥ ì†ŒìŠ¤ ì„ íƒ\n",
    "- **ê³„íš**: ì£¼ì œ ì œê³µ ë° AI ë¶„ì„ê°€ íŒ€ ìƒì„±\n",
    "- **LLM í™œìš©**: ì „ë¬¸ê°€ AIì™€ì˜ ì‹¬ì¸µ ì¸í„°ë·°\n",
    "- **ì—°êµ¬ ê³¼ì •**: ë³‘ë ¬ë¡œ ì •ë³´ ìˆ˜ì§‘ ë° ì¸í„°ë·° ìˆ˜í–‰\n",
    "- **ì¶œë ¥ í˜•ì‹**: ìµœì¢… ë³´ê³ ì„œë¡œ í†µí•©ëœ í†µì°°ë ¥\n",
    "- **ì„¤ì •**: í™˜ê²½ ì„¤ì • ë° API í‚¤ ì„¤ì •\n",
    "- **ë¶„ì„ê°€ ìƒì„±**: Human-In-The-Loopë¥¼ í†µí•œ ë¶„ì„ê°€ ìƒì„± ë° ê²€í† \n",
    "- **ì¸í„°ë·° ìˆ˜í–‰**: ì§ˆë¬¸ ìƒì„± ë° ë‹µë³€ ìˆ˜ì§‘\n",
    "- **ë³‘ë ¬ ì¸í„°ë·°**: Map-Reduceë¥¼ í†µí•œ ì¸í„°ë·° ë³‘ë ¬í™”\n",
    "- **ìµœì¢… ë³´ê³ ì„œ ì‘ì„±**: ë³´ê³ ì„œì˜ ì„œë¡  ë° ê²°ë¡  ì‘ì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6339db37",
   "metadata": {},
   "source": [
    "ì´ë²ˆ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ë‹¤ìŒì˜ ì„¸ ê°€ì§€ í…Œë§ˆë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.\n",
    "\n",
    "- **Memory**\n",
    "- **Human-in-the-loop**\n",
    "- **Controllability**\n",
    "\n",
    "ì´ì œ ì´ëŸ¬í•œ ê°œë…ì„ ê²°í•©í•˜ì—¬ AIì˜ ê°€ì¥ ì¸ê¸° ìˆëŠ” ì‘ìš© ë¶„ì•¼ ì¤‘ í•˜ë‚˜ì¸ ì—°êµ¬ ìë™í™”ë¥¼ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤. \n",
    "\n",
    "ì—°êµ¬ëŠ” ì¢…ì¢… ë¶„ì„ê°€ì—ê²Œ ìœ„ì„ë˜ëŠ” ë…¸ë™ ì§‘ì•½ì ì¸ ì‘ì—…ì…ë‹ˆë‹¤. AIëŠ” ì´ëŸ¬í•œ ì—°êµ¬ ê³¼ì •ì„ ì§€ì›í•  ìˆ˜ ìˆëŠ” ìƒë‹¹í•œ ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì—°êµ¬ëŠ” ë§ì¶¤í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì›ì‹œ LLM ì¶œë ¥ì€ ì‹¤ì œ ì˜ì‚¬ ê²°ì • ì›Œí¬í”Œë¡œìš°ì— ì í•©í•˜ì§€ ì•Šì€ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë§ì¶¤í˜• AI ê¸°ë°˜ [ì—°êµ¬ ë° ë³´ê³ ì„œ ìƒì„±](https://jxnl.co/writing/2024/06/05/predictions-for-the-future-of-rag/#reports-over-rag) ì›Œí¬í”Œë¡œìš°ëŠ” ì´ë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ìœ ë§í•œ ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "![langgraph-storm-concept](./assets/langgraph-storm-concept.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5b8ea",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d41258fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dad8507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "LangGraph-Use-Cases\n"
     ]
    }
   ],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"LangGraph-Use-Cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "889da53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ìµœì‹  ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°\n",
    "GPT4o = \"gpt-4.1\"\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=GPT4o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017f222",
   "metadata": {},
   "source": [
    "## ë¶„ì„ê°€ ìƒì„±: Human-In-The-Loop\n",
    "\n",
    "- **ë¶„ì„ê°€ ìƒì„±**: `Human-In-The-Loop`ë¥¼ í™œìš©í•˜ì—¬ ë¶„ì„ê°€ë¥¼ ìƒì„±í•˜ê³  ê²€í† í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be7f039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "\n",
    "# ë¶„ì„ê°€ì˜ ì†ì„±ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤\n",
    "class Analyst(BaseModel):\n",
    "    # ì£¼ìš” ì†Œì† ì •ë³´\n",
    "    affiliation: str = Field(\n",
    "        description=\"Primary affiliation of the analyst.\",\n",
    "    )\n",
    "    # ì´ë¦„\n",
    "    name: str = Field(description=\"Name of the analyst.\")\n",
    "\n",
    "    # ì—­í• \n",
    "    role: str = Field(\n",
    "        description=\"Role of the analyst in the context of the topic.\",\n",
    "    )\n",
    "    # ì¤‘ì , ìš°ë ¤ ì‚¬í•­ ë° ë™ê¸°ì— ëŒ€í•œ ì„¤ëª…\n",
    "    description: str = Field(\n",
    "        description=\"Description of the analyst focus, concerns, and motives.\",\n",
    "    )\n",
    "\n",
    "    # ë¶„ì„ê°€ì˜ ì¸ì  ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜í•˜ëŠ” ì†ì„±\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "\n",
    "\n",
    "# ë¶„ì„ê°€ë“¤ì˜ ì§‘í•©\n",
    "class Perspectives(BaseModel):\n",
    "    # ë¶„ì„ê°€ ëª©ë¡\n",
    "    analysts: List[Analyst] = Field(\n",
    "        description=\"Comprehensive list of analysts with their roles and affiliations.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4845a360",
   "metadata": {},
   "source": [
    "ë‹¤ìŒì€ Analyst í´ë˜ìŠ¤ë¥¼ í†µí•´ ìƒì„±ëœ ë¶„ì„ê°€ë“¤ì˜ ì§‘í•©ì„ ì¶”ì í•˜ëŠ” ìƒíƒœë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dba2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœ ì •ì˜\n",
    "class GenerateAnalystsState(TypedDict):\n",
    "    # ì—°êµ¬ ì£¼ì œ\n",
    "    topic: str\n",
    "    # ìƒì„±í•  ë¶„ì„ê°€ì˜ ìµœëŒ€ ìˆ˜\n",
    "    max_analysts: int\n",
    "    # ì‚¬ëŒ í”¼ë“œë°±\n",
    "    human_analyst_feedback: str\n",
    "    # ë¶„ì„ê°€ ëª©ë¡\n",
    "    analysts: List[Analyst]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba448ac",
   "metadata": {},
   "source": [
    "## ë¶„ì„ê°€(Analyst) ìƒì„± ë…¸ë“œ ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd092f4",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œëŠ” ë¶„ì„ê°€(Analyst) ìƒì„± ë…¸ë“œë¥¼ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ì½”ë“œëŠ” ì£¼ì–´ì§„ ì—°êµ¬ ì£¼ì œì— ëŒ€í•´ ë‹¤ì–‘í•œ ë¶„ì„ê°€ë¥¼ ìƒì„±í•˜ëŠ” ë¡œì§ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ê° ë¶„ì„ê°€ëŠ” ê³ ìœ í•œ ì—­í• ê³¼ ì†Œì†ì„ ê°€ì§€ë©°, ì£¼ì œì— ëŒ€í•œ ì „ë¬¸ì ì¸ ê´€ì ì„ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cd7ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# ë¶„ì„ê°€ ìƒì„± í”„ë¡¬í”„íŠ¸\n",
    "analyst_instructions = \"\"\"You are tasked with creating a set of AI analyst personas.\n",
    "\n",
    "Follow these instructions carefully:\n",
    "1. First, review the research topic:\n",
    "\n",
    "{topic}\n",
    "\n",
    "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
    "\n",
    "{human_analyst_feedback}\n",
    "\n",
    "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
    "\n",
    "4. Pick the top {max_analysts} themes.\n",
    "\n",
    "5. Assign one analyst to each theme.\"\"\"\n",
    "\n",
    "\n",
    "# ë¶„ì„ê°€ ìƒì„± ë…¸ë“œ\n",
    "def create_analysts(state: GenerateAnalystsState):\n",
    "    \"\"\"ë¶„ì„ê°€ í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "\n",
    "    topic = state[\"topic\"]\n",
    "    max_analysts = state[\"max_analysts\"]\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", \"\")\n",
    "\n",
    "    # LLMì— êµ¬ì¡°í™”ëœ ì¶œë ¥ í˜•ì‹ì„ ì ìš©\n",
    "    structured_llm = llm.with_structured_output(Perspectives)\n",
    "\n",
    "    # ë¶„ì„ê°€ ìƒì„±ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "    system_message = analyst_instructions.format(\n",
    "        topic=topic,\n",
    "        human_analyst_feedback=human_analyst_feedback,\n",
    "        max_analysts=max_analysts,\n",
    "    )\n",
    "\n",
    "    # LLMì„ í˜¸ì¶œí•˜ì—¬ ë¶„ì„ê°€ í˜ë¥´ì†Œë‚˜ ìƒì„±\n",
    "    analysts = structured_llm.invoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [HumanMessage(content=\"Generate the set of analysts.\")]\n",
    "    )\n",
    "\n",
    "    # ìƒì„±ëœ ë¶„ì„ê°€ ëª©ë¡ì„ ìƒíƒœì— ì €ì¥\n",
    "    return {\"analysts\": analysts.analysts}\n",
    "\n",
    "\n",
    "# ì‚¬ìš©ì í”¼ë“œë°± ë…¸ë“œ(ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ì§„í–‰í•  ì˜ˆì •ì´ë¯€ë¡œ, ë‚´ìš©ì€ ë¹„ì›Œ ë‘ì–´ë„ ë¬´ë°©)\n",
    "def human_feedback(state: GenerateAnalystsState):\n",
    "    \"\"\"ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°›ê¸° ìœ„í•œ ì¤‘ë‹¨ì  ë…¸ë“œ\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# ì¸ê°„ í”¼ë“œë°± ì—¬ë¶€ì— ë”°ë¼ ì›Œí¬í”Œë¡œìš°ì˜ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜\n",
    "def should_continue(state: GenerateAnalystsState):\n",
    "    \"\"\"ì›Œí¬í”Œë¡œìš°ì˜ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", None)\n",
    "    if human_analyst_feedback:\n",
    "        return \"create_analysts\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22196430",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ ìƒì„±\n",
    "\n",
    "ì´ì œ ë¶„ì„ê°€ ìƒì„± ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f33720ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "builder = StateGraph(GenerateAnalystsState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "builder.add_node(\"create_analysts\", create_analysts)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²°\n",
    "builder.add_edge(START, \"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€: ì‚¬ëŒ í”¼ë“œë°±ì´ ìˆì„ ê²½ìš° ë‹¤ì‹œ ë¶„ì„ê°€ ìƒì„± ë…¸ë“œë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.\n",
    "builder.add_conditional_edges(\n",
    "    \"human_feedback\", should_continue, [\"create_analysts\", END]\n",
    ")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ìƒì„±\n",
    "memory = MemorySaver()\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼(ì¤‘ë‹¨ì  ì„¤ì •)\n",
    "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹œê°í™”\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b96538",
   "metadata": {},
   "source": [
    "## ë¶„ì„ê°€ ìƒì„±ì„ ìœ„í•œ ê·¸ë˜í”„ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06ddccc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mcreate_analysts\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "affiliation='AI Infrastructure Research Lab' name='Dr. Yuna Kim' role='Architectural Analyst' description='Dr. Kim focuses on the technical distinctions between Modular RAG and Naive RAG, analyzing how architectural changes lead to performance and scalability differences. Her main concern is how modularization impacts flexibility, maintainability, and integration with other production systems.'\n",
      "affiliation='Enterprise AI Solutions, Inc.' name='Eliot Park' role='Production Deployment Strategist' description='Eliot specializes in bringing AI models, especially Retrieval Augmented Generation systems, into production environments. His perspective centers around the operational and business advantages of Modular RAGâ€”such as reliability, efficiency, ease of scaling, and rapid adaptation to changing requirementsâ€”in comparison to Naive RAG.'\n",
      "affiliation='SecureTech Analytics' name='Ava Lee' role='Risk and Compliance Analyst' description='Ava evaluates the security, monitoring, and compliance implications of using Modular versus Naive RAG in enterprise settings. She is keenly interested in how modular design enables better auditability and risk management, critical for organizations with strict regulatory obligations.'\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36m__interrupt__\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph\n",
    "\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=10,\n",
    "    configurable={\"thread_id\": random_uuid()},\n",
    ")\n",
    "\n",
    "# ë¶„ì„ê°€ ìˆ˜ ì„¤ì •\n",
    "max_analysts = 3\n",
    "\n",
    "# ì—°êµ¬ ì£¼ì œ ì„¤ì •\n",
    "topic = \"Modular RAG ê°€ ê¸°ì¡´ì˜ Naive RAG ì™€ ì–´ë–¤ ì°¨ì´ê°€ ìˆëŠ”ì§€ì™€ production level ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì \"\n",
    "\n",
    "# ì…ë ¥ ë°ì´í„° ì„¤ì •\n",
    "inputs = {\n",
    "    \"topic\": topic,\n",
    "    \"max_analysts\": max_analysts,\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "invoke_graph(graph, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9c2b79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mcreate_analysts\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\"analysts\":[{\"affiliation\":\"Enterprise AI Consultant, DataEdge Solutions\",\"name\":\"Dr. Min-jun Park\",\"role\":\"Scalability & Architecture Specialist\",\"description\":\"Dr. Park examines the architectural distinctions between Modular RAG and Naive RAG, focusing on their respective approaches to retrieval granularity, modularity, and extensibility. His primary concern is understanding how the modular design improves flexibility, maintainability, and the ease of integrating new data sources in large-scale enterprise implementations.\"},{\"affiliation\":\"Machine Learning Product Lead, HyperNLP\",\"name\":\"Soo-yeon Kim\",\"role\":\"Production Deployment Strategist\",\"description\":\"Soo-yeon Kim investigates the advantages of Modular RAG over Naive RAG in real-world, production-level use cases. Her focus is on system robustness, operational efficiency, fault tolerance, and the capacity for independent module updates, all crucial for maintaining reliable AI-powered retrieval systems in live business environments.\"},{\"affiliation\":\"Research Scientist, KAIST AI Lab\",\"name\":\"Jae-hyuk Lee\",\"role\":\"Performance and Optimization Analyst\",\"description\":\"Jae-hyuk Lee explores how Modular RAG affects retrieval accuracy, latency, and resource efficiency compared to Naive RAG. He analyzes experimental benchmarks, use-case fit, and the impact of modularization on fine-tuning and rapid iteration cycles, aiming to optimize both system performance and end-user experience.\"}]}"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, stream_graph\n",
    "\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=10,\n",
    "    configurable={\"thread_id\": random_uuid()},\n",
    ")\n",
    "\n",
    "# ë¶„ì„ê°€ ìˆ˜ ì„¤ì •\n",
    "max_analysts = 3\n",
    "\n",
    "# ì—°êµ¬ ì£¼ì œ ì„¤ì •\n",
    "topic = \"Modular RAG ê°€ ê¸°ì¡´ì˜ Naive RAG ì™€ ì–´ë–¤ ì°¨ì´ê°€ ìˆëŠ”ì§€ì™€ production level ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì \"\n",
    "\n",
    "# ì…ë ¥ ë°ì´í„° ì„¤ì •\n",
    "inputs = {\n",
    "    \"topic\": topic,\n",
    "    \"max_analysts\": max_analysts,\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "stream_graph(graph, inputs, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623117de",
   "metadata": {},
   "source": [
    "`__interrupt__` ê°€ ì¶œë ¥ë˜ë©´ ì¸ê°„ì˜ í”¼ë“œë°±ì„ ë°›ì„ ì¤€ë¹„ê°€ ëœ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ ì•„ë˜ì˜ ìƒíƒœë¥¼ ê°€ì ¸ì™€ì„œ ì¸ê°„ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8fe74eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('human_feedback',)\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë˜í”„ì˜ í˜„ì¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°\n",
    "state = graph.get_state(config)\n",
    "\n",
    "# ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œ í™•ì¸\n",
    "print(state.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d6ca4e",
   "metadata": {},
   "source": [
    "`update_state()` ë¥¼ í†µí•´ ì¸ê°„ í”¼ë“œë°±ì„ ì£¼ì…í•©ë‹ˆë‹¤. ì´ë•Œ `human_analyst_feedback` í‚¤ì— í”¼ë“œë°± ë‚´ìš©ì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë˜í•œ `as_node` ì¸ìë¥¼ í†µí•´ í”¼ë“œë°±ì„ ë°›ì„ ë…¸ë“œë¥¼ ì§€ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efba1d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '37c11b5d-9b0c-435b-b89a-026ee3039a13',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0ab197-0127-64ca-8002-04eac471abd9'}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê·¸ë˜í”„ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ human_feedback ë…¸ë“œì˜ ì—­í•  ìˆ˜í–‰\n",
    "graph.update_state(\n",
    "    config,\n",
    "    {\n",
    "        \"human_analyst_feedback\": \"Add in someone named Teddy Lee from a startup to add an entrepreneur perspective\"\n",
    "    },\n",
    "    as_node=\"human_feedback\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b22e9d",
   "metadata": {},
   "source": [
    "`None` ê°’ì„ ì…ë ¥ìœ¼ë¡œ ì£¼ê²Œ ë˜ë©´, ì´ì–´ì„œ ê·¸ë˜í”„ê°€ ì§„í–‰ë©ë‹ˆë‹¤.\n",
    "\n",
    "**ì°¸ê³ **\n",
    "\n",
    "- ì¬ê°œí•˜ê³ ì í•  ë•ŒëŠ” ì…ë ¥ì— `None` ê°’ì„ í• ë‹¹í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ì¬ê°œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65011c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mcreate_analysts\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "affiliation='Stanford University, Department of Computer Science' name='Dr. Lilian Park' role='AI Researcher and RAG Methodology Specialist' description='Dr. Park focuses on the technical evolution of Retrieval-Augmented Generation (RAG) methods. Her work dissects the architectural improvements brought by modular RAG over naive RAG, analyzing the implications for scalability, maintainability, and the integration of domain-specific modules.'\n",
      "affiliation='GAFA (Global Enterprise Technology Integrator)' name='Michael Grant' role='Enterprise AI Solutions Architect' description='Michael specializes in deploying large-scale AI solutions in enterprise settings. His primary concern is the production-readiness of RAG systems, with an emphasis on reliability, operational efficiency, and how modular architectures facilitate smoother production deployments compared to naive approaches.'\n",
      "affiliation='AlpinaAI (Startup Founder)' name='Teddy Lee' role='Entrepreneur and Product Lead' description='Teddy Lee brings a startup perspective, concentrating on the practical and business benefits of modular RAG for fast-paced, resource-constrained teams. He evaluates how modularization accelerates prototyping, customization, and iteration, which are crucial factors for startups aiming to outpace the competition.'\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36m__interrupt__\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ì´ì–´ì„œ ì§„í–‰\n",
    "invoke_graph(graph, None, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf393cce",
   "metadata": {},
   "source": [
    "ë‹¤ì‹œ `__interrupt__` ê°€ ì¶œë ¥ë˜ë©´ ì¸ê°„ì˜ í”¼ë“œë°±ì„ ë°›ì„ ì¤€ë¹„ê°€ ëœ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ì „ì˜ ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ë‹¤ì‹œ ì¸ê°„ í”¼ë“œë°±ì„ ì œê³µí•˜ì—¬ ìƒì„±ëœ ë¶„ì„ê°€ì˜ í˜ë¥´ì†Œë‚˜ë¥¼ ì¡°ì •í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "í•˜ì§€ë§Œ, ì¶”ê°€ í”¼ë“œë°±ì´ ì—†ì„ ê²½ìš° `None` ê°’ì„ í• ë‹¹í•˜ì—¬ ë¶„ì„ê°€ ìƒì„± ì‘ì—…ì„ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab512d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '37c11b5d-9b0c-435b-b89a-026ee3039a13',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0ab197-4734-681e-8004-41d6e9d3d365'}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì¶”ê°€ í”¼ë“œë°±ì´ ì—†ì„ ê²½ìš° None ê°’ì„ í• ë‹¹í•˜ì—¬ ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "human_feedback_input = None\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ human_feedback ë…¸ë“œì˜ ì—­í•  ìˆ˜í–‰\n",
    "graph.update_state(\n",
    "    config, {\"human_analyst_feedback\": human_feedback_input}, as_node=\"human_feedback\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35618b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ì–´ì„œ ì§„í–‰\n",
    "invoke_graph(graph, None, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710300b6",
   "metadata": {},
   "source": [
    "ìµœì¢… ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d759708e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒì„±ëœ ë¶„ì„ê°€ ìˆ˜: 3\n",
      "================================\n",
      "Name: Dr. Lilian Park\n",
      "Role: AI Researcher and RAG Methodology Specialist\n",
      "Affiliation: Stanford University, Department of Computer Science\n",
      "Description: Dr. Park focuses on the technical evolution of Retrieval-Augmented Generation (RAG) methods. Her work dissects the architectural improvements brought by modular RAG over naive RAG, analyzing the implications for scalability, maintainability, and the integration of domain-specific modules.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Name: Michael Grant\n",
      "Role: Enterprise AI Solutions Architect\n",
      "Affiliation: GAFA (Global Enterprise Technology Integrator)\n",
      "Description: Michael specializes in deploying large-scale AI solutions in enterprise settings. His primary concern is the production-readiness of RAG systems, with an emphasis on reliability, operational efficiency, and how modular architectures facilitate smoother production deployments compared to naive approaches.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Name: Teddy Lee\n",
      "Role: Entrepreneur and Product Lead\n",
      "Affiliation: AlpinaAI (Startup Founder)\n",
      "Description: Teddy Lee brings a startup perspective, concentrating on the practical and business benefits of modular RAG for fast-paced, resource-constrained teams. He evaluates how modularization accelerates prototyping, customization, and iteration, which are crucial factors for startups aiming to outpace the competition.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë˜í”„ì˜ ìµœì¢… ìƒíƒœ ê°€ì ¸ì˜¤ê¸°\n",
    "final_state = graph.get_state(config)\n",
    "\n",
    "# ìµœì¢… ìƒíƒœì—ì„œ ìƒì„±ëœ ë¶„ì„ê°€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "analysts = final_state.values.get(\"analysts\")\n",
    "\n",
    "# ìƒì„±ëœ ë¶„ì„ê°€ ìˆ˜ ì¶œë ¥\n",
    "print(f\"ìƒì„±ëœ ë¶„ì„ê°€ ìˆ˜: {len(analysts)}\", end=\"\\n================================\\n\")\n",
    "\n",
    "# ê° ë¶„ì„ê°€ì˜ í˜ë¥´ì†Œë‚˜ ì¶œë ¥\n",
    "for analyst in analysts:\n",
    "    print(analyst.persona)\n",
    "    print(\"- \" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c61b611",
   "metadata": {},
   "source": [
    "`final_state.next` ëŠ” ê·¸ë˜í”„ì˜ ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ëª¨ë“  ì‘ì—…ì´ ë§ˆë¬´ë¦¬ ë˜ì—ˆê¸° ë•Œë¬¸ì— ë¹ˆ `tuple` ì´ ì¶œë ¥ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f92144e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë˜í”„ì˜ ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°\n",
    "print(final_state.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e14e5c",
   "metadata": {},
   "source": [
    "## ì¸í„°ë·° ìˆ˜í–‰\n",
    "\n",
    "### ì§ˆë¬¸ ìƒì„±\n",
    "\n",
    "- ë¶„ì„ê°€ëŠ” ì „ë¬¸ê°€ì—ê²Œ ì§ˆë¬¸ì„ ì œì‹œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "089de179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "# ì¸í„°ë·° ìƒíƒœ ì •ì˜\n",
    "class InterviewState(MessagesState):\n",
    "    # ëŒ€í™” í„´ìˆ˜\n",
    "    max_num_turns: int\n",
    "    # ì†ŒìŠ¤ ë¬¸ì„œë¥¼ í¬í•¨í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "    context: Annotated[list, operator.add]\n",
    "    # ì§€ì •ëœ ë¶„ì„ê°€\n",
    "    analyst: Analyst\n",
    "    # ì¸í„°ë·° ë‚´ìš©ì„ ì €ì¥í•˜ëŠ” ë¬¸ìì—´\n",
    "    interview: str\n",
    "    # ë³´ê³ ì„œ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸\n",
    "    sections: list\n",
    "\n",
    "\n",
    "# ê²€ìƒ‰ ì¿¼ë¦¬ ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = Field(None, description=\"Search query for retrieval.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd2a54",
   "metadata": {},
   "source": [
    "ë‹¤ìŒìœ¼ë¡œëŠ” ì¸í„°ë·° ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a74a90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\n",
    "\n",
    "Your goal is boil down to interesting and specific insights related to your topic.\n",
    "\n",
    "1. Interesting: Insights that people will find surprising or non-obvious.\n",
    "\n",
    "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
    "\n",
    "Here is your topic of focus and set of goals: {goals}\n",
    "\n",
    "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
    "\n",
    "Continue to ask questions to drill down and refine your understanding of the topic.\n",
    "\n",
    "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
    "\n",
    "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\"\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ ì •ì˜\n",
    "def generate_question(state: InterviewState):\n",
    "    # ìƒíƒœì—ì„œ ë¶„ì„ê°€ì™€ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # ì§ˆë¬¸ ìƒì„±\n",
    "    # ë¶„ì„ê°€ì˜ ëª©í‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìƒì„±\n",
    "    system_message = question_instructions.format(goals=analyst.persona)\n",
    "    # LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ ìƒì„±\n",
    "    question = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
    "\n",
    "    # ìƒíƒœì— ë©”ì‹œì§€ ê¸°ë¡\n",
    "    return {\"messages\": [question]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064303de",
   "metadata": {},
   "source": [
    "## ë„êµ¬ ì •ì˜\n",
    "\n",
    "ì „ë¬¸ê°€ëŠ” ì—¬ëŸ¬ ì†ŒìŠ¤ë¡œë¶€í„° ì •ë³´ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜ì§‘í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì›¹ ë¬¸ì„œ ìŠ¤í¬ë˜í•‘, VectorDB, ì›¹ ê²€ìƒ‰, ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Arxiv, Tavily ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "592a8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ì„ ìœ„í•œ TavilySearch ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "tavily_search = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd85cc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Published': '2024-07-26', 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks', 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang', 'Summary': 'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.', 'entry_id': 'http://arxiv.org/abs/2407.21059v1', 'published_first_time': '2024-07-26', 'comment': None, 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI', 'cs.IR'], 'links': ['http://arxiv.org/abs/2407.21059v1', 'http://arxiv.org/pdf/2407.21059v1']}, page_content='1\\nModular RAG: Transforming RAG Systems into\\nLEGO-like Reconfigurable Frameworks\\nYunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\\nAbstractâ€”Retrieval-augmented\\nGeneration\\n(RAG)\\nhas\\nmarkedly enhanced the capabilities of Large Language Models\\n(LLMs) in tackling knowledge-intensive tasks. The increasing\\ndemands of application scenarios have driven the evolution\\nof RAG, leading to the integration of advanced retrievers,\\nLLMs and other complementary technologies, which in turn\\nhas amplified the intricacy of RAG systems. However, the rapid\\nadvancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process\\nof â€œretrieve-then-generateâ€. In this context, this paper examines\\nthe limitations of the existing RAG paradigm and introduces\\nthe modular RAG framework. By decomposing complex RAG\\nsystems into independent modules and specialized operators, it\\nfacilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a\\nmore advanced design that integrates routing, scheduling, and\\nfusion mechanisms. Drawing on extensive research, this paper\\nfurther identifies prevalent RAG patternsâ€”linear, conditional,\\nbranching, and loopingâ€”and offers a comprehensive analysis\\nof their respective implementation nuances. Modular RAG\\npresents\\ninnovative\\nopportunities\\nfor\\nthe\\nconceptualization\\nand deployment of RAG systems. Finally, the paper explores\\nthe potential emergence of new operators and paradigms,\\nestablishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment\\nof RAG technologies.\\nIndex Termsâ€”Retrieval-augmented generation, large language\\nmodel, modular system, information retrieval\\nI. INTRODUCTION\\nL\\nARGE Language Models (LLMs) have demonstrated\\nremarkable capabilities, yet they still face numerous\\nchallenges, such as hallucination and the lag in information up-\\ndates [1]. Retrieval-augmented Generation (RAG), by access-\\ning external knowledge bases, provides LLMs with important\\ncontextual information, significantly enhancing their perfor-\\nmance on knowledge-intensive tasks [2]. Currently, RAG, as\\nan enhancement method, has been widely applied in various\\npractical application scenarios, including knowledge question\\nanswering, recommendation systems, customer service, and\\npersonal assistants. [3]â€“[6]\\nDuring the nascent stages of RAG , its core framework is\\nconstituted by indexing, retrieval, and generation, a paradigm\\nreferred to as Naive RAG [7]. However, as the complexity\\nof tasks and the demands of applications have escalated, the\\nYunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\\nSystems, Tongji University, Shanghai, 201210, China.\\nYun Xiong is with Shanghai Key Laboratory of Data Science, School of\\nComputer Science, Fudan University, Shanghai, 200438, China.\\nMeng Wang and Haofen Wang are with College of Design and Innovation,\\nTongji University, Shanghai, 20092, China. (Corresponding author: Haofen\\nWang. E-mail: carter.whfcarter@gmail.com)\\nlimitations of Naive RAG have become increasingly apparent.\\nAs depicted in Figure 1, it predominantly hinges on the\\nstraightforward similarity of chunks, result in poor perfor-\\nmance when confronted with complex queries and chunks with\\nsubstantial variability. The primary challenges of Naive RAG\\ninclude: 1) Shallow Understanding of Queries. The semantic\\nsimilarity between a query and document chunk is not always\\nhighly consistent. Relying solely on similarity calculations\\nfor retrieval lacks an in-depth exploration of the relationship\\nbetween the query and the document [8]. 2) Retrieval Re-\\ndundancy and Noise. Feeding all retrieved chunks directly\\ninto LLMs is not always beneficial. Research indicates that\\nan excess of redundant and noisy information may interfere\\nwith the LLMâ€™s identification of key information, thereby\\nincreasing the risk of generating erroneous and hallucinated\\nresponses. [9]\\nTo overcome the aforementioned limitations, '), Document(metadata={'Published': '2024-03-27', 'Title': 'Retrieval-Augmented Generation for Large Language Models: A Survey', 'Authors': 'Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang', 'Summary': \"Large Language Models (LLMs) showcase impressive capabilities but encounter\\nchallenges like hallucination, outdated knowledge, and non-transparent,\\nuntraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\\nemerged as a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the generation,\\nparticularly for knowledge-intensive tasks, and allows for continuous knowledge\\nupdates and integration of domain-specific information. RAG synergistically\\nmerges LLMs' intrinsic knowledge with the vast, dynamic repositories of\\nexternal databases. This comprehensive review paper offers a detailed\\nexamination of the progression of RAG paradigms, encompassing the Naive RAG,\\nthe Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\\ntripartite foundation of RAG frameworks, which includes the retrieval, the\\ngeneration and the augmentation techniques. The paper highlights the\\nstate-of-the-art technologies embedded in each of these critical components,\\nproviding a profound understanding of the advancements in RAG systems.\\nFurthermore, this paper introduces up-to-date evaluation framework and\\nbenchmark. At the end, this article delineates the challenges currently faced\\nand points out prospective avenues for research and development.\", 'entry_id': 'http://arxiv.org/abs/2312.10997v5', 'published_first_time': '2023-12-18', 'comment': 'Ongoing Work', 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI'], 'links': ['http://arxiv.org/abs/2312.10997v5', 'http://arxiv.org/pdf/2312.10997v5']}, page_content='1\\nRetrieval-Augmented Generation for Large\\nLanguage Models: A Survey\\nYunfan Gaoa, Yun Xiongb, Xinyu Gaob, Kangxiang Jiab, Jinliu Panb, Yuxi Bic, Yi Daia, Jiawei Suna, Meng\\nWangc, and Haofen Wang a,c\\naShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\\nbShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\\ncCollege of Design and Innovation, Tongji University\\nAbstractâ€”Large Language Models (LLMs) showcase impres-\\nsive capabilities but encounter challenges like hallucination,\\noutdated knowledge, and non-transparent, untraceable reasoning\\nprocesses. Retrieval-Augmented Generation (RAG) has emerged\\nas a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the\\ngeneration, particularly for knowledge-intensive tasks, and allows\\nfor continuous knowledge updates and integration of domain-\\nspecific information. RAG synergistically merges LLMsâ€™ intrin-\\nsic knowledge with the vast, dynamic repositories of external\\ndatabases. This comprehensive review paper offers a detailed\\nexamination of the progression of RAG paradigms, encompassing\\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\\nIt meticulously scrutinizes the tripartite foundation of RAG\\nframeworks, which includes the retrieval, the generation and the\\naugmentation techniques. The paper highlights the state-of-the-\\nart technologies embedded in each of these critical components,\\nproviding a profound understanding of the advancements in RAG\\nsystems. Furthermore, this paper introduces up-to-date evalua-\\ntion framework and benchmark. At the end, this article delineates\\nthe challenges currently faced and points out prospective avenues\\nfor research and development 1.\\nIndex Termsâ€”Large language model, retrieval-augmented gen-\\neration, natural language processing, information retrieval\\nI. INTRODUCTION\\nL\\nARGE language models (LLMs) have achieved remark-\\nable success, though they still face significant limitations,\\nespecially in domain-specific or knowledge-intensive tasks [1],\\nnotably producing â€œhallucinationsâ€ [2] when handling queries\\nbeyond their training data or requiring current information. To\\novercome challenges, Retrieval-Augmented Generation (RAG)\\nenhances LLMs by retrieving relevant document chunks from\\nexternal knowledge base through semantic similarity calcu-\\nlation. By referencing external knowledge, RAG effectively\\nreduces the problem of generating factually incorrect content.\\nIts integration into LLMs has resulted in widespread adoption,\\nestablishing RAG as a key technology in advancing chatbots\\nand enhancing the suitability of LLMs for real-world applica-\\ntions.\\nRAG technology has rapidly developed in recent years, and\\nthe technology tree summarizing related research is shown\\nCorresponding Author.Email:haofen.wang@tongji.edu.cn\\n1Resources\\nare\\navailable\\nat\\nhttps://github.com/Tongji-KGLLM/\\nRAG-Survey\\nin Figure 1. The development trajectory of RAG in the era\\nof large models exhibits several distinct stage characteristics.\\nInitially, RAGâ€™s inception coincided with the rise of the\\nTransformer architecture, focusing on enhancing language\\nmodels by incorporating additional knowledge through Pre-\\nTraining Models (PTM). This early stage was characterized\\nby foundational work aimed at refining pre-training techniques\\n[3]â€“[5].The subsequent arrival of ChatGPT [6] marked a\\npivotal moment, with LLM demonstrating powerful in context\\nlearning (ICL) capabilities. RAG research shifted towards\\nproviding better information for LLMs to answer more com-\\nplex and knowledge-intensive tasks during the inference stage,\\nleading to rapid development in RAG studies. As research\\nprogressed, the enhancement of RAG was no longer limited\\nto the inference stage but began to incorporate more with LLM\\nfine-tuning techniques.\\nThe burgeoning field of RAG has experienced swift growth,\\nyet it has not been accompanied by a systematic synthesis that\\ncould clarify its broader trajectory. Thi'), Document(metadata={'Published': '2025-10-11', 'Title': 'MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning', 'Authors': 'Thang Nguyen, Peter Chin, Yu-Wing Tai', 'Summary': 'We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation\\n(RAG) that addresses the inherent ambiguities and reasoning challenges in\\ncomplex information-seeking tasks. Unlike conventional RAG methods that rely on\\nend-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates\\na collaborative set of specialized AI agents: Planner, Step Definer, Extractor,\\nand QA Agents, each responsible for a distinct stage of the RAG pipeline. By\\ndecomposing tasks into subtasks such as query disambiguation, evidence\\nextraction, and answer synthesis, and enabling agents to communicate\\nintermediate reasoning via chain-of-thought prompting, MA-RAG progressively\\nrefines retrieval and synthesis while maintaining modular interpretability.\\nExtensive experiments on multi-hop and ambiguous QA benchmarks, including NQ,\\nHotpotQA, 2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly\\noutperforms standalone LLMs and existing RAG methods across all model scales.\\nNotably, even a small LLaMA3-8B model equipped with MA-RAG surpasses larger\\nstandalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\\nstate-of-the-art results on challenging multi-hop datasets. Ablation studies\\nreveal that both the planner and extractor agents are critical for multi-hop\\nreasoning, and that high-capacity models are especially important for the QA\\nagent to synthesize answers effectively. Beyond general-domain QA, MA-RAG\\ngeneralizes to specialized domains such as medical QA, achieving competitive\\nperformance against domain-specific models without any domain-specific\\nfine-tuning. Our results highlight the effectiveness of collaborative, modular\\nreasoning in retrieval-augmented systems: MA-RAG not only improves answer\\naccuracy and robustness but also provides interpretable intermediate reasoning\\nsteps, establishing a new paradigm for efficient and reliable multi-agent RAG.', 'entry_id': 'http://arxiv.org/abs/2505.20096v2', 'published_first_time': '2025-05-26', 'comment': None, 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI'], 'links': ['http://arxiv.org/abs/2505.20096v2', 'http://arxiv.org/pdf/2505.20096v2']}, page_content='MA-RAG: MULTI-AGENT RETRIEVAL-AUGMENTED\\nGENERATION\\nVIA\\nCOLLABORATIVE\\nCHAIN-OF-\\nTHOUGHT REASONING\\nThang Nguyen & Peter Chin & Yu-Wing Tai\\nDartmouth College\\n{thangnv.th, peter.chin, yu-wing.tai}@dartmouth.edu\\nABSTRACT\\nWe present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Gener-\\nation (RAG) that addresses the inherent ambiguities and reasoning challenges in\\ncomplex information-seeking tasks. Unlike conventional RAG methods that rely\\non end-to-end fine-tuning or isolated component enhancements, MA-RAG orches-\\ntrates a collaborative set of specialized AI agents: Planner, Step Definer, Extrac-\\ntor, and QA Agents, each responsible for a distinct stage of the RAG pipeline.\\nBy decomposing tasks into subtasks such as query disambiguation, evidence ex-\\ntraction, and answer synthesis, and enabling agents to communicate intermedi-\\nate reasoning via chain-of-thought prompting, MA-RAG progressively refines re-\\ntrieval and synthesis while maintaining modular interpretability. Extensive exper-\\niments on multi-hop and ambiguous QA benchmarks, including NQ, HotpotQA,\\n2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly outperforms\\nstandalone LLMs and existing RAG methods across all model scales. Notably,\\neven a small LLaMA3-8B model equipped with MA-RAG surpasses larger stan-\\ndalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\\nstate-of-the-art results on challenging multi-hop datasets. Ablation studies reveal\\nthat both the planner and extractor agents are critical for multi-hop reasoning,\\nand that high-capacity models are especially important for the QA agent to syn-\\nthesize answers effectively. Beyond general-domain QA, MA-RAG generalizes\\nto specialized domains such as medical QA, achieving competitive performance\\nagainst domain-specific models without any domain-specific fine-tuning. Our re-\\nsults highlight the effectiveness of collaborative, modular reasoning in retrieval-\\naugmented systems: MA-RAG not only improves answer accuracy and robustness\\nbut also provides interpretable intermediate reasoning steps, establishing a new\\nparadigm for efficient and reliable multi-agent RAG1.\\n1\\nINTRODUCTION\\nRecent advances in natural language processing have driven the development of Retrieval-\\nAugmented Generation (RAG) models, which aim to enhance the factual accuracy and contextual\\nrelevance of generated text by integrating external knowledge sources (Lewis et al., 2020; Guu et al.,\\n2020; Izacard & Grave, 2021; Lin et al., 2024). These systems address core limitations of Large Lan-\\nguage Models (LLMs), such as outdated knowledge (Zhang et al., 2023b; Kasai et al., 2023) and\\npoor generalization to domain-specific queries (Siriwardhana et al., 2023; Xiong et al., 2024), by\\nretrieving top-k documents from an external corpus (Formal et al., 2022; Izacard et al., 2022; Wang\\net al., 2022a) to ground the modelâ€™s output in relevant evidence.\\nPrior research in RAG has largely concentrated on optimizing three key componentsâ€”retrieval,\\naugmentation, and generation (Gao et al., 2024; Fan et al., 2024) (Figure 1(a)). Retrieval strate-\\ngies span sparse methods (Jones, 1972; Robertson & Zaragoza, 2009) and dense retrieval (Reimers\\n& Gurevych, 2019; Karpukhin et al., 2020), each with respective weaknesses such as lexical\\ngaps (Berger et al., 2000) or retrieval failure on out-of-distribution and multi-hop queries (Dai et al.,\\n1Our code is available at https://github.com/thangylvp/MA-RAG\\n1\\narXiv:2505.20096v2  [cs.CL]  11 Oct 2025\\nQuery\\nDocs\\nAnswer\\nDocs\\nAnswer\\nCoT\\nNotes\\nPost-process\\na) Vanilla RAG\\nStep 1\\nStep ...\\nCoT\\nSub-Query\\nQuery\\nDocs\\nNotes\\nCoT\\nQuery\\nSub-Answer\\nCoT\\nb) RAG with post-\\nprocessing retrieved docs\\nd) MA-RAG\\nQuery\\nDocs\\nAnswer\\nc) RAG with interleaving\\nretrieval and thoughts\\nAnswer\\nCoT\\nFigure 1: Architectural Comparison of MA-RAG and Prior RAG Methods. a) A naive RAG sys-\\ntem performs one-shot retrieval followed by direct answer generation. b) Enhanced systems incor-\\nporate post-retrieval processing such as document re-')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.retrievers import ArxivRetriever\n",
    "\n",
    "# Arxiv ê²€ìƒ‰ì„ ìœ„í•œ ArxivRetriever ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "arxiv_retriever = ArxivRetriever(\n",
    "    load_max_docs=3,\n",
    "    load_all_available_meta=True,\n",
    "    get_full_documents=True,\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "arxiv_search_results = arxiv_retriever.invoke(\"Modular RAG vs Naive RAG\")\n",
    "print(arxiv_search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03485bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2024-07-26',\n",
       " 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks',\n",
       " 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang',\n",
       " 'Summary': 'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.',\n",
       " 'entry_id': 'http://arxiv.org/abs/2407.21059v1',\n",
       " 'published_first_time': '2024-07-26',\n",
       " 'comment': None,\n",
       " 'journal_ref': None,\n",
       " 'doi': None,\n",
       " 'primary_category': 'cs.CL',\n",
       " 'categories': ['cs.CL', 'cs.AI', 'cs.IR'],\n",
       " 'links': ['http://arxiv.org/abs/2407.21059v1',\n",
       "  'http://arxiv.org/pdf/2407.21059v1']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arxiv ë©”íƒ€ë°ì´í„° ì¶œë ¥\n",
    "arxiv_search_results[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fc31182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstractâ€”Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of â€œretrieve-then-generateâ€. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patternsâ€”linear, conditional,\n",
      "branching, and loopingâ€”and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Termsâ€”Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]â€“[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLMâ€™s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n"
     ]
    }
   ],
   "source": [
    "# Arxiv ë‚´ìš© ì¶œë ¥\n",
    "print(arxiv_search_results[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6294ff",
   "metadata": {},
   "source": [
    "ë¬¸ì„œ ê²€ìƒ‰ê²°ê³¼ë¥¼ í¬ë§·íŒ… ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0475512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…\n",
    "formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "    [\n",
    "        f'<Document source=\"{doc.metadata[\"entry_id\"]}\" date=\"{doc.metadata.get(\"Published\", \"\")}\" authors=\"{doc.metadata.get(\"Authors\", \"\")}\"/>\\n<Title>\\n{doc.metadata[\"Title\"]}\\n</Title>\\n\\n<Summary>\\n{doc.metadata[\"Summary\"]}\\n</Summary>\\n\\n<Content>\\n{doc.page_content}\\n</Content>\\n</Document>'\n",
    "        for doc in arxiv_search_results\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abc66263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstractâ€”Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of â€œretrieve-then-generateâ€. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patternsâ€”linear, conditional,\n",
      "branching, and loopingâ€”and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Termsâ€”Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]â€“[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLMâ€™s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2312.10997v5\" date=\"2024-03-27\" authors=\"Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Retrieval-Augmented Generation for Large Language Models: A Survey\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Large Language Models (LLMs) showcase impressive capabilities but encounter\n",
      "challenges like hallucination, outdated knowledge, and non-transparent,\n",
      "untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\n",
      "emerged as a promising solution by incorporating knowledge from external\n",
      "databases. This enhances the accuracy and credibility of the generation,\n",
      "particularly for knowledge-intensive tasks, and allows for continuous knowledge\n",
      "updates and integration of domain-specific information. RAG synergistically\n",
      "merges LLMs' intrinsic knowledge with the vast, dynamic repositories of\n",
      "external databases. This comprehensive review paper offers a detailed\n",
      "examination of the progression of RAG paradigms, encompassing the Naive RAG,\n",
      "the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\n",
      "tripartite foundation of RAG frameworks, which includes the retrieval, the\n",
      "generation and the augmentation techniques. The paper highlights the\n",
      "state-of-the-art technologies embedded in each of these critical components,\n",
      "providing a profound understanding of the advancements in RAG systems.\n",
      "Furthermore, this paper introduces up-to-date evaluation framework and\n",
      "benchmark. At the end, this article delineates the challenges currently faced\n",
      "and points out prospective avenues for research and development.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Retrieval-Augmented Generation for Large\n",
      "Language Models: A Survey\n",
      "Yunfan Gaoa, Yun Xiongb, Xinyu Gaob, Kangxiang Jiab, Jinliu Panb, Yuxi Bic, Yi Daia, Jiawei Suna, Meng\n",
      "Wangc, and Haofen Wang a,c\n",
      "aShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\n",
      "bShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\n",
      "cCollege of Design and Innovation, Tongji University\n",
      "Abstractâ€”Large Language Models (LLMs) showcase impres-\n",
      "sive capabilities but encounter challenges like hallucination,\n",
      "outdated knowledge, and non-transparent, untraceable reasoning\n",
      "processes. Retrieval-Augmented Generation (RAG) has emerged\n",
      "as a promising solution by incorporating knowledge from external\n",
      "databases. This enhances the accuracy and credibility of the\n",
      "generation, particularly for knowledge-intensive tasks, and allows\n",
      "for continuous knowledge updates and integration of domain-\n",
      "specific information. RAG synergistically merges LLMsâ€™ intrin-\n",
      "sic knowledge with the vast, dynamic repositories of external\n",
      "databases. This comprehensive review paper offers a detailed\n",
      "examination of the progression of RAG paradigms, encompassing\n",
      "the Naive RAG, the Advanced RAG, and the Modular RAG.\n",
      "It meticulously scrutinizes the tripartite foundation of RAG\n",
      "frameworks, which includes the retrieval, the generation and the\n",
      "augmentation techniques. The paper highlights the state-of-the-\n",
      "art technologies embedded in each of these critical components,\n",
      "providing a profound understanding of the advancements in RAG\n",
      "systems. Furthermore, this paper introduces up-to-date evalua-\n",
      "tion framework and benchmark. At the end, this article delineates\n",
      "the challenges currently faced and points out prospective avenues\n",
      "for research and development 1.\n",
      "Index Termsâ€”Large language model, retrieval-augmented gen-\n",
      "eration, natural language processing, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE language models (LLMs) have achieved remark-\n",
      "able success, though they still face significant limitations,\n",
      "especially in domain-specific or knowledge-intensive tasks [1],\n",
      "notably producing â€œhallucinationsâ€ [2] when handling queries\n",
      "beyond their training data or requiring current information. To\n",
      "overcome challenges, Retrieval-Augmented Generation (RAG)\n",
      "enhances LLMs by retrieving relevant document chunks from\n",
      "external knowledge base through semantic similarity calcu-\n",
      "lation. By referencing external knowledge, RAG effectively\n",
      "reduces the problem of generating factually incorrect content.\n",
      "Its integration into LLMs has resulted in widespread adoption,\n",
      "establishing RAG as a key technology in advancing chatbots\n",
      "and enhancing the suitability of LLMs for real-world applica-\n",
      "tions.\n",
      "RAG technology has rapidly developed in recent years, and\n",
      "the technology tree summarizing related research is shown\n",
      "Corresponding Author.Email:haofen.wang@tongji.edu.cn\n",
      "1Resources\n",
      "are\n",
      "available\n",
      "at\n",
      "https://github.com/Tongji-KGLLM/\n",
      "RAG-Survey\n",
      "in Figure 1. The development trajectory of RAG in the era\n",
      "of large models exhibits several distinct stage characteristics.\n",
      "Initially, RAGâ€™s inception coincided with the rise of the\n",
      "Transformer architecture, focusing on enhancing language\n",
      "models by incorporating additional knowledge through Pre-\n",
      "Training Models (PTM). This early stage was characterized\n",
      "by foundational work aimed at refining pre-training techniques\n",
      "[3]â€“[5].The subsequent arrival of ChatGPT [6] marked a\n",
      "pivotal moment, with LLM demonstrating powerful in context\n",
      "learning (ICL) capabilities. RAG research shifted towards\n",
      "providing better information for LLMs to answer more com-\n",
      "plex and knowledge-intensive tasks during the inference stage,\n",
      "leading to rapid development in RAG studies. As research\n",
      "progressed, the enhancement of RAG was no longer limited\n",
      "to the inference stage but began to incorporate more with LLM\n",
      "fine-tuning techniques.\n",
      "The burgeoning field of RAG has experienced swift growth,\n",
      "yet it has not been accompanied by a systematic synthesis that\n",
      "could clarify its broader trajectory. Thi\n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2505.20096v2\" date=\"2025-10-11\" authors=\"Thang Nguyen, Peter Chin, Yu-Wing Tai\"/>\n",
      "<Title>\n",
      "MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation\n",
      "(RAG) that addresses the inherent ambiguities and reasoning challenges in\n",
      "complex information-seeking tasks. Unlike conventional RAG methods that rely on\n",
      "end-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates\n",
      "a collaborative set of specialized AI agents: Planner, Step Definer, Extractor,\n",
      "and QA Agents, each responsible for a distinct stage of the RAG pipeline. By\n",
      "decomposing tasks into subtasks such as query disambiguation, evidence\n",
      "extraction, and answer synthesis, and enabling agents to communicate\n",
      "intermediate reasoning via chain-of-thought prompting, MA-RAG progressively\n",
      "refines retrieval and synthesis while maintaining modular interpretability.\n",
      "Extensive experiments on multi-hop and ambiguous QA benchmarks, including NQ,\n",
      "HotpotQA, 2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly\n",
      "outperforms standalone LLMs and existing RAG methods across all model scales.\n",
      "Notably, even a small LLaMA3-8B model equipped with MA-RAG surpasses larger\n",
      "standalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\n",
      "state-of-the-art results on challenging multi-hop datasets. Ablation studies\n",
      "reveal that both the planner and extractor agents are critical for multi-hop\n",
      "reasoning, and that high-capacity models are especially important for the QA\n",
      "agent to synthesize answers effectively. Beyond general-domain QA, MA-RAG\n",
      "generalizes to specialized domains such as medical QA, achieving competitive\n",
      "performance against domain-specific models without any domain-specific\n",
      "fine-tuning. Our results highlight the effectiveness of collaborative, modular\n",
      "reasoning in retrieval-augmented systems: MA-RAG not only improves answer\n",
      "accuracy and robustness but also provides interpretable intermediate reasoning\n",
      "steps, establishing a new paradigm for efficient and reliable multi-agent RAG.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "MA-RAG: MULTI-AGENT RETRIEVAL-AUGMENTED\n",
      "GENERATION\n",
      "VIA\n",
      "COLLABORATIVE\n",
      "CHAIN-OF-\n",
      "THOUGHT REASONING\n",
      "Thang Nguyen & Peter Chin & Yu-Wing Tai\n",
      "Dartmouth College\n",
      "{thangnv.th, peter.chin, yu-wing.tai}@dartmouth.edu\n",
      "ABSTRACT\n",
      "We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Gener-\n",
      "ation (RAG) that addresses the inherent ambiguities and reasoning challenges in\n",
      "complex information-seeking tasks. Unlike conventional RAG methods that rely\n",
      "on end-to-end fine-tuning or isolated component enhancements, MA-RAG orches-\n",
      "trates a collaborative set of specialized AI agents: Planner, Step Definer, Extrac-\n",
      "tor, and QA Agents, each responsible for a distinct stage of the RAG pipeline.\n",
      "By decomposing tasks into subtasks such as query disambiguation, evidence ex-\n",
      "traction, and answer synthesis, and enabling agents to communicate intermedi-\n",
      "ate reasoning via chain-of-thought prompting, MA-RAG progressively refines re-\n",
      "trieval and synthesis while maintaining modular interpretability. Extensive exper-\n",
      "iments on multi-hop and ambiguous QA benchmarks, including NQ, HotpotQA,\n",
      "2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly outperforms\n",
      "standalone LLMs and existing RAG methods across all model scales. Notably,\n",
      "even a small LLaMA3-8B model equipped with MA-RAG surpasses larger stan-\n",
      "dalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\n",
      "state-of-the-art results on challenging multi-hop datasets. Ablation studies reveal\n",
      "that both the planner and extractor agents are critical for multi-hop reasoning,\n",
      "and that high-capacity models are especially important for the QA agent to syn-\n",
      "thesize answers effectively. Beyond general-domain QA, MA-RAG generalizes\n",
      "to specialized domains such as medical QA, achieving competitive performance\n",
      "against domain-specific models without any domain-specific fine-tuning. Our re-\n",
      "sults highlight the effectiveness of collaborative, modular reasoning in retrieval-\n",
      "augmented systems: MA-RAG not only improves answer accuracy and robustness\n",
      "but also provides interpretable intermediate reasoning steps, establishing a new\n",
      "paradigm for efficient and reliable multi-agent RAG1.\n",
      "1\n",
      "INTRODUCTION\n",
      "Recent advances in natural language processing have driven the development of Retrieval-\n",
      "Augmented Generation (RAG) models, which aim to enhance the factual accuracy and contextual\n",
      "relevance of generated text by integrating external knowledge sources (Lewis et al., 2020; Guu et al.,\n",
      "2020; Izacard & Grave, 2021; Lin et al., 2024). These systems address core limitations of Large Lan-\n",
      "guage Models (LLMs), such as outdated knowledge (Zhang et al., 2023b; Kasai et al., 2023) and\n",
      "poor generalization to domain-specific queries (Siriwardhana et al., 2023; Xiong et al., 2024), by\n",
      "retrieving top-k documents from an external corpus (Formal et al., 2022; Izacard et al., 2022; Wang\n",
      "et al., 2022a) to ground the modelâ€™s output in relevant evidence.\n",
      "Prior research in RAG has largely concentrated on optimizing three key componentsâ€”retrieval,\n",
      "augmentation, and generation (Gao et al., 2024; Fan et al., 2024) (Figure 1(a)). Retrieval strate-\n",
      "gies span sparse methods (Jones, 1972; Robertson & Zaragoza, 2009) and dense retrieval (Reimers\n",
      "& Gurevych, 2019; Karpukhin et al., 2020), each with respective weaknesses such as lexical\n",
      "gaps (Berger et al., 2000) or retrieval failure on out-of-distribution and multi-hop queries (Dai et al.,\n",
      "1Our code is available at https://github.com/thangylvp/MA-RAG\n",
      "1\n",
      "arXiv:2505.20096v2  [cs.CL]  11 Oct 2025\n",
      "Query\n",
      "Docs\n",
      "Answer\n",
      "Docs\n",
      "Answer\n",
      "CoT\n",
      "Notes\n",
      "Post-process\n",
      "a) Vanilla RAG\n",
      "Step 1\n",
      "Step ...\n",
      "CoT\n",
      "Sub-Query\n",
      "Query\n",
      "Docs\n",
      "Notes\n",
      "CoT\n",
      "Query\n",
      "Sub-Answer\n",
      "CoT\n",
      "b) RAG with post-\n",
      "processing retrieved docs\n",
      "d) MA-RAG\n",
      "Query\n",
      "Docs\n",
      "Answer\n",
      "c) RAG with interleaving\n",
      "retrieval and thoughts\n",
      "Answer\n",
      "CoT\n",
      "Figure 1: Architectural Comparison of MA-RAG and Prior RAG Methods. a) A naive RAG sys-\n",
      "tem performs one-shot retrieval followed by direct answer generation. b) Enhanced systems incor-\n",
      "porate post-retrieval processing such as document re-\n",
      "</Content>\n",
      "</Document>\n"
     ]
    }
   ],
   "source": [
    "print(formatted_search_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439f615",
   "metadata": {},
   "source": [
    "## ë…¸ë“œ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d26cd924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import get_buffer_string\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# ê²€ìƒ‰ ì¿¼ë¦¬ ì‘ì„±\n",
    "search_instructions = SystemMessage(\n",
    "    content=f\"\"\"You will be given a conversation between an analyst and an expert.\n",
    "\n",
    "Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\n",
    "\n",
    "First, analyze the full conversation.\n",
    "\n",
    "Pay particular attention to the final question posed by the analyst.\n",
    "\n",
    "Convert this final question into a well-structured web search query\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ í•¨ìˆ˜ ì •ì˜\n",
    "def search_web(state: InterviewState):\n",
    "    \"\"\"ì›¹ ê²€ìƒ‰ì„ í†µí•œ ë¬¸ì„œ ê²€ìƒ‰\"\"\"\n",
    "\n",
    "    # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±\n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structured_llm.invoke([search_instructions] + state[\"messages\"])\n",
    "\n",
    "    # ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    search_docs = tavily_search.invoke(search_query.search_query)\n",
    "\n",
    "    # ê²€ìƒ‰ ê²°ê³¼ í˜•ì‹ ì§€ì •\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}\n",
    "\n",
    "\n",
    "# Arxiv ê²€ìƒ‰ ë…¸ë“œ ìƒì„±\n",
    "def search_arxiv(state: InterviewState):\n",
    "    \"\"\"Arxiv ê²€ìƒ‰ ë…¸ë“œ\"\"\"\n",
    "\n",
    "    # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±\n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structured_llm.invoke([search_instructions] + state[\"messages\"])\n",
    "\n",
    "    try:\n",
    "        # ê²€ìƒ‰ ìˆ˜í–‰\n",
    "        arxiv_search_results = arxiv_retriever.invoke(\n",
    "            search_query.search_query,\n",
    "            load_max_docs=2,\n",
    "            load_all_available_meta=True,\n",
    "            get_full_documents=True,\n",
    "        )\n",
    "\n",
    "        # ê²€ìƒ‰ ê²°ê³¼ í˜•ì‹ ì§€ì •\n",
    "        formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "            [\n",
    "                f'<Document source=\"{doc.metadata[\"entry_id\"]}\" date=\"{doc.metadata.get(\"Published\", \"\")}\" authors=\"{doc.metadata.get(\"Authors\", \"\")}\"/>\\n<Title>\\n{doc.metadata[\"Title\"]}\\n</Title>\\n\\n<Summary>\\n{doc.metadata[\"Summary\"]}\\n</Summary>\\n\\n<Content>\\n{doc.page_content}\\n</Content>\\n</Document>'\n",
    "                for doc in arxiv_search_results\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return {\"context\": [formatted_search_docs]}\n",
    "    except Exception as e:\n",
    "        print(f\"Arxiv ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        return {\n",
    "            \"context\": [\"<Error>Arxiv ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.</Error>\"]\n",
    "        }\n",
    "\n",
    "\n",
    "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
    "\n",
    "Here is analyst area of focus: {goals}.\n",
    "\n",
    "You goal is to answer a question posed by the interviewer.\n",
    "\n",
    "To answer question, use this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "When answering questions, follow these guidelines:\n",
    "\n",
    "1. Use only the information provided in the context.\n",
    "\n",
    "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
    "\n",
    "3. The context contain sources at the topic of each individual document.\n",
    "\n",
    "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\n",
    "\n",
    "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
    "\n",
    "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list:\n",
    "\n",
    "[1] assistant/docs/llama3_1.pdf, page 7\n",
    "\n",
    "And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\"\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± í•¨ìˆ˜ ì •ì˜\n",
    "def generate_answer(state: InterviewState):\n",
    "    \"\"\"ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ë…¸ë“œ\"\"\"\n",
    "\n",
    "    # ìƒíƒœì—ì„œ ë¶„ì„ê°€ì™€ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±\n",
    "    system_message = answer_instructions.format(goals=analyst.persona, context=context)\n",
    "    answer = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
    "\n",
    "    # ë©”ì‹œì§€ë¥¼ ì „ë¬¸ê°€ì˜ ë‹µë³€ìœ¼ë¡œ ëª…ëª…\n",
    "    answer.name = \"expert\"\n",
    "\n",
    "    # ìƒíƒœì— ë©”ì‹œì§€ ì¶”ê°€\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "\n",
    "# ì¸í„°ë·° ì €ì¥ í•¨ìˆ˜ ì •ì˜\n",
    "def save_interview(state: InterviewState):\n",
    "    \"\"\"ì¸í„°ë·° ì €ì¥\"\"\"\n",
    "\n",
    "    # ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # ì¸í„°ë·°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "    interview = get_buffer_string(messages)\n",
    "\n",
    "    # ì¸í„°ë·° í‚¤ì— ì €ì¥\n",
    "    return {\"interview\": interview}\n",
    "\n",
    "\n",
    "# ë©”ì‹œì§€ ë¼ìš°íŒ… í•¨ìˆ˜ ì •ì˜\n",
    "def route_messages(state: InterviewState, name: str = \"expert\"):\n",
    "    \"\"\"ì§ˆë¬¸ê³¼ ë‹µë³€ ì‚¬ì´ì˜ ë¼ìš°íŒ…\"\"\"\n",
    "\n",
    "    # ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°\n",
    "    messages = state[\"messages\"]\n",
    "    max_num_turns = state.get(\"max_num_turns\", 2)\n",
    "\n",
    "    # ì „ë¬¸ê°€ì˜ ë‹µë³€ ìˆ˜ í™•ì¸\n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "\n",
    "    # ì „ë¬¸ê°€ê°€ ìµœëŒ€ í„´ ìˆ˜ ì´ìƒ ë‹µë³€í•œ ê²½ìš° ì¢…ë£Œ\n",
    "    if num_responses >= max_num_turns:\n",
    "        return \"save_interview\"\n",
    "\n",
    "    # ì´ ë¼ìš°í„°ëŠ” ê° ì§ˆë¬¸-ë‹µë³€ ìŒ í›„ì— ì‹¤í–‰ë¨\n",
    "    # ë…¼ì˜ ì¢…ë£Œë¥¼ ì‹ í˜¸í•˜ëŠ” ë§ˆì§€ë§‰ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°\n",
    "    last_question = messages[-2]\n",
    "\n",
    "    if \"Thank you so much for your help\" in last_question.content:\n",
    "        return \"save_interview\"\n",
    "    return \"ask_question\"\n",
    "\n",
    "\n",
    "# ì„¸ì…˜ ì‘ì„± ì§€ì‹œì‚¬í•­\n",
    "section_writer_instructions = \"\"\"You are an expert technical writer.\n",
    "\n",
    "Your task is to create a detailed and comprehensive section of a report, thoroughly analyzing a set of source documents.\n",
    "This involves extracting key insights, elaborating on relevant points, and providing in-depth explanations to ensure clarity and understanding. Your writing should include necessary context, supporting evidence, and examples to enhance the reader's comprehension. Maintain a logical and well-organized structure, ensuring that all critical aspects are covered in detail and presented in a professional tone.\n",
    "\n",
    "Please follow these instructions:\n",
    "1. Analyze the content of the source documents:\n",
    "- The name of each source document is at the start of the document, with the <Document tag.\n",
    "\n",
    "2. Create a report structure using markdown formatting:\n",
    "- Use ## for the section title\n",
    "- Use ### for sub-section headers\n",
    "\n",
    "3. Write the report following this structure:\n",
    "a. Title (## header)\n",
    "b. Summary (### header)\n",
    "c. Comprehensive analysis (### header)\n",
    "d. Sources (### header)\n",
    "\n",
    "4. Make your title engaging based upon the focus area of the analyst:\n",
    "{focus}\n",
    "\n",
    "5. For the summary section:\n",
    "- Set up summary with general background / context related to the focus area of the analyst\n",
    "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
    "- Create a numbered list of source documents, as you use them\n",
    "- Do not mention the names of interviewers or experts\n",
    "- Aim for approximately 400 words maximum\n",
    "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
    "\n",
    "6. For the Comprehensive analysis section:\n",
    "- Provide a detailed examination of the information from the source documents.\n",
    "- Break down complex ideas into digestible segments, ensuring a logical flow of ideas.\n",
    "- Use sub-sections where necessary to cover multiple perspectives or dimensions of the analysis.\n",
    "- Support your analysis with data, direct quotes, and examples from the source documents.\n",
    "- Clearly explain the relevance of each point to the overall focus of the report.\n",
    "- Use bullet points or numbered lists for clarity when presenting multiple related ideas.\n",
    "- Ensure the tone remains professional and objective, avoiding bias or unsupported opinions.\n",
    "- Aim for at least 800 words to ensure the analysis is thorough.\n",
    "\n",
    "7. In the Sources section:\n",
    "- Include all sources used in your report\n",
    "- Provide full links to relevant websites or specific document paths\n",
    "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
    "- It will look like:\n",
    "\n",
    "### Sources\n",
    "[1] Link or Document name\n",
    "[2] Link or Document name\n",
    "\n",
    "8. Be sure to combine sources. For example this is not correct:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "There should be no redundant sources. It should simply be:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "9. Final review:\n",
    "- Ensure the report follows the required structure\n",
    "- Include no preamble before the title of the report\n",
    "- Check that all guidelines have been followed\"\"\"\n",
    "\n",
    "\n",
    "# ì„¹ì…˜ ì‘ì„± í•¨ìˆ˜ ì •ì˜\n",
    "def write_section(state: InterviewState):\n",
    "    \"\"\"ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ë…¸ë“œ\"\"\"\n",
    "\n",
    "    # ìƒíƒœì—ì„œ ì»¨í…ìŠ¤íŠ¸, ë¶„ì„ê°€ ê°€ì ¸ì˜¤ê¸°\n",
    "    context = state[\"context\"]\n",
    "    analyst = state[\"analyst\"]\n",
    "\n",
    "    # ì„¹ì…˜ ì‘ì„±ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    system_message = section_writer_instructions.format(focus=analyst.description)\n",
    "    section = llm.invoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [HumanMessage(content=f\"Use this source to write your section: {context}\")]\n",
    "    )\n",
    "\n",
    "    # ìƒíƒœì— ì„¹ì…˜ ì¶”ê°€\n",
    "    return {\"sections\": [section.content]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb721d",
   "metadata": {},
   "source": [
    "## ì¸í„°ë·° ê·¸ë˜í”„ ìƒì„±\n",
    "\n",
    "ì¸í„°ë·°ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê·¸ë˜í”„ë¥¼ ì •ì˜í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f74e1e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# ë…¸ë“œ ë° ì—£ì§€ ì¶”ê°€\n",
    "interview_builder = StateGraph(InterviewState)\n",
    "interview_builder.add_node(\"ask_question\", generate_question)\n",
    "interview_builder.add_node(\"search_web\", search_web)\n",
    "interview_builder.add_node(\"search_arxiv\", search_arxiv)\n",
    "interview_builder.add_node(\"answer_question\", generate_answer)\n",
    "interview_builder.add_node(\"save_interview\", save_interview)\n",
    "interview_builder.add_node(\"write_section\", write_section)\n",
    "\n",
    "# íë¦„ ì„¤ì •\n",
    "interview_builder.add_edge(START, \"ask_question\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_web\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_arxiv\")\n",
    "interview_builder.add_edge(\"search_web\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_arxiv\", \"answer_question\")\n",
    "interview_builder.add_conditional_edges(\n",
    "    \"answer_question\", route_messages, [\"ask_question\", \"save_interview\"]\n",
    ")\n",
    "interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
    "interview_builder.add_edge(\"write_section\", END)\n",
    "\n",
    "# ì¸í„°ë·° ê·¸ë˜í”„ ìƒì„±\n",
    "memory = MemorySaver()\n",
    "interview_graph = interview_builder.compile(checkpointer=memory).with_config(\n",
    "    run_name=\"Conduct Interviews\"\n",
    ")\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹œê°í™”\n",
    "visualize_graph(interview_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7bbf7293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analyst(affiliation='Stanford University, Department of Computer Science', name='Dr. Lilian Park', role='AI Researcher and RAG Methodology Specialist', description='Dr. Park focuses on the technical evolution of Retrieval-Augmented Generation (RAG) methods. Her work dissects the architectural improvements brought by modular RAG over naive RAG, analyzing the implications for scalability, maintainability, and the integration of domain-specific modules.')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¶„ì„ê°€ ëª©ë¡ì—ì„œ ì²« ë²ˆì§¸ ë¶„ì„ê°€ ì„ íƒ\n",
    "analysts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b6fe55",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ ì‹¤í–‰\n",
    "\n",
    "ì´ì œ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0672f652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mask_question\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ê¸°ìˆ  ì „ë¬¸ ë§¤ì²´ì˜ ë°ì´í„° ê¸°ìì¸ ë¯¼ì§€ ì•„ì´ë¼ê³  í•©ë‹ˆë‹¤. ì˜¤ëŠ˜ Modular RAGì™€ Naive RAGì˜ ì°¨ì´, ê·¸ë¦¬ê³  ì‹¤ë¬´ì—ì„œ Modular RAGë¥¼ ì‚¬ìš©í•  ë•Œ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì´ì ì´ ìˆëŠ”ì§€ ì—¬ì­¤ë³´ê³  ì‹¶ì–´ì„œ ì¸í„°ë·°ë¥¼ ìš”ì²­ë“œë ¸ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì²« ì§ˆë¬¸ë¶€í„° ë“œë¦¬ìë©´, \"Naive RAG\"ê°€ ê¸°ë³¸ì ìœ¼ë¡œ ë‹¨ì¼ ê²€ìƒ‰ê¸°(retriever)ì™€ ìƒì„±ê¸°(generator)ë¥¼ ì—°ê²°í•œ êµ¬ì¡°ë¡œ ì•Œë ¤ì ¸ ìˆëŠ”ë°, Dr. Parkê»˜ì„œ Modular RAGë¥¼ ì—°êµ¬í•˜ì‹œë©° ë³´ì‹  ëšœë ·í•œ êµ¬ì¡°ì  ì°¨ì´ë‚˜ ê°œì„ ì ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆì„ê¹Œìš”? ì‹¤ì œë¡œ ì–´ë–¤ ì‹ìœ¼ë¡œ ëª¨ë“ˆí™”ê°€ ì´ë£¨ì–´ì§€ëŠ”ì§€, ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_web\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document href=\"https://www.ibm.com/think/topics/rag-techniques\"/>\n",
      "While naive RAG is straightforward and quick, modular RAGâ€”often built with frameworks such as LangChainâ€”provides enhanced flexibility, scalability and\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
      "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. By adopting a modular architecture, this approach addresses the limitations of Naive RAG, offering enhanced flexibility, scalability, and efficiency. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. * *Seamless Integration*: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.superteams.ai/blog/how-to-implement-naive-rag-advanced-rag-and-modular-rag\"/>\n",
      "Naive RAG is a paradigm that combines information retrieval with natural language generation to produce responses to queries or prompts.\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_arxiv\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"http://arxiv.org/abs/2508.05650v1\" date=\"2025-07-26\" authors=\"Jiaxuan Liang, Shide Zhou, Kailong Wang\"/>\n",
      "<Title>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "While Retrieval Augmented Generation (RAG) is now widely adopted to enhance\n",
      "LLMs, evaluating its true performance benefits in a reproducible and\n",
      "interpretable way remains a major hurdle. Existing methods often fall short:\n",
      "they lack domain coverage, employ coarse metrics that miss sub document\n",
      "precision, and fail to capture computational trade offs. Most critically, they\n",
      "provide no standardized framework for comparing RAG effectiveness across\n",
      "different models and domains.\n",
      "  We introduce OmniBench RAG, a novel automated platform for multi domain\n",
      "evaluation of RAG systems. The platform quantifies performance gains across\n",
      "accuracy and efficiency dimensions, spanning nine knowledge fields including\n",
      "culture, geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency differences\n",
      "between pre RAG and post RAG models), enabling reproducible comparisons across\n",
      "models and tasks. The platform features dynamic test generation, modular\n",
      "evaluation pipelines, and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant gains in\n",
      "culture to declines in mathematics, highlighting the critical importance of\n",
      "systematic, domain aware assessment. A demonstration video is available at:\n",
      "https://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets:\n",
      "https://github.com/Garnett-Liang/Omnibench-RAG.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation\n",
      "Platform for Retrieval-Augmented Generation Tools\n",
      "Jiaxuan Liang*, Shide Zhou*, and Kailong Wangâ€ \n",
      "Huazhong University of Science and Technology\n",
      "{liangjx, shidez, wangkl}@hust.edu.cn\n",
      "Abstractâ€”While Retrieval Augmented Generation (RAG) is\n",
      "now widely adopted to enhance LLMs, evaluating its true\n",
      "performance benefits in a reproducible and interpretable way\n",
      "remains a major hurdle. Existing methods often fall short: they\n",
      "lack domain coverage, employ coarse metrics that miss sub\n",
      "document precision, and fail to capture computational trade\n",
      "offs. Most critically, they provide no standardized framework\n",
      "for comparing RAG effectiveness across different models and\n",
      "domains.\n",
      "We introduce OmniBench RAG, a novel automated platform\n",
      "for multi domain evaluation of RAG systems. The platform\n",
      "quantifies performance gains across accuracy and efficiency\n",
      "dimensions, spanning nine knowledge fields including culture,\n",
      "geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency\n",
      "differences between pre RAG and post RAG models), enabling\n",
      "reproducible comparisons across models and tasks. The platform\n",
      "features dynamic test generation, modular evaluation pipelines,\n",
      "and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant\n",
      "gains in culture to declines in mathematics, highlighting the\n",
      "critical importance of systematic, domain aware assessment. A\n",
      "demonstration video is available at: https://www.youtube.com/\n",
      "watch?v=BZx83QFcTCI. Code and datasets: https://github.com/\n",
      "Garnett-Liang/Omnibench-RAG.\n",
      "I. INTRODUCTION\n",
      "Retrieval-Augmented Generation (RAG) is a key technique\n",
      "for enhancing Large Language Models (LLMs) [1], [2]. By\n",
      "grounding model responses in external, verifiable knowledge,\n",
      "RAG promises to mitigate hallucinations [3], improve factual\n",
      "accuracy [4], and provide up-to-date information [5]. However,\n",
      "the true effectiveness of RAG is far from uniform. Recent\n",
      "studies [6], [7] reveal a significant disparity: while RAG\n",
      "can boost the accuracy of smaller models like Llama-3.2-3B-\n",
      "Instruct by as much as 38.12%, its impact on state-of-the-art\n",
      "models such as GPT-4o, which excel with extended context\n",
      "windows, is often less pronounced. This variability, which\n",
      "depends not only on the modelâ€™s scale but also heavily on\n",
      "the knowledge domain, underscores a critical challenge: the\n",
      "lack of a systematic platform to quantify the value of RAG\n",
      "across these diverse contexts.\n",
      "Current RAG evaluation approaches suffer from fundamen-\n",
      "tal limitations that impede reproducible and comprehensive as-\n",
      "sessment: First, they lack automated multi-domain evalua-\n",
      "tion capabilities and rely on non-deterministic components.\n",
      "*Jiaxuan Liang and Shide Zhou are co-first authors.\n",
      "â€ Kailong Wang is the corresponding author.\n",
      "Existing benchmarks typically require manual configuration\n",
      "for each knowledge domain and fail to provide unified assess-\n",
      "ment across diverse fields like finance, healthcare, or culture,\n",
      "making cross-domain performance analysis labor-intensive and\n",
      "inconsistent. Moreover, key metrics in leading frameworks\n",
      "(e.g., LLM-based scoring in Ragas [8]) inadvertently introduce\n",
      "randomness due to reliance on large language models in the\n",
      "evaluation loop, undermining result reproducibility. Second,\n",
      "they employ static datasets and coarse-grained metrics.\n",
      "Most frameworks rely on fixed benchmarks and document-\n",
      "level retrieval metrics (e.g., MRR@k[9]), missing the critical\n",
      "sub-document precision needed to assess whether models\n",
      "extract specific facts accurately. They also lack the ability to\n",
      "dynamically generate test cases that probe complex reasoning\n",
      "patterns. Third, they fail to capture the computational\n",
      "trade-offs inherent in RAG systems. Without automated\n",
      "profiling of resource utilization and efficiency metrics, practi-\n",
      "tioners cannot make informed decisions about the cost-benefit\n",
      "trade-offs of deploying RAG in production environments.\n",
      "Our \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2502.11228v2\" date=\"2025-05-22\" authors=\"Mohammad Reza Rezaei, Adji Bousso Dieng\"/>\n",
      "<Title>\n",
      "Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\n",
      "for domain-specific question-answering (QA) tasks by leveraging external\n",
      "knowledge sources. However, traditional RAG systems primarily focus on\n",
      "relevance-based retrieval and often struggle with redundancy, especially when\n",
      "reasoning requires connecting information from multiple sources. This paper\n",
      "introduces Vendi-RAG, a framework based on an iterative process that jointly\n",
      "optimizes retrieval diversity and answer quality. This joint optimization leads\n",
      "to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\n",
      "the Vendi Score (VS), a flexible similarity-based diversity metric, to promote\n",
      "semantic diversity in document retrieval. It then uses an LLM judge that\n",
      "evaluates candidate answers, generated after a reasoning step, and outputs a\n",
      "score that the retriever uses to balance relevance and diversity among the\n",
      "retrieved documents during each iteration. Experiments on three challenging\n",
      "datasets -- HotpotQA, MuSiQue, and 2WikiMultiHopQA -- demonstrate Vendi-RAG's\n",
      "effectiveness in multi-hop reasoning tasks. The framework achieves significant\n",
      "accuracy improvements over traditional single-step and multi-step RAG\n",
      "approaches, with accuracy increases reaching up to +4.2% on HotpotQA, +4.1% on\n",
      "2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the current\n",
      "best baseline. The benefits of Vendi-RAG are even more pronounced as the number\n",
      "of retrieved documents increases. Finally, we evaluated Vendi-RAG across\n",
      "different LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini, and\n",
      "observed consistent improvements, demonstrating that the framework's advantages\n",
      "are model-agnostic.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "Vendi-RAG: Adaptively Trading-Off Diversity And\n",
      "Quality Significantly Improves Retrieval\n",
      "Augmented Generation With LLMs\n",
      "Mohammad R. Rezaei1, 3 and Adji Bousso Dieng2, 3\n",
      "1Institute of Biomedical Engineering, University of Toronto\n",
      "2Department of Computer Science, Princeton University\n",
      "3Vertaix\n",
      "May 26, 2025\n",
      "Abstract\n",
      "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\n",
      "for domain-specific question-answering (QA) tasks by leveraging external\n",
      "knowledge sources. However, traditional RAG systems primarily focus on\n",
      "relevance-based retrieval and often struggle with redundancy, especially when\n",
      "reasoning requires connecting information from multiple sources. This paper\n",
      "introduces Vendi-RAG, a framework based on an iterative process that jointly\n",
      "optimizes retrieval diversity and answer quality. This joint optimization leads\n",
      "to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\n",
      "the Vendi Score (VS), a flexible similarity-based diversity metric, to promote\n",
      "semantic diversity in document retrieval. It then uses an LLM judge that eval-\n",
      "uates candidate answers, generated after a reasoning step, and outputs a\n",
      "score that the retriever uses to balance relevance and diversity among the\n",
      "retrieved documents during each iteration. Experiments on three challenging\n",
      "datasetsâ€”HotpotQA, MuSiQue, and 2WikiMultiHopQAâ€”demonstrate Vendi-\n",
      "RAGâ€™s effectiveness in multi-hop reasoning tasks. The framework achieves sig-\n",
      "nificant accuracy improvements over traditional single-step or multi-step RAG\n",
      "approaches, with accuracy increases reaching +4.2% on HotpotQA, +4.1% on\n",
      "2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the\n",
      "current best baseline. The benefits of Vendi-RAG are even more pronounced as\n",
      "the number of retrieved documents increases. Finally, we evaluated Vendi-RAG\n",
      "across different LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini,\n",
      "and observed consistent improvements, demonstrating that the frameworkâ€™s\n",
      "advantages are model-agnostic.\n",
      "Keywords: RAG, LLMs, Question Answering, NLP, Diversity, Vendi Scoring\n",
      "1\n",
      "Introduction\n",
      "Retrieval-augmented generation (RAG) has emerged as a transformative framework\n",
      "for enhancing the performance of large language models (LLMs) in domain-specific\n",
      "tasks such as question-answering (QA). By retrieving relevant information from\n",
      "external sources beyond the training set, RAG enables LLMs to answer specialized\n",
      "1\n",
      "arXiv:2502.11228v2  [cs.CL]  22 May 2025\n",
      "Retrieval\n",
      "Query\n",
      "Answer\n",
      "LLM Judge \n",
      "Quality Check\n",
      "Rewritten  \n",
      "Query\n",
      "Final \n",
      "Answer\n",
      "Vendi Score\n",
      "Vendi Score\n",
      "Diversity  \n",
      "weight s\n",
      "Decision Block \n",
      "s > threshold Thr \n",
      "Iteration < N\n",
      "â€¦\n",
      "Reasoning\n",
      "Figure 1: The process begins with an initial retrieval step, where a diverse set of\n",
      "documents is retrieved using the Vendi Score, ensuring broad semantic coverage.\n",
      "Next, leveraging a reasoning step to construct a coherent path to the final answer,\n",
      "the LLM generates an answer, which then undergoes quality assessment by an LLM\n",
      "judge. Based on the answer quality, the retriever is adjusted to balance diversity and\n",
      "relevance: high-quality answers limit the emphasis on diversity, while low-quality\n",
      "answers prompt the retriever to prioritize diversity more heavily. This adjustment\n",
      "is controlled by an adaptive parameter, s, which is updated over iterations. The\n",
      "process continues until the answer quality reaches an optimal threshold, denoted\n",
      "by Thr. Finally, the highest-quality responses and documents are selected, ensuring\n",
      "both diversity and accuracy.\n",
      "queries more effectively Achiam et al. (2023); Team et al. (2023); Jiang et al. (2024).\n",
      "This approach has been particularly successful in single-hop QA, where a question\n",
      "can be answered using information from a single document Raiaan et al. (2024);\n",
      "Kwiatkowski et al. (2019). For instance, answering a question such as \"Who wrote\n",
      "the novel Frankenstein?\" only requires retrieving relevant information from a single\n",
      "document containing this fact.\n",
      "However, multi-hop QA introduces significantly greater complexit\n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstractâ€”Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of â€œretrieve-then-generateâ€. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patternsâ€”linear, conditional,\n",
      "branching, and loopingâ€”and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Termsâ€”Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]â€“[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLMâ€™s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manswer_question\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: expert\n",
      "\n",
      "ë„¤, Modular RAGëŠ” ê¸°ì¡´ì˜ Naive RAGì™€ ì—¬ëŸ¬ ì¸¡ë©´ì—ì„œ ê·¼ë³¸ì ì¸ ì°¨ì´ê°€ ìˆìœ¼ë©°, íŠ¹íˆ production(ì‹¤ì„œë¹„ìŠ¤) í™˜ê²½ì—ì„œ ì¤‘ìš”í•œ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "**1. êµ¬ì¡°ì  ì°¨ì´**\n",
      "- **Naive RAG**ëŠ” \"retrieve-then-generate\"ë¼ëŠ” ë‹¨ìˆœí•œ ì§ë ¬ êµ¬ì¡°ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ì¦‰, ì™¸ë¶€ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰(retrieve)í•˜ê³ , í•´ë‹¹ ê²°ê³¼ë¥¼ LLM(ìƒì„± ëª¨ë¸)ì— ì…ë ¥í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ í”„ë¡œì„¸ìŠ¤ëŠ” í•˜ë‚˜ì˜ ì¼ì§ì„  íŒŒì´í”„ë¼ì¸ì´ë©°, ê²€ìƒ‰-ìƒì„± ë‹¨ê³„ë¥¼ ë¶„ë¦¬í•˜ê±°ë‚˜ í™•ì¥í•˜ëŠ” ë° í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ì¦‰, retrievalê³¼ generationì„ í•˜ë‚˜ì˜ ê³ ì •ëœ, ìœ ì—°í•˜ì§€ ì•Šì€ íë¦„ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤ [4][5].\n",
      "- **Modular RAG**ëŠ” RAG ì‹œìŠ¤í…œì„ ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì´ê³  êµì²´ ê°€ëŠ¥í•œ â€œëª¨ë“ˆâ€ë¡œ ë¶„í•´í•©ë‹ˆë‹¤. ê° ëª¨ë“ˆ(ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ì–‘í•œ typeì˜ retriever, ranker, router, ì¡°ê±´ë¶€ ë¶„ê¸°, ë£¨í”„ ë“±)ì€ íŠ¹ì • ì—­í• ì„ ë‹´ë‹¹í•˜ë©°, í•„ìš”ì— ë”°ë¼ ì¶”ê°€Â·ì‚­ì œÂ·êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ëª¨ë“ˆ ì‚¬ì´ì˜ routing, scheduling, fusion ë“± ê³ ê¸‰ ë©”ì»¤ë‹ˆì¦˜ì´ ë„ì…ë˜ì–´ ë‹¤ì–‘í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¡œì¨ linearí•œ êµ¬ì¡°ë¿ ì•„ë‹ˆë¼ conditional(ì¡°ê±´ë¶€), branching(ë¶„ê¸°), looping(ë°˜ë³µ) ë“± ë³µì¡í•œ ì²˜ë¦¬ íŒ¨í„´ì„ íŒ¨ëŸ¬ë‹¤ì„ ìˆ˜ì¤€ì—ì„œ ì§€ì›í•©ë‹ˆë‹¤ [3][5].\n",
      "\n",
      "**2. Production í™˜ê²½ì—ì„œì˜ ì´ì **\n",
      "- **ìœ ì—°ì„± ë° í™•ì¥ì„±**: Naive RAGëŠ” ë³€í™”ê°€ í•„ìš”í•œ ê²½ìš° ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ìˆ˜ì •í•´ì•¼ í•˜ì§€ë§Œ, Modular RAGëŠ” ê° ëª¨ë“ˆë§Œ êµì²´Â·ì—…ë°ì´íŠ¸í•˜ë©´ ë˜ë¯€ë¡œ ìƒˆë¡œìš´ ë„ë©”ì¸ ì ìš©, retriever êµì²´, LLM êµì²´ ë“± ìœ ì§€ë³´ìˆ˜ê°€ í›¨ì”¬ ìˆ˜ì›”í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ì¿¼ë¦¬ì—ë§Œ ë³„ë„ì˜ ë­í‚¹ ëª¨ë“ˆì´ë‚˜ ì •ì œ ëª¨ë“ˆì„ ë¶™ì´ëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤ [3][5].\n",
      "- **íš¨ìœ¨ì„± í–¥ìƒ**: ë¶ˆí•„ìš”í•œ ì •ë³´ì˜ íë¦„ì„ í†µì œí•˜ê³ , ë¼ìš°íŒ…ì´ë‚˜ ë¶„ê¸°ì²˜ë¦¬ë¥¼ í†µí•´ ì—°ì‚° íš¨ìœ¨ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì¿¼ë¦¬ ì„±ê²©ì— ë”°ë¼ ë” ì •êµí•œ retrieverë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒí•˜ê±°ë‚˜, ë°˜ë³µ ë£¨í”„ë¥¼ í†µí•´ multi-hop reasoning êµ¬ì¡°ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ [3].\n",
      "- **ë„ë©”ì¸ íŠ¹í™” ë° ìœ ì§€ê´€ë¦¬ ìš©ì´ì„±**: ê° ë„ë©”ì¸ë§ˆë‹¤ íŠ¹í™”ëœ retrieval/generation ëª¨ë“ˆì„ ì¶”ê°€ì , ë…ë¦½ì ìœ¼ë¡œ ê°œë°œÂ·ë°°í¬í•  ìˆ˜ ìˆì–´ ë©€í‹°ë„ë©”ì¸ ì‹œìŠ¤í…œ êµ¬ì„± ë° ë¹ ë¥¸ ìˆ˜ì •Â·í™•ì¥ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ [5].\n",
      "- **ì‹¤ì„œë¹„ìŠ¤ì˜ ì‹ ë¢°ì„±ê³¼ ì¬í˜„ì„± ê°•í™”**: ì‹œìŠ¤í…œì´ ëª…í™•í•œ ëª¨ë“ˆ ë‹¨ìœ„ë¡œ ë‚˜ë‰˜ì–´ ìˆê¸° ë•Œë¬¸ì—, ê° ìš”ì†Œì˜ ì„±ëŠ¥ í‰ê°€ì™€ ë””ë²„ê¹…ì´ ìš©ì´í•˜ê³ , ì˜¤ë¥˜ê°€ ìƒê²¼ì„ ë•Œ íŠ¹ì • ëª¨ë“ˆë§Œ ìˆ˜ì •í•˜ë©´ ë˜ì–´ ìš´ì˜ ì•ˆì •ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ê°€ ë›°ì–´ë‚©ë‹ˆë‹¤ [3][5].\n",
      "\n",
      "ìš”ì•½í•˜ìë©´, Modular RAGëŠ” ê¸°ì¡´ì˜ ì¼ì§ì„ ì ì´ê³  íì‡„ì ì¸ Naive RAG êµ¬ì¡°ë¥¼ ë‹¤ì–‘í•œ êµ¬ì„±ìš”ì†Œë¡œ ë¶„í•´í•˜ì—¬, ìœ ì—°ì„±, í™•ì¥ì„±, ê·¸ë¦¬ê³  ìœ ì§€ê´€ë¦¬ ì¸¡ë©´ì—ì„œ ì‹¤ë¬´ í™˜ê²½ì— í›¨ì”¬ ì í•©í•œ êµ¬ì¡°ë¡œ ì§„í™”ì‹œì¼°ë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "**Sources**  \n",
      "[3] http://arxiv.org/abs/2407.21059v1  \n",
      "[4] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mask_question\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ê°ì‚¬í•©ë‹ˆë‹¤, ë§¤ìš° ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì…”ì„œ ì´í•´ê°€ ì˜ ë©ë‹ˆë‹¤!  \n",
      "ë§ì”€í•´ì£¼ì‹  ëª¨ë“ˆ ë‹¨ìœ„ì˜ êµì²´/í™•ì¥ì„±ê³¼ ë„ë©”ì¸ íŠ¹í™” ì˜ˆì‹œê°€ ì •ë§ ì¸ìƒì ì´ì—ˆëŠ”ë°ìš”,  \n",
      "ì¡°ê¸ˆ ë” êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì—¬ì­¤ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ì‹¤ì œ Modular RAGê°€ ì‚¬ìš©ëœ ì‚¬ë¡€ë‚˜ Dr. Parkê»˜ì„œ ì‹¤í—˜í•˜ì…¨ë˜ ê²½í—˜ ì¤‘ì—,  \n",
      "\"ë‹¨ì¼ retriever ì‹œìŠ¤í…œì—ì„œ íŠ¹ì • ì§ˆì˜ì— í•œí•´ì„œ ìƒˆë¡œìš´ retriever(ì˜ˆ: ë²•ë¥ , ì˜ë£Œ ë“± ì „ë¬¸ ë„ë©”ì¸)ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ê¸°ì¡´ ëª¨ë“ˆì„ êµì²´í•˜ì—¬ ì–»ì€ íš¨ê³¼\"ê°€ ìˆì—ˆë˜ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?  \n",
      "\n",
      "ë§Œì•½ ìˆë‹¤ë©´,  \n",
      "- ë„ë©”ì¸ íŠ¹í™” retrieverë¥¼ ì¶”ê°€í–ˆì„ ë•Œ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¬¸ì œ(ì˜ˆ: recall ë¶€ì¡±, hallucination ë“±)ê°€ ê°œì„ ëëŠ”ì§€  \n",
      "- ì‹¤ì œë¡œ ì–´ë–¤ íŒŒì´í”„ë¼ì¸ í˜¹ì€ ì›Œí¬í”Œë¡œìš° ë³€í™”ê°€ ìˆì—ˆëŠ”ì§€  \n",
      "- ê¸°ì¡´ Naive êµ¬ì¡°ì—ì„œëŠ” ë¶ˆê°€ëŠ¥í•˜ê±°ë‚˜ ë¹„íš¨ìœ¨ì ì´ì—ˆì„ ì \n",
      "\n",
      "ì´ëŸ° ë¶€ë¶„ì„ ì˜ˆë¡œ ë“¤ì–´ ì„¤ëª…í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_arxiv\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstractâ€”Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of â€œretrieve-then-generateâ€. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patternsâ€”linear, conditional,\n",
      "branching, and loopingâ€”and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Termsâ€”Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]â€“[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLMâ€™s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2312.10997v5\" date=\"2024-03-27\" authors=\"Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Retrieval-Augmented Generation for Large Language Models: A Survey\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Large Language Models (LLMs) showcase impressive capabilities but encounter\n",
      "challenges like hallucination, outdated knowledge, and non-transparent,\n",
      "untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\n",
      "emerged as a promising solution by incorporating knowledge from external\n",
      "databases. This enhances the accuracy and credibility of the generation,\n",
      "particularly for knowledge-intensive tasks, and allows for continuous knowledge\n",
      "updates and integration of domain-specific information. RAG synergistically\n",
      "merges LLMs' intrinsic knowledge with the vast, dynamic repositories of\n",
      "external databases. This comprehensive review paper offers a detailed\n",
      "examination of the progression of RAG paradigms, encompassing the Naive RAG,\n",
      "the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\n",
      "tripartite foundation of RAG frameworks, which includes the retrieval, the\n",
      "generation and the augmentation techniques. The paper highlights the\n",
      "state-of-the-art technologies embedded in each of these critical components,\n",
      "providing a profound understanding of the advancements in RAG systems.\n",
      "Furthermore, this paper introduces up-to-date evaluation framework and\n",
      "benchmark. At the end, this article delineates the challenges currently faced\n",
      "and points out prospective avenues for research and development.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Retrieval-Augmented Generation for Large\n",
      "Language Models: A Survey\n",
      "Yunfan Gaoa, Yun Xiongb, Xinyu Gaob, Kangxiang Jiab, Jinliu Panb, Yuxi Bic, Yi Daia, Jiawei Suna, Meng\n",
      "Wangc, and Haofen Wang a,c\n",
      "aShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\n",
      "bShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\n",
      "cCollege of Design and Innovation, Tongji University\n",
      "Abstractâ€”Large Language Models (LLMs) showcase impres-\n",
      "sive capabilities but encounter challenges like hallucination,\n",
      "outdated knowledge, and non-transparent, untraceable reasoning\n",
      "processes. Retrieval-Augmented Generation (RAG) has emerged\n",
      "as a promising solution by incorporating knowledge from external\n",
      "databases. This enhances the accuracy and credibility of the\n",
      "generation, particularly for knowledge-intensive tasks, and allows\n",
      "for continuous knowledge updates and integration of domain-\n",
      "specific information. RAG synergistically merges LLMsâ€™ intrin-\n",
      "sic knowledge with the vast, dynamic repositories of external\n",
      "databases. This comprehensive review paper offers a detailed\n",
      "examination of the progression of RAG paradigms, encompassing\n",
      "the Naive RAG, the Advanced RAG, and the Modular RAG.\n",
      "It meticulously scrutinizes the tripartite foundation of RAG\n",
      "frameworks, which includes the retrieval, the generation and the\n",
      "augmentation techniques. The paper highlights the state-of-the-\n",
      "art technologies embedded in each of these critical components,\n",
      "providing a profound understanding of the advancements in RAG\n",
      "systems. Furthermore, this paper introduces up-to-date evalua-\n",
      "tion framework and benchmark. At the end, this article delineates\n",
      "the challenges currently faced and points out prospective avenues\n",
      "for research and development 1.\n",
      "Index Termsâ€”Large language model, retrieval-augmented gen-\n",
      "eration, natural language processing, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE language models (LLMs) have achieved remark-\n",
      "able success, though they still face significant limitations,\n",
      "especially in domain-specific or knowledge-intensive tasks [1],\n",
      "notably producing â€œhallucinationsâ€ [2] when handling queries\n",
      "beyond their training data or requiring current information. To\n",
      "overcome challenges, Retrieval-Augmented Generation (RAG)\n",
      "enhances LLMs by retrieving relevant document chunks from\n",
      "external knowledge base through semantic similarity calcu-\n",
      "lation. By referencing external knowledge, RAG effectively\n",
      "reduces the problem of generating factually incorrect content.\n",
      "Its integration into LLMs has resulted in widespread adoption,\n",
      "establishing RAG as a key technology in advancing chatbots\n",
      "and enhancing the suitability of LLMs for real-world applica-\n",
      "tions.\n",
      "RAG technology has rapidly developed in recent years, and\n",
      "the technology tree summarizing related research is shown\n",
      "Corresponding Author.Email:haofen.wang@tongji.edu.cn\n",
      "1Resources\n",
      "are\n",
      "available\n",
      "at\n",
      "https://github.com/Tongji-KGLLM/\n",
      "RAG-Survey\n",
      "in Figure 1. The development trajectory of RAG in the era\n",
      "of large models exhibits several distinct stage characteristics.\n",
      "Initially, RAGâ€™s inception coincided with the rise of the\n",
      "Transformer architecture, focusing on enhancing language\n",
      "models by incorporating additional knowledge through Pre-\n",
      "Training Models (PTM). This early stage was characterized\n",
      "by foundational work aimed at refining pre-training techniques\n",
      "[3]â€“[5].The subsequent arrival of ChatGPT [6] marked a\n",
      "pivotal moment, with LLM demonstrating powerful in context\n",
      "learning (ICL) capabilities. RAG research shifted towards\n",
      "providing better information for LLMs to answer more com-\n",
      "plex and knowledge-intensive tasks during the inference stage,\n",
      "leading to rapid development in RAG studies. As research\n",
      "progressed, the enhancement of RAG was no longer limited\n",
      "to the inference stage but began to incorporate more with LLM\n",
      "fine-tuning techniques.\n",
      "The burgeoning field of RAG has experienced swift growth,\n",
      "yet it has not been accompanied by a systematic synthesis that\n",
      "could clarify its broader trajectory. Thi\n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2408.05933v1\" date=\"2024-08-12\" authors=\"Fei Liu, Zejun Kang, Xing Han\"/>\n",
      "<Title>\n",
      "Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "With the growing demand for offline PDF chatbots in automotive industrial\n",
      "production environments, optimizing the deployment of large language models\n",
      "(LLMs) in local, low-performance settings has become increasingly important.\n",
      "This study focuses on enhancing Retrieval-Augmented Generation (RAG) techniques\n",
      "for processing complex automotive industry documents using locally deployed\n",
      "Ollama models. Based on the Langchain framework, we propose a multi-dimensional\n",
      "optimization approach for Ollama's local RAG implementation. Our method\n",
      "addresses key challenges in automotive document processing, including\n",
      "multi-column layouts and technical specifications. We introduce improvements in\n",
      "PDF processing, retrieval mechanisms, and context compression, tailored to the\n",
      "unique characteristics of automotive industry documents. Additionally, we\n",
      "design custom classes supporting embedding pipelines and an agent supporting\n",
      "self-RAG based on LangGraph best practices. To evaluate our approach, we\n",
      "constructed a proprietary dataset comprising typical automotive industry\n",
      "documents, including technical reports and corporate regulations. We compared\n",
      "our optimized RAG model and self-RAG agent against a naive RAG baseline across\n",
      "three datasets: our automotive industry dataset, QReCC, and CoQA. Results\n",
      "demonstrate significant improvements in context precision, context recall,\n",
      "answer relevancy, and faithfulness, with particularly notable performance on\n",
      "the automotive industry dataset. Our optimization scheme provides an effective\n",
      "solution for deploying local RAG systems in the automotive sector, addressing\n",
      "the specific needs of PDF chatbots in industrial production environments. This\n",
      "research has important implications for advancing information processing and\n",
      "intelligent production in the automotive industry.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with \n",
      "Locally Deployed Ollama Models \n",
      "Optimizing RAG Techniques Based on Locally Deployed Ollama Models \n",
      "A Case Study with Locally Deployed Ollama Models \n",
      "Fei Liu * \n",
      "China Automotive Technology & Research Center, liufei@catarc.ac.cn \n",
      "Zejun Kang \n",
      "China Automotive Technology & Research Center, kangzejun@catarc.ac.cn \n",
      "Xing Han \n",
      "China Automotive Technology & Research Center, hanxing@catarc.ac.cn \n",
      "With the growing demand for offline PDF chatbots in automotive industrial production environments, optimizing the deployment \n",
      "of large language models (LLMs) in local, low-performance settings has become increasingly important. This study focuses on \n",
      "enhancing Retrieval-Augmented Generation (RAG) techniques for processing complex automotive industry documents using \n",
      "locally deployed Ollama models. \n",
      "Based on the Langchain framework, we propose a multi-dimensional optimization approach for Ollama's local RAG \n",
      "implementation. Our method addresses key challenges in automotive document processing, including multi-column layouts and \n",
      "technical specifications. We introduce improvements in PDF processing, retrieval mechanisms, and context compression, tailored \n",
      "to the unique characteristics of automotive industry documents. Additionally, we design custom classes supporting embedding \n",
      "pipelines and an agent supporting self-RAG based on LangGraph best practices. \n",
      "To evaluate our approach, we constructed a proprietary dataset comprising typical automotive industry documents, including \n",
      "technical reports and corporate regulations. We compared our optimized RAG model and self-RAG agent against a naive RAG \n",
      "baseline across three datasets: our automotive industry dataset, QReCC, and CoQA. Results demonstrate significant improvements \n",
      "in context precision, context recall, answer relevancy, and faithfulness, with particularly notable performance on the automotive \n",
      "industry dataset. \n",
      "Our optimization scheme provides an effective solution for deploying local RAG systems in the automotive sector, addressing the \n",
      "specific needs of PDF chatbots in industrial production environments. This research has important implications for advancing \n",
      "information processing and intelligent production in the automotive industry. \n",
      " \n",
      "* Place the footnote text for the author (if applicable) here.  \n",
      "CCS CONCEPTS â€¢ Computing methodologies â€¢ Artificial intelligence â€¢ Natural language processing â€¢ Natural language \n",
      "generation \n",
      " \n",
      "Additional Keywords and Phrases: Automotive Industry, Langchain, self-rag, PDF Processing, RAG, Ollama \n",
      "1 INTRODUCTION \n",
      "1.1 Research Background \n",
      "The automotive industry is undergoing a significant digital transformation, with an increasing reliance on complex \n",
      "technical documentation for various processes [1]. This shift encompasses design, manufacturing, and quality \n",
      "control, all of which now heavily depend on efficient information management systems [2]. The growing volume of \n",
      "technical documents, often in PDF format, has created a pressing need for advanced information retrieval and \n",
      "question-answering capabilities in industrial settings [3]. \n",
      "Large Language Models (LLMs) have emerged as powerful tools in natural language processing, demonstrating \n",
      "remarkable abilities in tasks such as document understanding and question answering [4]. These models have \n",
      "shown potential in handling the complex, domain-specific language often found in automotive documentation. \n",
      "However, the application of LLMs in industrial environments presents unique challenges, particularly in terms of \n",
      "computational resources and data privacy [5]. \n",
      "Among the various techniques developed to enhance LLM performance, Retrieval-Augmented Generation (RAG) \n",
      "has gained significant attention [6]. RAG combines the generative capabilities of LLMs with external knowledge \n",
      "retrieval, allowing for more accurate and contextually relevant responses. This approach, initially proposed by \n",
      "Lew\n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_web\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document href=\"https://velog.io/@shanny8888/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-3-Retrieval-Augmented-Generation-for-Large-Language-Models-A-Survey\"/>\n",
      "ëª¨ë“ˆí˜• RAG(Modular RAG)ëŠ” ì—¬ëŸ¬ ê¸°ëŠ¥ì„ ëª¨ë“ˆí™”í•´ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ë†’ì¸ ìµœì‹  íŒ¨ëŸ¬ë‹¤ì„ì´ë‹¤. ê°ê°ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë°œì „í•˜ê³  ìˆë‹¤. RAGì˜ íš¨ê³¼ì™€\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://g3lu.tistory.com/42\"/>\n",
      "Domain Knowledge Fine-Tuning : ì„ë² ë”© ëª¨ë¸ì´ ê° ë„ë©”ì¸ë³„ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ í¬ì°©í•  ìˆ˜ ìˆë„ë¡, ë„ë©”ì¸ íŠ¹í™” ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ fine-tuningí•œë‹¤.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://blog-ko.superb-ai.com/rag-technology-evolution-naive-advanced-modular-approaches/\"/>\n",
      "ì´ˆê¸° Naive RAGì˜ ë‹¨ìˆœ ë²¡í„° ìœ ì‚¬ë„ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë“±ì¥í•œ Advanced RAGëŠ” ì˜ë¯¸ë¡ ì  ì²­í‚¹, ì¿¼ë¦¬ ìµœì í™”, ë‹¤ì–‘í•œ ê²€ìƒ‰ ë°©ë²•ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. ë”\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manswer_question\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: expert\n",
      "\n",
      "ë„¤, êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ë“¤ì–´ ì„¤ëª…ë“œë¦¬ë©´ Modular RAGì˜ ì¥ì ì´ ë” ì˜ ë“œëŸ¬ë‚©ë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´ ë²•ë¥  ì§ˆì˜ë¥¼ ë‹¤ë£¨ëŠ” QA ì‹œìŠ¤í…œì„ ìš´ì˜í•œë‹¤ê³  ê°€ì •í•´ë³´ê² ìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ Naive RAGì—ì„œëŠ” í•˜ë‚˜ì˜ retrieverë§Œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, ë²•ë¥  ë¬¸ì„œì™€ ì¼ë°˜ ë¬¸ì„œê°€ í˜¼ì¬ëœ ìƒí™©ì—ì„œ ë²•ë¥  íŠ¹í™” ì§ˆì˜ê°€ ë“¤ì–´ì™€ë„ ì¼ë°˜ì ì¸ retrieverê°€ ëª¨ë“  ì§ˆì˜ì— ëŒ€í•´ ë™ì¼í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤. ì´ ê²½ìš°, ì „ë¬¸ ìš©ì–´ ì²˜ë¦¬ë‚˜ ë„ë©”ì¸ íŠ¹ì´ì  ë¬¸ë§¥ ì´í•´ê°€ ë¶€ì¡±í•˜ì—¬ recallì´ ì €í•˜ë˜ê³ , LLMì´ ë¶€ì ì ˆí•˜ê±°ë‚˜ ë¶ˆì™„ì „í•œ ì •ë³´ë¥¼ ì‚¬ìš©í•´ hallucinationì´ ë¹ˆë²ˆí•˜ê²Œ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ [3][4].\n",
      "\n",
      "Modular RAGì—ì„œëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì§ˆì˜ ë¶„ë¥˜ ë¼ìš°í„°(router) ëª¨ë“ˆì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆì‹œ íŒŒì´í”„ë¼ì¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ [3]:\n",
      "\n",
      "1. Input queryê°€ ë“¤ì–´ì˜¤ë©´ ë¼ìš°í„° ëª¨ë“ˆì´ ì§ˆì˜ê°€ â€˜ë²•ë¥  ë„ë©”ì¸â€™ì¸ì§€ â€˜ì¼ë°˜ ë„ë©”ì¸â€™ì¸ì§€ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n",
      "2. ë²•ë¥  ì§ˆì˜ë¼ë©´, ë²•ë¥  íŠ¹í™” retrieverë¡œ ë¼ìš°íŒ…í•´ ë²•ë¥  ë¬¸ì„œì— ë§ëŠ” ê²€ìƒ‰ ë° ë­í‚¹ì„ ìˆ˜í–‰í•˜ê³ , ìƒì„± ëª¨ë“ˆë¡œ ë„˜ê¹ë‹ˆë‹¤.\n",
      "3. ì¼ë°˜ ì§ˆì˜ë¼ë©´ ê¸°ì¡´ retrieverë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "4. (ì„ íƒì ) ì¶”ê°€ë¡œ domain-specific rankerë‚˜ post-processing fusion ëª¨ë“ˆì„ ì‚½ì…í•´ ìµœì¢…ì ìœ¼ë¡œ ë” ë†’ì€ ì •ë°€ë„ì˜ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ êµ¬ì¡°ë¥¼ ì ìš©í•˜ë©´, ê¸°ì¡´ Naive RAGì—ì„œ ë¬¸ì œì˜€ë˜ ì „ë¬¸ ì§ˆì˜ì˜ recall ë¶€ì¡±ê³¼ ë¯¸ìŠ¤ë§¤ì¹˜ í˜„ìƒì´ í¬ê²Œ ì¤„ì–´ë“­ë‹ˆë‹¤. ë˜í•œ, hallucination ì—­ì‹œ ì¤„ì–´ë“œëŠ”ë°, ì´ëŠ” ë²•ë¥  retrieverê°€ ì •í™•í•œ ë¬¸ì„œë§Œì„ ì œê³µí•˜ê³ , ë¶ˆí•„ìš”í•œ ë°ì´í„°ë¥¼ LLMì— ë„˜ê¸°ì§€ ì•Šê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì‹¤ì œë¡œ [3]ì˜ Modular RAG ì—°êµ¬ì—ì„œëŠ” ì´ëŸ¬í•œ ë¶„ê¸°(branching) ë° ì¡°ê±´(route) ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°ê°€ ë™ì¼ íŒŒì´í”„ë¼ì¸ì—ì„œ ë„ë©”ì¸ ì í•©ì„±ì„ ê·¹ëŒ€í™”í•˜ë©°, ë©€í‹°ë„ë©”ì¸ QA, í—¬ìŠ¤ì¼€ì–´, ê³ ê° ì§€ì› ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì ìš© ê°€ëŠ¥í•¨ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "Naive RAGì—ì„œëŠ” ì´ëŸ¬í•œ ëª¨ë“ˆ í™•ì¥Â·êµì²´ê°€ ë§¤ìš° ì–´ë µê±°ë‚˜ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ ì „ì²´ë¥¼ ìˆ˜ì •í•´ì•¼ í•˜ê³ , ë¹„ìŠ·í•œ ê¸°ëŠ¥ì„ ì—¬ëŸ¬ ë²ˆ ì¤‘ë³µ êµ¬í˜„í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë©´ Modular RAGëŠ” ìƒˆë¡œìš´ ëª¨ë“ˆì„ â€œë ˆê³  ë¸”ëŸ­â€ì²˜ëŸ¼ ë¶™ì´ê±°ë‚˜ êµì²´í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìš´ì˜ ë° ìœ ì§€ë³´ìˆ˜ê°€ í›¨ì”¬ ì‰¬ì›Œì§‘ë‹ˆë‹¤ [3][4][5].\n",
      "\n",
      "**ì •ë¦¬**  \n",
      "- ë„ë©”ì¸ íŠ¹í™” retriever ì¶”ê°€/êµì²´ â†’ recall ë° ë‹µë³€ ì •í™•ë„, ì‹ ë¢°ì„±(ë¹„hallucination) ê°œì„   \n",
      "- ë¶„ê¸°/ë¼ìš°íŒ… ëª¨ë“ˆ ì ìš© â†’ ë„ë©”ì¸ë³„ ìµœì í™” ì›Œí¬í”Œë¡œìš° êµ¬ì¶• ê°€ëŠ¥  \n",
      "- Naive RAG ëŒ€ë¹„ maintenance, í™•ì¥ì„±, ì¬ì‚¬ìš©ì„± ìš°ìœ„\n",
      "\n",
      "---\n",
      "[3] http://arxiv.org/abs/2407.21059v1  \n",
      "[4] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mask_question\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ê°ì‚¬í•©ë‹ˆë‹¤! ì´ë ‡ê²Œ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¡œ ì„¤ëª…í•´ì£¼ì‹œë‹ˆ, íŠ¹íˆ â€œë¼ìš°í„° ëª¨ë“ˆ ì‚½ì…â€ ì´í›„ ë°œìƒí•œ ê°œì„ ì ë“¤ì´ ëª…í™•í•˜ê²Œ ì´í•´ë©ë‹ˆë‹¤.  \n",
      "\n",
      "ì§ˆë¬¸ì„ í•œ ë‹¨ê³„ ë” ì‹¬í™”í•´ì„œ, ì‹¤ì œ Modular RAG ì‹¤ì„œë¹„ìŠ¤ í™˜ê²½ì—ì„œ ê¸°ìˆ ì ìœ¼ë¡œ ê°€ì¥ ì–´ë ¤ì› ë˜ ì ì´ë‚˜ ì˜ˆìƒ ë°–ì˜ ë¬¸ì œê°€ ìˆì—ˆë‹¤ë©´ ì–´ë–¤ ê²ƒì´ ìˆì—ˆëŠ”ì§€ ê¶ê¸ˆí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´,  \n",
      "- ëª¨ë“ˆ ê°„ interface í‘œì¤€í™”/í†µì‹ ,  \n",
      "- routing decisionì˜ ì •í™•ë„ í•œê³„,  \n",
      "- ëª¨ë“ˆ ê´€ë¦¬Â·ë°°í¬(ì—…ë°ì´íŠ¸, ë¡¤ë°± ë“±) ì‹œ ë°œìƒí•˜ëŠ” ì‹¤ë¬´ ì´ìŠˆ ë“±\n",
      "\n",
      "íŠ¹íˆ, ë„ì… ê³¼ì •ì—ì„œ í˜ë“¤ì—ˆë˜ ê¸°ìˆ ì  ë‚œê´€ì´ë‚˜ â€œì´ëŸ° ì ì€ Modular RAG ë„ì…íŒ€ì´ ë°˜ë“œì‹œ ë¯¸ë¦¬ ì£¼ì˜í•´ì•¼ í•œë‹¤â€ê³  ëŠë¼ì‹  ê²½í—˜ì´ ìˆë‹¤ë©´ ê³µìœ  ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_arxiv\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstractâ€”Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of â€œretrieve-then-generateâ€. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patternsâ€”linear, conditional,\n",
      "branching, and loopingâ€”and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Termsâ€”Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]â€“[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLMâ€™s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2505.20096v2\" date=\"2025-10-11\" authors=\"Thang Nguyen, Peter Chin, Yu-Wing Tai\"/>\n",
      "<Title>\n",
      "MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation\n",
      "(RAG) that addresses the inherent ambiguities and reasoning challenges in\n",
      "complex information-seeking tasks. Unlike conventional RAG methods that rely on\n",
      "end-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates\n",
      "a collaborative set of specialized AI agents: Planner, Step Definer, Extractor,\n",
      "and QA Agents, each responsible for a distinct stage of the RAG pipeline. By\n",
      "decomposing tasks into subtasks such as query disambiguation, evidence\n",
      "extraction, and answer synthesis, and enabling agents to communicate\n",
      "intermediate reasoning via chain-of-thought prompting, MA-RAG progressively\n",
      "refines retrieval and synthesis while maintaining modular interpretability.\n",
      "Extensive experiments on multi-hop and ambiguous QA benchmarks, including NQ,\n",
      "HotpotQA, 2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly\n",
      "outperforms standalone LLMs and existing RAG methods across all model scales.\n",
      "Notably, even a small LLaMA3-8B model equipped with MA-RAG surpasses larger\n",
      "standalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\n",
      "state-of-the-art results on challenging multi-hop datasets. Ablation studies\n",
      "reveal that both the planner and extractor agents are critical for multi-hop\n",
      "reasoning, and that high-capacity models are especially important for the QA\n",
      "agent to synthesize answers effectively. Beyond general-domain QA, MA-RAG\n",
      "generalizes to specialized domains such as medical QA, achieving competitive\n",
      "performance against domain-specific models without any domain-specific\n",
      "fine-tuning. Our results highlight the effectiveness of collaborative, modular\n",
      "reasoning in retrieval-augmented systems: MA-RAG not only improves answer\n",
      "accuracy and robustness but also provides interpretable intermediate reasoning\n",
      "steps, establishing a new paradigm for efficient and reliable multi-agent RAG.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "MA-RAG: MULTI-AGENT RETRIEVAL-AUGMENTED\n",
      "GENERATION\n",
      "VIA\n",
      "COLLABORATIVE\n",
      "CHAIN-OF-\n",
      "THOUGHT REASONING\n",
      "Thang Nguyen & Peter Chin & Yu-Wing Tai\n",
      "Dartmouth College\n",
      "{thangnv.th, peter.chin, yu-wing.tai}@dartmouth.edu\n",
      "ABSTRACT\n",
      "We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Gener-\n",
      "ation (RAG) that addresses the inherent ambiguities and reasoning challenges in\n",
      "complex information-seeking tasks. Unlike conventional RAG methods that rely\n",
      "on end-to-end fine-tuning or isolated component enhancements, MA-RAG orches-\n",
      "trates a collaborative set of specialized AI agents: Planner, Step Definer, Extrac-\n",
      "tor, and QA Agents, each responsible for a distinct stage of the RAG pipeline.\n",
      "By decomposing tasks into subtasks such as query disambiguation, evidence ex-\n",
      "traction, and answer synthesis, and enabling agents to communicate intermedi-\n",
      "ate reasoning via chain-of-thought prompting, MA-RAG progressively refines re-\n",
      "trieval and synthesis while maintaining modular interpretability. Extensive exper-\n",
      "iments on multi-hop and ambiguous QA benchmarks, including NQ, HotpotQA,\n",
      "2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly outperforms\n",
      "standalone LLMs and existing RAG methods across all model scales. Notably,\n",
      "even a small LLaMA3-8B model equipped with MA-RAG surpasses larger stan-\n",
      "dalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\n",
      "state-of-the-art results on challenging multi-hop datasets. Ablation studies reveal\n",
      "that both the planner and extractor agents are critical for multi-hop reasoning,\n",
      "and that high-capacity models are especially important for the QA agent to syn-\n",
      "thesize answers effectively. Beyond general-domain QA, MA-RAG generalizes\n",
      "to specialized domains such as medical QA, achieving competitive performance\n",
      "against domain-specific models without any domain-specific fine-tuning. Our re-\n",
      "sults highlight the effectiveness of collaborative, modular reasoning in retrieval-\n",
      "augmented systems: MA-RAG not only improves answer accuracy and robustness\n",
      "but also provides interpretable intermediate reasoning steps, establishing a new\n",
      "paradigm for efficient and reliable multi-agent RAG1.\n",
      "1\n",
      "INTRODUCTION\n",
      "Recent advances in natural language processing have driven the development of Retrieval-\n",
      "Augmented Generation (RAG) models, which aim to enhance the factual accuracy and contextual\n",
      "relevance of generated text by integrating external knowledge sources (Lewis et al., 2020; Guu et al.,\n",
      "2020; Izacard & Grave, 2021; Lin et al., 2024). These systems address core limitations of Large Lan-\n",
      "guage Models (LLMs), such as outdated knowledge (Zhang et al., 2023b; Kasai et al., 2023) and\n",
      "poor generalization to domain-specific queries (Siriwardhana et al., 2023; Xiong et al., 2024), by\n",
      "retrieving top-k documents from an external corpus (Formal et al., 2022; Izacard et al., 2022; Wang\n",
      "et al., 2022a) to ground the modelâ€™s output in relevant evidence.\n",
      "Prior research in RAG has largely concentrated on optimizing three key componentsâ€”retrieval,\n",
      "augmentation, and generation (Gao et al., 2024; Fan et al., 2024) (Figure 1(a)). Retrieval strate-\n",
      "gies span sparse methods (Jones, 1972; Robertson & Zaragoza, 2009) and dense retrieval (Reimers\n",
      "& Gurevych, 2019; Karpukhin et al., 2020), each with respective weaknesses such as lexical\n",
      "gaps (Berger et al., 2000) or retrieval failure on out-of-distribution and multi-hop queries (Dai et al.,\n",
      "1Our code is available at https://github.com/thangylvp/MA-RAG\n",
      "1\n",
      "arXiv:2505.20096v2  [cs.CL]  11 Oct 2025\n",
      "Query\n",
      "Docs\n",
      "Answer\n",
      "Docs\n",
      "Answer\n",
      "CoT\n",
      "Notes\n",
      "Post-process\n",
      "a) Vanilla RAG\n",
      "Step 1\n",
      "Step ...\n",
      "CoT\n",
      "Sub-Query\n",
      "Query\n",
      "Docs\n",
      "Notes\n",
      "CoT\n",
      "Query\n",
      "Sub-Answer\n",
      "CoT\n",
      "b) RAG with post-\n",
      "processing retrieved docs\n",
      "d) MA-RAG\n",
      "Query\n",
      "Docs\n",
      "Answer\n",
      "c) RAG with interleaving\n",
      "retrieval and thoughts\n",
      "Answer\n",
      "CoT\n",
      "Figure 1: Architectural Comparison of MA-RAG and Prior RAG Methods. a) A naive RAG sys-\n",
      "tem performs one-shot retrieval followed by direct answer generation. b) Enhanced systems incor-\n",
      "porate post-retrieval processing such as document re-\n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2410.20753v2\" date=\"2025-02-04\" authors=\"Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma\"/>\n",
      "<Title>\n",
      "Plan*RAG: Efficient Test-Time Planning for Retrieval Augmented Generation\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "We introduce Plan*RAG, a novel framework that enables structured multi-hop\n",
      "reasoning in retrieval-augmented generation (RAG) through test-time reasoning\n",
      "plan generation. While existing approaches such as ReAct maintain reasoning\n",
      "chains within the language model's context window, we observe that this often\n",
      "leads to plan fragmentation and execution failures. Our key insight is that by\n",
      "isolating the reasoning plan as a directed acyclic graph (DAG) outside the LM's\n",
      "working memory, we can enable (1) systematic exploration of reasoning paths,\n",
      "(2) atomic subqueries enabling precise retrievals and grounding, and (3)\n",
      "efficiency through parallel execution and bounded context window utilization.\n",
      "Moreover, Plan*RAG's modular design allows it to be integrated with existing\n",
      "RAG methods, thus providing a practical solution to improve current RAG\n",
      "systems. On standard multi-hop reasoning benchmarks, Plan*RAG consistently\n",
      "achieves improvements over recently proposed methods such as RQ-RAG and\n",
      "Self-RAG, while maintaining comparable computational costs.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "Planâˆ—RAG: Efficient Test-Time Planning for Retrieval Augmented Generation\n",
      "Prakhar Verma â€  1 Sukruta Prakash Midigeshi 2 Gaurav Sinha 2 Arno Solin 1\n",
      "Nagarajan Natarajan 2 Amit Sharma 2\n",
      "Abstract\n",
      "We introduce Planâˆ—RAG, a novel framework\n",
      "that enables structured multi-hop reasoning in\n",
      "retrieval-augmented generation (RAG) through\n",
      "test-time reasoning plan generation. While exist-\n",
      "ing approaches such as ReAct maintain reason-\n",
      "ing chains within the language modelâ€™s context\n",
      "window, we observe that this often leads to plan\n",
      "fragmentation and execution failures. Our key\n",
      "insight is that by isolating the reasoning plan as\n",
      "a directed acyclic graph (DAG) outside the LMâ€™s\n",
      "working memory, we can enable (1) systematic\n",
      "exploration of reasoning paths, (2) atomic sub-\n",
      "queries enabling precise retrievals and ground-\n",
      "ing, and (3) efficiency through parallel execution\n",
      "and bounded context window utilization. More-\n",
      "over, Planâˆ—RAGâ€™s modular design allows it to\n",
      "be integrated with existing RAG methods, thus\n",
      "providing a practical solution to improve current\n",
      "RAG systems. On standard multi-hop reasoning\n",
      "benchmarks, Planâˆ—RAG consistently achieves im-\n",
      "provements over recently proposed methods such\n",
      "as RQ-RAG and Self-RAG, while maintaining\n",
      "comparable computational costs.\n",
      "1. Introduction\n",
      "Retrieval-Augmented Generation (RAG, Lewis et al., 2020;\n",
      "Petroni et al., 2020; Guu et al., 2020) has emerged as a\n",
      "promising approach for grounding language model (LM)\n",
      "responses in external knowledge. However, RAG systems\n",
      "struggle with multi-hop queries that require reasoning across\n",
      "multiple retrieved documents (Tang & Yang, 2024; Wei\n",
      "et al., 2022). A key challenge lies in the initial retrieval step,\n",
      "which often fails to retrieve sufficient relevant documents\n",
      "due to the queryâ€™s lack of full contextual information (Ma\n",
      "et al., 2023). This limitation has been highlighted in recent\n",
      "surveys (Torfi et al., 2020; Zhao et al., 2023) as a funda-\n",
      "â€  Work done during an internship with Microsoft Research.\n",
      "1Aalto University, Finland 2Microsoft Research. Correspondence\n",
      "to: <prakhar.verma@aalto.fi>, <amshar@microsoft.com>.\n",
      "RAG\n",
      "Self-RAG\n",
      "ReAct\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "Test-time planning improves RAG\n",
      "25.51\n",
      "34.09\n",
      "33.15\n",
      "31.12\n",
      "37.31\n",
      "40.44\n",
      "Accuracy (%)\n",
      "Vanilla\n",
      "With Planâˆ—\n",
      "Figure 1. Planâˆ—RAG improves performance on the HotpotQA\n",
      "benchmark substantially compared to various existing RAG meth-\n",
      "ods, demonstrating the value of externalizing planning as a directed\n",
      "acyclic graph (DAG) outside of the LLMâ€™s context.\n",
      "mental barrier to reliable AI systems, particularly given the\n",
      "widespread deployment of large language models (Brown\n",
      "et al., 2020) across critical domains. Consider the query:\n",
      "â€œRumble Fish was a novel by the author of the coming-of-age\n",
      "novel published in what year by Viking Press?â€ Answering\n",
      "this requires an iterative retrieval process: identifying the\n",
      "Rumble Fishâ€™s author, connecting to their coming-of-age\n",
      "novel, and determining its publication year. Single-step\n",
      "retrieval in RAG systems often fails in such cases, as it\n",
      "may retrieve documents about Rumble Fishâ€™s author and\n",
      "Viking Press without recognizing the intermediate factâ€”\n",
      "the authorâ€™s coming-of-age novelâ€”must first be established.\n",
      "Furthermore, Leng et al. (2024); Shuster et al. (2021) demon-\n",
      "strate that even when relevant documents are retrieved, LMs\n",
      "struggle to reason across them due to fixed context win-\n",
      "dows, leading to information loss and broken reasoning\n",
      "chain. These limitations pose risks in critical domains such\n",
      "as healthcare and finance (Pal et al., 2023; Zhao et al., 2024),\n",
      "where accurate multi-step reasoning is essential.\n",
      "Recent research has attempted to address these limita-\n",
      "tions through structured reasoning frameworks. Chain-of-\n",
      "Thought (CoT) prompting (Wei et al., 2022) and systematic\n",
      "query decomposition (Patel et al., 2022) have introduced\n",
      "explicit reasoning steps, enabling more granular thought\n",
      "processes and targeted retrievals. Building upon these foun-\n",
      "dations, Yao et al. (2023) proposed ReActâ€”a framework\n",
      "that creates a reasoning chain \n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_web\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document href=\"https://www.meilisearch.com/blog/modular-rag\"/>\n",
      "Modular RAG refers to a method of building retrieval-augmented generation (RAG) systems where the entire setup is divided into smaller and independent components. The key components of modular RAG are the retriever, which finds useful information, the generator, which turns the information into responses, and additional modules such as rerankers, memory, or vector databases, which improve the accuracy of the artificial intelligence system. Modular RAG works by retrieving relevant context from external knowledge sources, passing it through a generative model, and allowing different modules to handle tasks such as filtering, summarization, or reasoning, depending on the task's requirements. You can implement modular RAG by combining retrievers and LLMs into a RAG pipeline that fits your use case.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.themoonlight.io/ko/review/modular-rag-transforming-rag-systems-into-lego-like-reconfigurable-frameworks\"/>\n",
      "ì €ìë“¤ì€ RAG ì‹œìŠ¤í…œì´ ì ì  ë” ë³µì¡í•´ì§€ëŠ” ìƒí™©ì—ì„œ ê¸°ì¡´ì˜ RAG íŒ¨ëŸ¬ë‹¤ì„ì´ ê°€ì§€ëŠ” í•œê³„ë¥¼ ì–¸ê¸‰í•˜ë©°, ì´ë¡œ ì¸í•´ RAG ì‹œìŠ¤í…œì˜ ëª¨ë“ˆí™”ë¥¼ í†µí•´ ìœ ì—°í•˜ê³  ì¬êµ¬ì„± ê°€ëŠ¥í•œ\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://aiheroes.ai/community/254\"/>\n",
      "3) RAGì˜ ì£¼ìš” íŒ¨ëŸ¬ë‹¤ì„ - Modular RAG. ëª¨ë“ˆì‹ RAG ì‹œìŠ¤í…œì€ ê¸°ì¡´ RAGì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ë” ìœ ì—°í•˜ê³  ê°•ë ¥í•œ ì„±ëŠ¥ì„ ì œê³µí•˜ëŠ” ìƒˆë¡œìš´ êµ¬ì¡°ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manswer_question\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: expert\n",
      "\n",
      "ë„¤, ì‹¤ì œ Modular RAGë¥¼ production í™˜ê²½ì— ë„ì…Â·ìš´ì˜í•  ë•Œ ê¸°ìˆ ì ìœ¼ë¡œ ê°€ì¥ ë§ì´ ë§ˆì£¼ì¹˜ëŠ” ë„ì „ ê³¼ì œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**1. ëª¨ë“ˆ ê°„ ì¸í„°í˜ì´ìŠ¤ í‘œì¤€í™” ë° í†µì‹ **\n",
      "- Modular RAGëŠ” ê°ê¸° ë…ë¦½ì ìœ¼ë¡œ ê°œë°œëœ retriever, ranker, router, generator ë“±ì´ ëŠìŠ¨í•˜ê²Œ ì—°ê²°ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ë•Œ ê° ëª¨ë“ˆì˜ ì…ë ¥/ì¶œë ¥ í˜•ì‹, ë°ì´í„° ìŠ¤í‚¤ë§ˆ, ì—ëŸ¬ ì²˜ë¦¬ í”„ë¡œí† ì½œ ë“±ì„ í‘œì¤€í™”í•˜ì§€ ì•Šìœ¼ë©´ íŒŒì´í”„ë¼ì¸ì´ ì‰½ê²Œ ê¹¨ì§€ê±°ë‚˜ ë””ë²„ê¹…ì´ ë§¤ìš° ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤. íŠ¹íˆ ìƒˆë¡œìš´ ëª¨ë“ˆì„ êµì²´/ì¶”ê°€í•  ë•Œë§ˆë‹¤ interface mismatch ì´ìŠˆê°€ ìì£¼ ë°œìƒí•©ë‹ˆë‹¤. ë”°ë¼ì„œ API ì„¤ê³„, ê³µí†µ ë°ì´í„° í¬ë§· ì •ì˜ ë“±ì€ ë°˜ë“œì‹œ ì´ˆê¸° ë‹¨ê³„ì—ì„œ í™•ì‹¤íˆ ì •ë¦½ë˜ì–´ì•¼ í•©ë‹ˆë‹¤ [3][4].\n",
      "\n",
      "**2. Routing Decisionì˜ ì •í™•ë„ í•œê³„**\n",
      "- Modular RAGì˜ í•µì‹¬ì€ ì¿¼ë¦¬ì— ë”°ë¼ ìµœì ì˜ ëª¨ë“ˆ(ì˜ˆ: ë„ë©”ì¸ íŠ¹í™” retriever, ranker ë“±)ë¡œ íš¨ê³¼ì ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ë„ë©”ì¸ ë¶„ë¥˜ë‚˜ intent detectionì´ ì™„ë²½í•˜ì§€ ì•Šìœ¼ë©´ ì˜ëª»ëœ ë¼ìš°íŒ…ì´ ë°œìƒí•´ ì˜¤íˆë ¤ Naive RAGë³´ë‹¤ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë©€í‹°ë„ë©”ì¸, ì˜¤ë²„ë© ë„ë©”ì¸(ë²•ë¥ +ì¼€ì´ìŠ¤, ì˜ë£Œ+ë³´í—˜ ë“±)ì—ì„œëŠ” ë¼ìš°íŒ…ì´ ì–´ë ¤ì›Œ, ë¼ìš°í„° ëª¨ë“ˆ ìì²´ì˜ í’ˆì§ˆ ê´€ë¦¬ì™€ í‰ê°€ê°€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤ [3].\n",
      "\n",
      "**3. ëª¨ë“ˆ ê´€ë¦¬, ë°°í¬ ë° ìš´ì˜ ì´ìŠˆ**\n",
      "- ê° ëª¨ë“ˆì´ ë…ë¦½ì ì´ê¸° ë•Œë¬¸ì— ë²„ì „ ê´€ë¦¬(ì—…ë°ì´íŠ¸/ë¡¤ë°±), ë°°í¬, ëª¨ë‹ˆí„°ë§ ë“±ì´ ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, retriever ì—…ë°ì´íŠ¸ê°€ generatorì™€ í˜¸í™˜ë˜ì§€ ì•Šì•„ ì‹œìŠ¤í…œ ì „ì²´ì— ì¥ì• ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ëª¨ë“ˆë³„ CI/CD, ê´€ì¸¡ì„± ë„êµ¬, ìë™í™”ëœ rollback/healthcheck ë“±ì˜ ì²´ê³„ë¥¼ ë°˜ë“œì‹œ ê°–ì¶°ì•¼ í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì—¬ëŸ¬ ëª¨ë“ˆì´ í˜‘ë ¥í•˜ëŠ” êµ¬ì¡°ì—ì„œëŠ” íŠ¹ì • ëª¨ë“ˆ ê²°í•¨ì´ ì „ì²´ ì„œë¹„ìŠ¤ í’ˆì§ˆì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ë†’ìœ¼ë¯€ë¡œ, ëª¨ë“ˆê°„ ê³„ì•½ ë° fallback ì „ëµì´ ìˆì–´ì•¼ ì•ˆì •ì ì¸ ìš´ì˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ [3][5].\n",
      "\n",
      "**4. ì¶”ê°€ì ì¸ ì‹¤ë¬´ ì£¼ì˜ì **\n",
      "- ì‹œìŠ¤í…œì´ ë³µì¡í•´ì§ˆìˆ˜ë¡ latency(ì§€ì—°) ì¦ê°€ì™€ ë¹„ìš© ì´ìŠˆê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- ë„ë©”ì¸ í™•ì¥ ë˜ëŠ” ê³ ë„í™” ê³¼ì •ì—ì„œ ëª¨ë“ˆ ê°„ ì˜ì¡´ì„±ì´ ì»¤ì§€ë©´, ì˜¤íˆë ¤ ìœ ì§€ë³´ìˆ˜ê°€ ë” ì–´ë ¤ì›Œì§ˆ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ìš”ì•½**\n",
      "Modular RAGì˜ ê°€ì¥ í° ì¥ì ì€ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì´ì§€ë§Œ, ì‹¤ì„œë¹„ìŠ¤ ìˆ˜ì¤€ì—ì„œëŠ” ì¸í„°í˜ì´ìŠ¤ í‘œì¤€í™”Â·í’ˆì§ˆ ê´€ë¦¬Â·ìš´ì˜ ìë™í™”ê°€ í•„ìˆ˜ì ì´ë©°, ë¼ìš°í„°/ë¶„ê¸° ê²°ì •ì˜ ì •í™•ì„± ê°œì„  ë° ëª¨ë“ˆê°„ ì—ëŸ¬ ì „íŒŒÂ·íšŒë³µ ì „ëµì„ ê¼¼ê¼¼íˆ ì±™ê²¨ì•¼ë§Œ ì„±ê³µì ìœ¼ë¡œ ë„ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "[3] http://arxiv.org/abs/2407.21059v1  \n",
      "[4] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mask_question\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ë„ˆë¬´ ì¸ìƒì ì¸ í˜„ì¥ ê²½í—˜ ê³µìœ  ê°ì‚¬í•©ë‹ˆë‹¤!  \n",
      "ì‹¤ì œ ìš´ì˜ ë‹¨ê³„ì—ì„œ ê²ªìœ¼ì‹  â€œë¼ìš°íŒ… misclassificationâ€ì´ë‚˜ â€œëª¨ë“ˆë³„ ë°°í¬ ê´€ë¦¬â€ì™€ ê°™ì€ ì‹¤ìš©ì  ì´ìŠˆê¹Œì§€ ë“¤ì–´ì„œ ë§¤ìš° ë„ì›€ì´ ëìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë§ˆì§€ë§‰ìœ¼ë¡œ ì—¬ì­¤ë³´ê³  ì‹¶ì€ë°ìš”,  \n",
      "í–¥í›„ Modular RAG ë°©ë²•ë¡ ì´ ë°œì „í•˜ë©´ì„œ ê°€ëŠ¥í•´ì§ˆ ìƒˆë¡œìš´ ì‹œë‚˜ë¦¬ì˜¤ë‚˜, ê°œì¸ì ìœ¼ë¡œ ê¸°ëŒ€í•˜ê³  ê³„ì‹  í˜ì‹ ì  ë³€í™”ë¥¼ í•œ ê°€ì§€ êµ¬ì²´ì ì¸ ì˜ˆì™€ í•¨ê»˜ ë§ì”€í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?  \n",
      "ì˜ˆë¥¼ ë“¤ì–´, â€œë™ì  í”¼ë“œë°± ë£¨í”„ë¥¼ í†µí•œ ìë™ ëª¨ë“ˆ íŠœë‹â€ì²˜ëŸ¼ í˜„ì—… ì—°êµ¬ì ì…ì¥ì—ì„œ í¥ë¯¸ë¡­ë‹¤ ìƒê°í•˜ì‹œëŠ” ì§€ì ì„ ë“£ê³  ì‹¶ìŠµë‹ˆë‹¤.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_arxiv\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstractâ€”Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of â€œretrieve-then-generateâ€. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patternsâ€”linear, conditional,\n",
      "branching, and loopingâ€”and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Termsâ€”Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]â€“[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLMâ€™s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2505.20096v2\" date=\"2025-10-11\" authors=\"Thang Nguyen, Peter Chin, Yu-Wing Tai\"/>\n",
      "<Title>\n",
      "MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation\n",
      "(RAG) that addresses the inherent ambiguities and reasoning challenges in\n",
      "complex information-seeking tasks. Unlike conventional RAG methods that rely on\n",
      "end-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates\n",
      "a collaborative set of specialized AI agents: Planner, Step Definer, Extractor,\n",
      "and QA Agents, each responsible for a distinct stage of the RAG pipeline. By\n",
      "decomposing tasks into subtasks such as query disambiguation, evidence\n",
      "extraction, and answer synthesis, and enabling agents to communicate\n",
      "intermediate reasoning via chain-of-thought prompting, MA-RAG progressively\n",
      "refines retrieval and synthesis while maintaining modular interpretability.\n",
      "Extensive experiments on multi-hop and ambiguous QA benchmarks, including NQ,\n",
      "HotpotQA, 2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly\n",
      "outperforms standalone LLMs and existing RAG methods across all model scales.\n",
      "Notably, even a small LLaMA3-8B model equipped with MA-RAG surpasses larger\n",
      "standalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\n",
      "state-of-the-art results on challenging multi-hop datasets. Ablation studies\n",
      "reveal that both the planner and extractor agents are critical for multi-hop\n",
      "reasoning, and that high-capacity models are especially important for the QA\n",
      "agent to synthesize answers effectively. Beyond general-domain QA, MA-RAG\n",
      "generalizes to specialized domains such as medical QA, achieving competitive\n",
      "performance against domain-specific models without any domain-specific\n",
      "fine-tuning. Our results highlight the effectiveness of collaborative, modular\n",
      "reasoning in retrieval-augmented systems: MA-RAG not only improves answer\n",
      "accuracy and robustness but also provides interpretable intermediate reasoning\n",
      "steps, establishing a new paradigm for efficient and reliable multi-agent RAG.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "MA-RAG: MULTI-AGENT RETRIEVAL-AUGMENTED\n",
      "GENERATION\n",
      "VIA\n",
      "COLLABORATIVE\n",
      "CHAIN-OF-\n",
      "THOUGHT REASONING\n",
      "Thang Nguyen & Peter Chin & Yu-Wing Tai\n",
      "Dartmouth College\n",
      "{thangnv.th, peter.chin, yu-wing.tai}@dartmouth.edu\n",
      "ABSTRACT\n",
      "We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Gener-\n",
      "ation (RAG) that addresses the inherent ambiguities and reasoning challenges in\n",
      "complex information-seeking tasks. Unlike conventional RAG methods that rely\n",
      "on end-to-end fine-tuning or isolated component enhancements, MA-RAG orches-\n",
      "trates a collaborative set of specialized AI agents: Planner, Step Definer, Extrac-\n",
      "tor, and QA Agents, each responsible for a distinct stage of the RAG pipeline.\n",
      "By decomposing tasks into subtasks such as query disambiguation, evidence ex-\n",
      "traction, and answer synthesis, and enabling agents to communicate intermedi-\n",
      "ate reasoning via chain-of-thought prompting, MA-RAG progressively refines re-\n",
      "trieval and synthesis while maintaining modular interpretability. Extensive exper-\n",
      "iments on multi-hop and ambiguous QA benchmarks, including NQ, HotpotQA,\n",
      "2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly outperforms\n",
      "standalone LLMs and existing RAG methods across all model scales. Notably,\n",
      "even a small LLaMA3-8B model equipped with MA-RAG surpasses larger stan-\n",
      "dalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\n",
      "state-of-the-art results on challenging multi-hop datasets. Ablation studies reveal\n",
      "that both the planner and extractor agents are critical for multi-hop reasoning,\n",
      "and that high-capacity models are especially important for the QA agent to syn-\n",
      "thesize answers effectively. Beyond general-domain QA, MA-RAG generalizes\n",
      "to specialized domains such as medical QA, achieving competitive performance\n",
      "against domain-specific models without any domain-specific fine-tuning. Our re-\n",
      "sults highlight the effectiveness of collaborative, modular reasoning in retrieval-\n",
      "augmented systems: MA-RAG not only improves answer accuracy and robustness\n",
      "but also provides interpretable intermediate reasoning steps, establishing a new\n",
      "paradigm for efficient and reliable multi-agent RAG1.\n",
      "1\n",
      "INTRODUCTION\n",
      "Recent advances in natural language processing have driven the development of Retrieval-\n",
      "Augmented Generation (RAG) models, which aim to enhance the factual accuracy and contextual\n",
      "relevance of generated text by integrating external knowledge sources (Lewis et al., 2020; Guu et al.,\n",
      "2020; Izacard & Grave, 2021; Lin et al., 2024). These systems address core limitations of Large Lan-\n",
      "guage Models (LLMs), such as outdated knowledge (Zhang et al., 2023b; Kasai et al., 2023) and\n",
      "poor generalization to domain-specific queries (Siriwardhana et al., 2023; Xiong et al., 2024), by\n",
      "retrieving top-k documents from an external corpus (Formal et al., 2022; Izacard et al., 2022; Wang\n",
      "et al., 2022a) to ground the modelâ€™s output in relevant evidence.\n",
      "Prior research in RAG has largely concentrated on optimizing three key componentsâ€”retrieval,\n",
      "augmentation, and generation (Gao et al., 2024; Fan et al., 2024) (Figure 1(a)). Retrieval strate-\n",
      "gies span sparse methods (Jones, 1972; Robertson & Zaragoza, 2009) and dense retrieval (Reimers\n",
      "& Gurevych, 2019; Karpukhin et al., 2020), each with respective weaknesses such as lexical\n",
      "gaps (Berger et al., 2000) or retrieval failure on out-of-distribution and multi-hop queries (Dai et al.,\n",
      "1Our code is available at https://github.com/thangylvp/MA-RAG\n",
      "1\n",
      "arXiv:2505.20096v2  [cs.CL]  11 Oct 2025\n",
      "Query\n",
      "Docs\n",
      "Answer\n",
      "Docs\n",
      "Answer\n",
      "CoT\n",
      "Notes\n",
      "Post-process\n",
      "a) Vanilla RAG\n",
      "Step 1\n",
      "Step ...\n",
      "CoT\n",
      "Sub-Query\n",
      "Query\n",
      "Docs\n",
      "Notes\n",
      "CoT\n",
      "Query\n",
      "Sub-Answer\n",
      "CoT\n",
      "b) RAG with post-\n",
      "processing retrieved docs\n",
      "d) MA-RAG\n",
      "Query\n",
      "Docs\n",
      "Answer\n",
      "c) RAG with interleaving\n",
      "retrieval and thoughts\n",
      "Answer\n",
      "CoT\n",
      "Figure 1: Architectural Comparison of MA-RAG and Prior RAG Methods. a) A naive RAG sys-\n",
      "tem performs one-shot retrieval followed by direct answer generation. b) Enhanced systems incor-\n",
      "porate post-retrieval processing such as document re-\n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2410.20753v2\" date=\"2025-02-04\" authors=\"Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma\"/>\n",
      "<Title>\n",
      "Plan*RAG: Efficient Test-Time Planning for Retrieval Augmented Generation\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "We introduce Plan*RAG, a novel framework that enables structured multi-hop\n",
      "reasoning in retrieval-augmented generation (RAG) through test-time reasoning\n",
      "plan generation. While existing approaches such as ReAct maintain reasoning\n",
      "chains within the language model's context window, we observe that this often\n",
      "leads to plan fragmentation and execution failures. Our key insight is that by\n",
      "isolating the reasoning plan as a directed acyclic graph (DAG) outside the LM's\n",
      "working memory, we can enable (1) systematic exploration of reasoning paths,\n",
      "(2) atomic subqueries enabling precise retrievals and grounding, and (3)\n",
      "efficiency through parallel execution and bounded context window utilization.\n",
      "Moreover, Plan*RAG's modular design allows it to be integrated with existing\n",
      "RAG methods, thus providing a practical solution to improve current RAG\n",
      "systems. On standard multi-hop reasoning benchmarks, Plan*RAG consistently\n",
      "achieves improvements over recently proposed methods such as RQ-RAG and\n",
      "Self-RAG, while maintaining comparable computational costs.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "Planâˆ—RAG: Efficient Test-Time Planning for Retrieval Augmented Generation\n",
      "Prakhar Verma â€  1 Sukruta Prakash Midigeshi 2 Gaurav Sinha 2 Arno Solin 1\n",
      "Nagarajan Natarajan 2 Amit Sharma 2\n",
      "Abstract\n",
      "We introduce Planâˆ—RAG, a novel framework\n",
      "that enables structured multi-hop reasoning in\n",
      "retrieval-augmented generation (RAG) through\n",
      "test-time reasoning plan generation. While exist-\n",
      "ing approaches such as ReAct maintain reason-\n",
      "ing chains within the language modelâ€™s context\n",
      "window, we observe that this often leads to plan\n",
      "fragmentation and execution failures. Our key\n",
      "insight is that by isolating the reasoning plan as\n",
      "a directed acyclic graph (DAG) outside the LMâ€™s\n",
      "working memory, we can enable (1) systematic\n",
      "exploration of reasoning paths, (2) atomic sub-\n",
      "queries enabling precise retrievals and ground-\n",
      "ing, and (3) efficiency through parallel execution\n",
      "and bounded context window utilization. More-\n",
      "over, Planâˆ—RAGâ€™s modular design allows it to\n",
      "be integrated with existing RAG methods, thus\n",
      "providing a practical solution to improve current\n",
      "RAG systems. On standard multi-hop reasoning\n",
      "benchmarks, Planâˆ—RAG consistently achieves im-\n",
      "provements over recently proposed methods such\n",
      "as RQ-RAG and Self-RAG, while maintaining\n",
      "comparable computational costs.\n",
      "1. Introduction\n",
      "Retrieval-Augmented Generation (RAG, Lewis et al., 2020;\n",
      "Petroni et al., 2020; Guu et al., 2020) has emerged as a\n",
      "promising approach for grounding language model (LM)\n",
      "responses in external knowledge. However, RAG systems\n",
      "struggle with multi-hop queries that require reasoning across\n",
      "multiple retrieved documents (Tang & Yang, 2024; Wei\n",
      "et al., 2022). A key challenge lies in the initial retrieval step,\n",
      "which often fails to retrieve sufficient relevant documents\n",
      "due to the queryâ€™s lack of full contextual information (Ma\n",
      "et al., 2023). This limitation has been highlighted in recent\n",
      "surveys (Torfi et al., 2020; Zhao et al., 2023) as a funda-\n",
      "â€  Work done during an internship with Microsoft Research.\n",
      "1Aalto University, Finland 2Microsoft Research. Correspondence\n",
      "to: <prakhar.verma@aalto.fi>, <amshar@microsoft.com>.\n",
      "RAG\n",
      "Self-RAG\n",
      "ReAct\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "Test-time planning improves RAG\n",
      "25.51\n",
      "34.09\n",
      "33.15\n",
      "31.12\n",
      "37.31\n",
      "40.44\n",
      "Accuracy (%)\n",
      "Vanilla\n",
      "With Planâˆ—\n",
      "Figure 1. Planâˆ—RAG improves performance on the HotpotQA\n",
      "benchmark substantially compared to various existing RAG meth-\n",
      "ods, demonstrating the value of externalizing planning as a directed\n",
      "acyclic graph (DAG) outside of the LLMâ€™s context.\n",
      "mental barrier to reliable AI systems, particularly given the\n",
      "widespread deployment of large language models (Brown\n",
      "et al., 2020) across critical domains. Consider the query:\n",
      "â€œRumble Fish was a novel by the author of the coming-of-age\n",
      "novel published in what year by Viking Press?â€ Answering\n",
      "this requires an iterative retrieval process: identifying the\n",
      "Rumble Fishâ€™s author, connecting to their coming-of-age\n",
      "novel, and determining its publication year. Single-step\n",
      "retrieval in RAG systems often fails in such cases, as it\n",
      "may retrieve documents about Rumble Fishâ€™s author and\n",
      "Viking Press without recognizing the intermediate factâ€”\n",
      "the authorâ€™s coming-of-age novelâ€”must first be established.\n",
      "Furthermore, Leng et al. (2024); Shuster et al. (2021) demon-\n",
      "strate that even when relevant documents are retrieved, LMs\n",
      "struggle to reason across them due to fixed context win-\n",
      "dows, leading to information loss and broken reasoning\n",
      "chain. These limitations pose risks in critical domains such\n",
      "as healthcare and finance (Pal et al., 2023; Zhao et al., 2024),\n",
      "where accurate multi-step reasoning is essential.\n",
      "Recent research has attempted to address these limita-\n",
      "tions through structured reasoning frameworks. Chain-of-\n",
      "Thought (CoT) prompting (Wei et al., 2022) and systematic\n",
      "query decomposition (Patel et al., 2022) have introduced\n",
      "explicit reasoning steps, enabling more granular thought\n",
      "processes and targeted retrievals. Building upon these foun-\n",
      "dations, Yao et al. (2023) proposed ReActâ€”a framework\n",
      "that creates a reasoning chain \n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_web\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document href=\"https://dev523.medium.com/the-evolution-of-rag-how-retrieval-augmented-generation-is-transforming-enterprise-ai-in-2025-a0265bc1c297\"/>\n",
      "[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fdev523.medium.com%2Fthe-evolution-of-rag-how-retrieval-augmented-generation-is-transforming-enterprise-ai-in-2025-a0265bc1c297&source=post_page---top_nav_layout_nav-----------------------global_nav------------------) [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fdev523.medium.com%2Fthe-evolution-of-rag-how-retrieval-augmented-generation-is-transforming-enterprise-ai-in-2025-a0265bc1c297&source=post_page---top_nav_layout_nav-----------------------global_nav------------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fa0265bc1c297&operation=register&redirect=https%3A%2F%2Fdev523.medium.com%2Fthe-evolution-of-rag-how-retrieval-augmented-generation-is-transforming-enterprise-ai-in-2025-a0265bc1c297&user=Devendra+Parihar&userId=e3982408d2d8&source=---header_actions--a0265bc1c297---------------------clap_footer------------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa0265bc1c297&operation=register&redirect=https%3A%2F%2Fdev523.medium.com%2Fthe-evolution-of-rag-how-retrieval-augmented-generation-is-transforming-enterprise-ai-in-2025-a0265bc1c297&source=---header_actions--a0265bc1c297---------------------bookmark_footer------------------) [Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3Da0265bc1c297&operation=register&redirect=https%3A%2F%2Fdev523.medium.com%2Fthe-evolution-of-rag-how-retrieval-augmented-generation-is-transforming-enterprise-ai-in-2025-a0265bc1c297&source=---header_actions--a0265bc1c297---------------------post_audio_button------------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fa0265bc1c297&operation=register&redirect=https%3A%2F%2Fdev523.medium.com%2Fthe-evolution-of-rag-how-retrieval-augmented-generation-is-transforming-enterprise-ai-in-2025-a0265bc1c297&user=Devendra+Parihar&userId=e3982408d2d8&source=---footer_actions--a0265bc1c297---------------------clap_footer------------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fa0265bc1c297&operation=register&redirect=https%3A%2F%2Fdev523.medium.com%2Fthe-evolution-of-rag-how-retrieval-augmented-generation-is-transforming-enterprise-ai-in-2025-a0265bc1c297&user=Devendra+Parihar&userId=e3982408d2d8&source=---footer_actions--a0265bc1c297---------------------clap_footer------------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa0265bc1c297&operation=register&redirect=https%3A%2F%2Fdev523.medium.com%2Fthe-evolution-of-rag-how-retrieval-augmented-generation-is-transforming-enterprise-ai-in-2025-a0265bc1c297&source=---footer_actions--a0265bc1c297---------------------bookmark_footer------------------) [What are your thoughts?](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fdev523.medium.com%2Fthe-evolution-of-rag-how-retrieval-augmented-generation-is-transforming-enterprise-ai-in-2025-a0265bc1c297&source=---post_responses--a0265bc1c297---------------------respond_sidebar------------------) [![Image 19: Level Up Coding](https://miro.medium.com/v2/resize:fill:20:20/1*5D9oYBd58pyjMkV_5-zXXQ.jpeg)](https://levelup.gitconnected.com/?source=post_page---read_next_recirc--a0265bc1c297----0---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [6](https://medium.com/@fareedkhandev/building-long-term-memory-in-agentic-ai-2941b0cca3bf?source=post_page---read_next_recirc--a0265bc1c297----0---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [![Image 21: AI Advances](https://miro.medium.com/v2/resize:fill:20:20/1*R8zEd59FDf0l8Re94ImV0Q.png)](https://ai.gopubby.com/?source=post_page---read_next_recirc--a0265bc1c297----1---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [![Image 23: Heptabase](https://miro.medium.com/v2/resize:fill:20:20/1*W5slSxCkuZ7GIKCG4Vk12g.png)](https://medium.com/heptabase?source=post_page---read_next_recirc--a0265bc1c297----0---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [The Best Way to Use AI for Learning ----------------------------------- ### An effective method of learning complex knowledge with AI.](https://alanchan1209.medium.com/the-best-way-to-use-ai-for-learning-762c3467bdf1?source=post_page---read_next_recirc--a0265bc1c297----0---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [22](https://alanchan1209.medium.com/the-best-way-to-use-ai-for-learning-762c3467bdf1?source=post_page---read_next_recirc--a0265bc1c297----0---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F762c3467bdf1&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fheptabase%2Fthe-best-way-to-use-ai-for-learning-762c3467bdf1&source=---read_next_recirc--a0265bc1c297----0-----------------bookmark_preview----ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [![Image 25: Anil Kumar](https://miro.medium.com/v2/resize:fill:20:20/1*Eqi5mP3GU2svZfYjXIZqBw.jpeg)](https://medium.com/@architectmdm?source=post_page---read_next_recirc--a0265bc1c297----1---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [Retrieval-Augmented Generation (RAG): The Future of Context-Aware AI -------------------------------------------------------------------- ### Large Language Models (LLMs) like GPT-4 are powerful, but they hallucinate, lack real-time knowledge, and most importantly, canâ€™t accessâ€¦](https://medium.com/@architectmdm/retrieval-augmented-generation-rag-the-future-of-context-aware-ai-af07e97fad51?source=post_page---read_next_recirc--a0265bc1c297----1---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [](https://medium.com/@architectmdm/retrieval-augmented-generation-rag-the-future-of-context-aware-ai-af07e97fad51?source=post_page---read_next_recirc--a0265bc1c297----1---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf07e97fad51&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40architectmdm%2Fretrieval-augmented-generation-rag-the-future-of-context-aware-ai-af07e97fad51&source=---read_next_recirc--a0265bc1c297----1-----------------bookmark_preview----ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [![Image 27: Data Science Collective](https://miro.medium.com/v2/resize:fill:20:20/1*0nV0Q-FBHj94Kggq00pG2Q.jpeg)](https://medium.com/data-science-collective?source=post_page---read_next_recirc--a0265bc1c297----2---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [Data Science Collective](https://medium.com/data-science-collective?source=post_page---read_next_recirc--a0265bc1c297----2---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [Agentic AI: Implementing Long-Term Memory ----------------------------------------- ### This article helps you understand how to build complex memory systems and the frameworks that help](https://medium.com/@ilsilfverskiold/agentic-ai-implementing-long-term-memory-304be62063cc?source=post_page---read_next_recirc--a0265bc1c297----2---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [9](https://medium.com/@ilsilfverskiold/agentic-ai-implementing-long-term-memory-304be62063cc?source=post_page---read_next_recirc--a0265bc1c297----2---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F304be62063cc&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-collective%2Fagentic-ai-implementing-long-term-memory-304be62063cc&source=---read_next_recirc--a0265bc1c297----2-----------------bookmark_preview----ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [![Image 29: Tosny](https://miro.medium.com/v2/resize:fill:20:20/1*l5wpk3oO8kTVPfuWaB5LhA.png)](https://tosny.medium.com/?source=post_page---read_next_recirc--a0265bc1c297----3---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------) [Tosny](https://tosny.medium.com/?source=post_page---read_next_recirc--a0265bc1c297----3---------------------ef12e5b0_3e47_4393_b8c2_db2963f726fd--------------)\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.youtube.com/watch?v=yQQEnXRMvUA\"/>\n",
      "Modular RAG Architectures with Java and Spring AI by Thomas Vitale @ Spring I/O 2025\n",
      "Spring I/O\n",
      "44400 subscribers\n",
      "192 likes\n",
      "4240 views\n",
      "6 Aug 2025\n",
      "Spring I/O 2025 - 21-23 May, Barcelona\n",
      "\n",
      "Slides: https://speakerdeck.com/thomasvitale/modular-rag-architectures-with-java-and-spring-ai\n",
      "\n",
      "Repo: https://github.com/ThomasVitale/modular-rag /  https://github.com/ThomasVitale/llm-apps-java-spring-ai\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) is a foundational approach to enhancing LLMs by integrating them with targeted, domain-specific data. This session will provide a hands-on guide to designing and implementing modular RAG architectures using Java and Spring AI. Through practical examples, you will gain insights into building production-ready RAG workflows that support both current and future use cases.\n",
      "\n",
      "The session will cover five key stages:\n",
      "\n",
      "Data Indexing: Methods for structuring, chunking, and indexing documents, improving the efficiency and accuracy of downstream retrieval tasks.\n",
      "Query Analysis: Techniques for transforming and enhancing queries in the pre-retrieval phase to improve relevance and precision during retrieval.\n",
      "Retrieval: Strategies for sourcing data from multiple repositories, using agent-based routing to select relevant data sources, and combining, re-ranking, or filtering results to deliver the most contextually relevant information for generation.\n",
      "Augmentation: Methods for augmenting user prompts with retrieved content, including advanced techniques for contextualization, citation, and summarization.\n",
      "Evaluation: Metrics and evaluation methods to assess document relevance and model output accuracy, as well as iterative feedback loops for refining RAG workflows to meet quality standards.\n",
      "Additionally, the session will address important considerations for observability and developer experience in building RAG workflows.\n",
      "5 comments\n",
      "\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.youtube.com/watch?v=s9F56ZADpyw\"/>\n",
      "Multimodal Modular RAG for ... Dynamic RAG with Chroma and Hugging Face Llama. -Empowering AI Models: Fine-Tuning RAG Data and Human Feedback.\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manswer_question\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: expert\n",
      "\n",
      "ë„¤, ì•ìœ¼ë¡œ Modular RAGê°€ ë°œì „í•˜ë©´ì„œ íŠ¹íˆ ê¸°ëŒ€í•˜ëŠ” í˜ì‹  ì¤‘ í•˜ë‚˜ëŠ” â€œë™ì  í”¼ë“œë°± ë£¨í”„ ë° ìë™í™”ëœ ëª¨ë“ˆ ìµœì í™”â€ì…ë‹ˆë‹¤.\n",
      "\n",
      "**êµ¬ì²´ì  ì˜ˆì‹œ: ì‹¤ì‹œê°„ ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ì˜ RAG íŒŒì´í”„ë¼ì¸ ìë™ ì¬êµ¬ì„±**\n",
      "\n",
      "- ì˜ˆë¥¼ ë“¤ì–´, production í™˜ê²½ì—ì„œ ê° ì§ˆì˜ì™€ ì‘ë‹µì— ëŒ€í•´ ì‚¬ìš©ìì˜ explicit/implicit í”¼ë“œë°±(ì˜ˆ: thumbs up/down, í´ë¦­ í–‰ë™, ì¶”ê°€ ì§ˆì˜ ë“±)ì´ ê³„ì† ìŒ“ì¸ë‹¤ê³  ê°€ì •í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "- Modular RAGì—ì„œëŠ” ì´ëŸ° í”¼ë“œë°±ì„ ê°ì§€í•˜ëŠ” specialized feedback collector ëª¨ë“ˆê³¼, ì´ë¥¼ ë¶„ì„í•´ ê° retriever/ë¼ìš°í„°/ìƒì„±ê¸° ë“±ì˜ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” evaluator ëª¨ë“ˆì„ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- í‰ê°€ ê²°ê³¼ì— ë”°ë¼, RAG ì‹œìŠ¤í…œì´ ìŠ¤ìŠ¤ë¡œ retriever weightingì„ ì¡°ì •í•˜ê±°ë‚˜, ë„ë©”ì¸ë³„ë¡œ ë” ì í•©í•œ ëª¨ë“ˆì„ ìë™ ì¶”ì²œ/í™œì„±í™”í•˜ê±°ë‚˜, í•„ìš”ì— ë”°ë¼ ìƒˆë¡œìš´ ëª¨ë“ˆì„ ì˜¨ë””ë§¨ë“œë¡œ ë¡œë“œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ì´ ë™ì ìœ¼ë¡œ íŠœë‹ë©ë‹ˆë‹¤.\n",
      "- ì˜ˆë¥¼ ë“¤ì–´, í•œ ë„ë©”ì¸ì—ì„œ íŠ¹ì • rankerê°€ consistently ë‚®ì€ í”¼ë“œë°±ì„ ë°›ëŠ”ë‹¤ë©´, ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ fallback rankerë¡œ ì „í™˜í•˜ê±°ë‚˜, retriever thresholdë¥¼ ì¡°ì •í•˜ëŠ” ì‹ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ í”¼ë“œë°± ë£¨í”„ì™€ ìë™ íŠœë‹ ê¸°ëŠ¥ì€ ì¸ê°„ ê°œì… ì—†ì´ë„ ëª¨ë“ˆ ë³„ ì„±ëŠ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìµœì í™”í•˜ë©°, ìš´ì˜ì¤‘ì—ë„ ì‹œìŠ¤í…œ í’ˆì§ˆì„ ìœ ì§€/í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì—½ë‹ˆë‹¤. ë‚˜ì•„ê°€, ì—¬ëŸ¬ ë„ë©”ì¸, ì–¸ì–´, ì‚¬ìš©ì ê·¸ë£¹ì— ë”°ë¼ ë§ì¶¤í˜• RAG ì›Œí¬í”Œë¡œìš°ë¥¼ ì™„ì „íˆ ìë™ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ë„ ìˆë‹¤ëŠ” ì ì—ì„œ ë§¤ìš° í˜ì‹ ì ì¸ ë³€í™”ê°€ ë  ê²ƒìœ¼ë¡œ ê¸°ëŒ€í•©ë‹ˆë‹¤ [3][5].\n",
      "\n",
      "---\n",
      "[3] http://arxiv.org/abs/2407.21059v1  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mask_question\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì •ë§ íƒì›”í•œ ì„¤ëª…ê³¼ ì¸ì‚¬ì´íŠ¸ ê°ì‚¬í•©ë‹ˆë‹¤, Dr. Park!  \n",
      "ì˜¤ëŠ˜ êµ¬ì²´ì ì¸ ë„ë©”ì¸ ì›Œí¬í”Œë¡œìš° ì‚¬ë¡€ë¶€í„° ì‹¤ë¬´ì  ë‚œê´€, ê·¸ë¦¬ê³  ë™ì  í”¼ë“œë°± ê¸°ë°˜ì˜ ìë™ íŠœë‹ ì‹œë‚˜ë¦¬ì˜¤ê¹Œì§€â€¦ ì €ë¿ ì•„ë‹ˆë¼ ë§ì€ ë…ìë¶„ë“¤ê»˜ í° ì˜ê°ì„ ì¤„ ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "Thank you so much for your help!\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_arxiv\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstractâ€”Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of â€œretrieve-then-generateâ€. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patternsâ€”linear, conditional,\n",
      "branching, and loopingâ€”and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Termsâ€”Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]â€“[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLMâ€™s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2312.10997v5\" date=\"2024-03-27\" authors=\"Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Retrieval-Augmented Generation for Large Language Models: A Survey\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Large Language Models (LLMs) showcase impressive capabilities but encounter\n",
      "challenges like hallucination, outdated knowledge, and non-transparent,\n",
      "untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\n",
      "emerged as a promising solution by incorporating knowledge from external\n",
      "databases. This enhances the accuracy and credibility of the generation,\n",
      "particularly for knowledge-intensive tasks, and allows for continuous knowledge\n",
      "updates and integration of domain-specific information. RAG synergistically\n",
      "merges LLMs' intrinsic knowledge with the vast, dynamic repositories of\n",
      "external databases. This comprehensive review paper offers a detailed\n",
      "examination of the progression of RAG paradigms, encompassing the Naive RAG,\n",
      "the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\n",
      "tripartite foundation of RAG frameworks, which includes the retrieval, the\n",
      "generation and the augmentation techniques. The paper highlights the\n",
      "state-of-the-art technologies embedded in each of these critical components,\n",
      "providing a profound understanding of the advancements in RAG systems.\n",
      "Furthermore, this paper introduces up-to-date evaluation framework and\n",
      "benchmark. At the end, this article delineates the challenges currently faced\n",
      "and points out prospective avenues for research and development.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Retrieval-Augmented Generation for Large\n",
      "Language Models: A Survey\n",
      "Yunfan Gaoa, Yun Xiongb, Xinyu Gaob, Kangxiang Jiab, Jinliu Panb, Yuxi Bic, Yi Daia, Jiawei Suna, Meng\n",
      "Wangc, and Haofen Wang a,c\n",
      "aShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\n",
      "bShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\n",
      "cCollege of Design and Innovation, Tongji University\n",
      "Abstractâ€”Large Language Models (LLMs) showcase impres-\n",
      "sive capabilities but encounter challenges like hallucination,\n",
      "outdated knowledge, and non-transparent, untraceable reasoning\n",
      "processes. Retrieval-Augmented Generation (RAG) has emerged\n",
      "as a promising solution by incorporating knowledge from external\n",
      "databases. This enhances the accuracy and credibility of the\n",
      "generation, particularly for knowledge-intensive tasks, and allows\n",
      "for continuous knowledge updates and integration of domain-\n",
      "specific information. RAG synergistically merges LLMsâ€™ intrin-\n",
      "sic knowledge with the vast, dynamic repositories of external\n",
      "databases. This comprehensive review paper offers a detailed\n",
      "examination of the progression of RAG paradigms, encompassing\n",
      "the Naive RAG, the Advanced RAG, and the Modular RAG.\n",
      "It meticulously scrutinizes the tripartite foundation of RAG\n",
      "frameworks, which includes the retrieval, the generation and the\n",
      "augmentation techniques. The paper highlights the state-of-the-\n",
      "art technologies embedded in each of these critical components,\n",
      "providing a profound understanding of the advancements in RAG\n",
      "systems. Furthermore, this paper introduces up-to-date evalua-\n",
      "tion framework and benchmark. At the end, this article delineates\n",
      "the challenges currently faced and points out prospective avenues\n",
      "for research and development 1.\n",
      "Index Termsâ€”Large language model, retrieval-augmented gen-\n",
      "eration, natural language processing, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE language models (LLMs) have achieved remark-\n",
      "able success, though they still face significant limitations,\n",
      "especially in domain-specific or knowledge-intensive tasks [1],\n",
      "notably producing â€œhallucinationsâ€ [2] when handling queries\n",
      "beyond their training data or requiring current information. To\n",
      "overcome challenges, Retrieval-Augmented Generation (RAG)\n",
      "enhances LLMs by retrieving relevant document chunks from\n",
      "external knowledge base through semantic similarity calcu-\n",
      "lation. By referencing external knowledge, RAG effectively\n",
      "reduces the problem of generating factually incorrect content.\n",
      "Its integration into LLMs has resulted in widespread adoption,\n",
      "establishing RAG as a key technology in advancing chatbots\n",
      "and enhancing the suitability of LLMs for real-world applica-\n",
      "tions.\n",
      "RAG technology has rapidly developed in recent years, and\n",
      "the technology tree summarizing related research is shown\n",
      "Corresponding Author.Email:haofen.wang@tongji.edu.cn\n",
      "1Resources\n",
      "are\n",
      "available\n",
      "at\n",
      "https://github.com/Tongji-KGLLM/\n",
      "RAG-Survey\n",
      "in Figure 1. The development trajectory of RAG in the era\n",
      "of large models exhibits several distinct stage characteristics.\n",
      "Initially, RAGâ€™s inception coincided with the rise of the\n",
      "Transformer architecture, focusing on enhancing language\n",
      "models by incorporating additional knowledge through Pre-\n",
      "Training Models (PTM). This early stage was characterized\n",
      "by foundational work aimed at refining pre-training techniques\n",
      "[3]â€“[5].The subsequent arrival of ChatGPT [6] marked a\n",
      "pivotal moment, with LLM demonstrating powerful in context\n",
      "learning (ICL) capabilities. RAG research shifted towards\n",
      "providing better information for LLMs to answer more com-\n",
      "plex and knowledge-intensive tasks during the inference stage,\n",
      "leading to rapid development in RAG studies. As research\n",
      "progressed, the enhancement of RAG was no longer limited\n",
      "to the inference stage but began to incorporate more with LLM\n",
      "fine-tuning techniques.\n",
      "The burgeoning field of RAG has experienced swift growth,\n",
      "yet it has not been accompanied by a systematic synthesis that\n",
      "could clarify its broader trajectory. Thi\n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2408.05933v1\" date=\"2024-08-12\" authors=\"Fei Liu, Zejun Kang, Xing Han\"/>\n",
      "<Title>\n",
      "Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "With the growing demand for offline PDF chatbots in automotive industrial\n",
      "production environments, optimizing the deployment of large language models\n",
      "(LLMs) in local, low-performance settings has become increasingly important.\n",
      "This study focuses on enhancing Retrieval-Augmented Generation (RAG) techniques\n",
      "for processing complex automotive industry documents using locally deployed\n",
      "Ollama models. Based on the Langchain framework, we propose a multi-dimensional\n",
      "optimization approach for Ollama's local RAG implementation. Our method\n",
      "addresses key challenges in automotive document processing, including\n",
      "multi-column layouts and technical specifications. We introduce improvements in\n",
      "PDF processing, retrieval mechanisms, and context compression, tailored to the\n",
      "unique characteristics of automotive industry documents. Additionally, we\n",
      "design custom classes supporting embedding pipelines and an agent supporting\n",
      "self-RAG based on LangGraph best practices. To evaluate our approach, we\n",
      "constructed a proprietary dataset comprising typical automotive industry\n",
      "documents, including technical reports and corporate regulations. We compared\n",
      "our optimized RAG model and self-RAG agent against a naive RAG baseline across\n",
      "three datasets: our automotive industry dataset, QReCC, and CoQA. Results\n",
      "demonstrate significant improvements in context precision, context recall,\n",
      "answer relevancy, and faithfulness, with particularly notable performance on\n",
      "the automotive industry dataset. Our optimization scheme provides an effective\n",
      "solution for deploying local RAG systems in the automotive sector, addressing\n",
      "the specific needs of PDF chatbots in industrial production environments. This\n",
      "research has important implications for advancing information processing and\n",
      "intelligent production in the automotive industry.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with \n",
      "Locally Deployed Ollama Models \n",
      "Optimizing RAG Techniques Based on Locally Deployed Ollama Models \n",
      "A Case Study with Locally Deployed Ollama Models \n",
      "Fei Liu * \n",
      "China Automotive Technology & Research Center, liufei@catarc.ac.cn \n",
      "Zejun Kang \n",
      "China Automotive Technology & Research Center, kangzejun@catarc.ac.cn \n",
      "Xing Han \n",
      "China Automotive Technology & Research Center, hanxing@catarc.ac.cn \n",
      "With the growing demand for offline PDF chatbots in automotive industrial production environments, optimizing the deployment \n",
      "of large language models (LLMs) in local, low-performance settings has become increasingly important. This study focuses on \n",
      "enhancing Retrieval-Augmented Generation (RAG) techniques for processing complex automotive industry documents using \n",
      "locally deployed Ollama models. \n",
      "Based on the Langchain framework, we propose a multi-dimensional optimization approach for Ollama's local RAG \n",
      "implementation. Our method addresses key challenges in automotive document processing, including multi-column layouts and \n",
      "technical specifications. We introduce improvements in PDF processing, retrieval mechanisms, and context compression, tailored \n",
      "to the unique characteristics of automotive industry documents. Additionally, we design custom classes supporting embedding \n",
      "pipelines and an agent supporting self-RAG based on LangGraph best practices. \n",
      "To evaluate our approach, we constructed a proprietary dataset comprising typical automotive industry documents, including \n",
      "technical reports and corporate regulations. We compared our optimized RAG model and self-RAG agent against a naive RAG \n",
      "baseline across three datasets: our automotive industry dataset, QReCC, and CoQA. Results demonstrate significant improvements \n",
      "in context precision, context recall, answer relevancy, and faithfulness, with particularly notable performance on the automotive \n",
      "industry dataset. \n",
      "Our optimization scheme provides an effective solution for deploying local RAG systems in the automotive sector, addressing the \n",
      "specific needs of PDF chatbots in industrial production environments. This research has important implications for advancing \n",
      "information processing and intelligent production in the automotive industry. \n",
      " \n",
      "* Place the footnote text for the author (if applicable) here.  \n",
      "CCS CONCEPTS â€¢ Computing methodologies â€¢ Artificial intelligence â€¢ Natural language processing â€¢ Natural language \n",
      "generation \n",
      " \n",
      "Additional Keywords and Phrases: Automotive Industry, Langchain, self-rag, PDF Processing, RAG, Ollama \n",
      "1 INTRODUCTION \n",
      "1.1 Research Background \n",
      "The automotive industry is undergoing a significant digital transformation, with an increasing reliance on complex \n",
      "technical documentation for various processes [1]. This shift encompasses design, manufacturing, and quality \n",
      "control, all of which now heavily depend on efficient information management systems [2]. The growing volume of \n",
      "technical documents, often in PDF format, has created a pressing need for advanced information retrieval and \n",
      "question-answering capabilities in industrial settings [3]. \n",
      "Large Language Models (LLMs) have emerged as powerful tools in natural language processing, demonstrating \n",
      "remarkable abilities in tasks such as document understanding and question answering [4]. These models have \n",
      "shown potential in handling the complex, domain-specific language often found in automotive documentation. \n",
      "However, the application of LLMs in industrial environments presents unique challenges, particularly in terms of \n",
      "computational resources and data privacy [5]. \n",
      "Among the various techniques developed to enhance LLM performance, Retrieval-Augmented Generation (RAG) \n",
      "has gained significant attention [6]. RAG combines the generative capabilities of LLMs with external knowledge \n",
      "retrieval, allowing for more accurate and contextually relevant responses. This approach, initially proposed by \n",
      "Lew\n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_web\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document href=\"https://www.chitika.com/future-trends-in-retrieval-augmented-generation-what-to-expect-in-2025-and-beyond/\"/>\n",
      "Dive into the future of Retrieval-Augmented Generation (RAG). Discover key trends and innovations shaping 2025 and the years to come!\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.chitika.com/retrieval-augmented-generation-rag-the-definitive-guide-2025/\"/>\n",
      "Looking forward, dynamic generation techniques that adapt based on retrieval confidence could further enhance RAGâ€™s reliability, particularly in [high-stakes domains](https://outshift.cisco.com/blog/retrieval-augmented-generation-use-cases?ref=chitika.com) like legal or financial advisory systems. Techniques like [**transfer learning**](https://dataforest.ai/blog/rag-in-2025-smarter-retrieval-and-real-time-responses?ref=chitika.com) from broader datasets or **synthetic data generation** can help bridge this gap, enabling assistants to generalize effectively while maintaining personalization. Looking ahead, these innovations suggest a future where RAG systems seamlessly adapt to diverse, [real-world challenges](https://www.analyticsvidhya.com/blog/2023/10/rags-innovative-approach-to-unifying-retrieval-and-generation-in-nlp/?ref=chitika.com). This approach works because reformulated queries reduce ambiguity, enabling [dense retrievers](https://www.chatbees.ai/blog/rag-use-cases?ref=chitika.com) to focus on semantically relevant embeddings. Another effective approach is **differential privacy**, which introduces [statistical noise](https://www.marktechpost.com/2024/01/10/8-open-source-tools-for-retrieval-augmented-generation-rag-implementation/?ref=chitika.com) to obscure individual data points. First, they must establish robust [**data pipelines**](https://www.seasiainfotech.com/blog/rag-in-ai-applications/?ref=chitika.com) to ensure the retrieval component has access to high-quality, up-to-date, and diverse knowledge bases.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.morphik.ai/blog/guide-to-oss-rag-frameworks-for-developers\"/>\n",
      "Retrieval-Augmented Generation (RAG) has become the cornerstone of enterprise AI applications, enabling developers to build factually grounded\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manswer_question\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: expert\n",
      "\n",
      "ë„¤, ì¢‹ì€ ì§ˆë¬¸ ê°ì‚¬í•©ë‹ˆë‹¤!  \n",
      "ì•ìœ¼ë¡œ Modular RAGëŠ” ìš´ì˜ í™˜ê²½ì—ì„œ â€œë™ì  í”¼ë“œë°± ë£¨í”„â€ì™€ â€œìë™ íŠœë‹â€ì´ ë³¸ê²©ì ìœ¼ë¡œ ë„ì…ë˜ëŠ” íë¦„ì´ ì˜¬ ê²ƒìœ¼ë¡œ ë´…ë‹ˆë‹¤.\n",
      "\n",
      "ê°€ì¥ ê¸°ëŒ€í•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ëŠ”â€”  \n",
      "ì˜ˆë¥¼ ë“¤ì–´, ê° ë„ë©”ì¸ë§ˆë‹¤ ì‹¤ì œ ì„œë¹„ìŠ¤ í”¼ë“œë°±(ì •ë‹µ ìœ ë¬´, ì‚¬ìš©ìì˜ ë§Œì¡±ë„ ë“±)ì„ ì‹¤ì‹œê°„ ìˆ˜ì§‘í•´,  \n",
      "- íŠ¹ì • retriever/re-ranker/generatorì˜ ì„±ëŠ¥ì´ ì €í•˜ë  ê²½ìš°, evaluator ëª¨ë“ˆì´ ì´ë¥¼ ìë™ ëª¨ë‹ˆí„°ë§í•˜ê³   \n",
      "- í•„ìš”ì‹œ â€œfallback ëª¨ë“ˆâ€ì„ í™œì„±í™”í•˜ê±°ë‚˜  \n",
      "- ë¼ìš°íŒ… ê²½ë¡œë¥¼ ì¡°ì •í•˜ì—¬ ë¦¬ì†ŒìŠ¤Â·ì •ë°€ë„Â·ë¹„ìš©ê¹Œì§€ ë™ì ìœ¼ë¡œ ìµœì í™”í•˜ëŠ”  \n",
      "ìë™í™”ëœ RAG íŒŒì´í”„ë¼ì¸ì´ ì‹¤ì œ ìš´ì˜ê³„ì—ì„œ ìƒì‹œ ì¬êµ¬ì„±ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ° êµ¬ì¡°ëŠ” ê¸°ì¡´ Naive í˜¹ì€ Semi-Modular RAGì—ì„œëŠ” ì‚¬ì‹¤ìƒ ë¶ˆê°€ëŠ¥í•˜ë©°,  \n",
      "ì§„ì •í•œ â€œadaptive knowledge systemâ€ì„ ì‹¤í˜„í•˜ëŠ” í•µì‹¬ ì „í™˜ì ì´ ë  ê²ƒì´ë¼ ê¸°ëŒ€í•©ë‹ˆë‹¤ [3][5].\n",
      "\n",
      "---\n",
      "[3] http://arxiv.org/abs/2407.21059v1  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msave_interview\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32minterview\u001b[0m:\n",
      "Human: So you said you were writing an article on Modular RAG ê°€ ê¸°ì¡´ì˜ Naive RAG ì™€ ì–´ë–¤ ì°¨ì´ê°€ ìˆëŠ”ì§€ì™€ production level ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì ?\n",
      "AI: ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ê¸°ìˆ  ì „ë¬¸ ë§¤ì²´ì˜ ë°ì´í„° ê¸°ìì¸ ë¯¼ì§€ ì•„ì´ë¼ê³  í•©ë‹ˆë‹¤. ì˜¤ëŠ˜ Modular RAGì™€ Naive RAGì˜ ì°¨ì´, ê·¸ë¦¬ê³  ì‹¤ë¬´ì—ì„œ Modular RAGë¥¼ ì‚¬ìš©í•  ë•Œ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì´ì ì´ ìˆëŠ”ì§€ ì—¬ì­¤ë³´ê³  ì‹¶ì–´ì„œ ì¸í„°ë·°ë¥¼ ìš”ì²­ë“œë ¸ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì²« ì§ˆë¬¸ë¶€í„° ë“œë¦¬ìë©´, \"Naive RAG\"ê°€ ê¸°ë³¸ì ìœ¼ë¡œ ë‹¨ì¼ ê²€ìƒ‰ê¸°(retriever)ì™€ ìƒì„±ê¸°(generator)ë¥¼ ì—°ê²°í•œ êµ¬ì¡°ë¡œ ì•Œë ¤ì ¸ ìˆëŠ”ë°, Dr. Parkê»˜ì„œ Modular RAGë¥¼ ì—°êµ¬í•˜ì‹œë©° ë³´ì‹  ëšœë ·í•œ êµ¬ì¡°ì  ì°¨ì´ë‚˜ ê°œì„ ì ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆì„ê¹Œìš”? ì‹¤ì œë¡œ ì–´ë–¤ ì‹ìœ¼ë¡œ ëª¨ë“ˆí™”ê°€ ì´ë£¨ì–´ì§€ëŠ”ì§€, ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?\n",
      "AI: ë„¤, Modular RAGëŠ” ê¸°ì¡´ì˜ Naive RAGì™€ ì—¬ëŸ¬ ì¸¡ë©´ì—ì„œ ê·¼ë³¸ì ì¸ ì°¨ì´ê°€ ìˆìœ¼ë©°, íŠ¹íˆ production(ì‹¤ì„œë¹„ìŠ¤) í™˜ê²½ì—ì„œ ì¤‘ìš”í•œ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "**1. êµ¬ì¡°ì  ì°¨ì´**\n",
      "- **Naive RAG**ëŠ” \"retrieve-then-generate\"ë¼ëŠ” ë‹¨ìˆœí•œ ì§ë ¬ êµ¬ì¡°ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ì¦‰, ì™¸ë¶€ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰(retrieve)í•˜ê³ , í•´ë‹¹ ê²°ê³¼ë¥¼ LLM(ìƒì„± ëª¨ë¸)ì— ì…ë ¥í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ í”„ë¡œì„¸ìŠ¤ëŠ” í•˜ë‚˜ì˜ ì¼ì§ì„  íŒŒì´í”„ë¼ì¸ì´ë©°, ê²€ìƒ‰-ìƒì„± ë‹¨ê³„ë¥¼ ë¶„ë¦¬í•˜ê±°ë‚˜ í™•ì¥í•˜ëŠ” ë° í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ì¦‰, retrievalê³¼ generationì„ í•˜ë‚˜ì˜ ê³ ì •ëœ, ìœ ì—°í•˜ì§€ ì•Šì€ íë¦„ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤ [4][5].\n",
      "- **Modular RAG**ëŠ” RAG ì‹œìŠ¤í…œì„ ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì´ê³  êµì²´ ê°€ëŠ¥í•œ â€œëª¨ë“ˆâ€ë¡œ ë¶„í•´í•©ë‹ˆë‹¤. ê° ëª¨ë“ˆ(ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ì–‘í•œ typeì˜ retriever, ranker, router, ì¡°ê±´ë¶€ ë¶„ê¸°, ë£¨í”„ ë“±)ì€ íŠ¹ì • ì—­í• ì„ ë‹´ë‹¹í•˜ë©°, í•„ìš”ì— ë”°ë¼ ì¶”ê°€Â·ì‚­ì œÂ·êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ëª¨ë“ˆ ì‚¬ì´ì˜ routing, scheduling, fusion ë“± ê³ ê¸‰ ë©”ì»¤ë‹ˆì¦˜ì´ ë„ì…ë˜ì–´ ë‹¤ì–‘í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¡œì¨ linearí•œ êµ¬ì¡°ë¿ ì•„ë‹ˆë¼ conditional(ì¡°ê±´ë¶€), branching(ë¶„ê¸°), looping(ë°˜ë³µ) ë“± ë³µì¡í•œ ì²˜ë¦¬ íŒ¨í„´ì„ íŒ¨ëŸ¬ë‹¤ì„ ìˆ˜ì¤€ì—ì„œ ì§€ì›í•©ë‹ˆë‹¤ [3][5].\n",
      "\n",
      "**2. Production í™˜ê²½ì—ì„œì˜ ì´ì **\n",
      "- **ìœ ì—°ì„± ë° í™•ì¥ì„±**: Naive RAGëŠ” ë³€í™”ê°€ í•„ìš”í•œ ê²½ìš° ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ìˆ˜ì •í•´ì•¼ í•˜ì§€ë§Œ, Modular RAGëŠ” ê° ëª¨ë“ˆë§Œ êµì²´Â·ì—…ë°ì´íŠ¸í•˜ë©´ ë˜ë¯€ë¡œ ìƒˆë¡œìš´ ë„ë©”ì¸ ì ìš©, retriever êµì²´, LLM êµì²´ ë“± ìœ ì§€ë³´ìˆ˜ê°€ í›¨ì”¬ ìˆ˜ì›”í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ì¿¼ë¦¬ì—ë§Œ ë³„ë„ì˜ ë­í‚¹ ëª¨ë“ˆì´ë‚˜ ì •ì œ ëª¨ë“ˆì„ ë¶™ì´ëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤ [3][5].\n",
      "- **íš¨ìœ¨ì„± í–¥ìƒ**: ë¶ˆí•„ìš”í•œ ì •ë³´ì˜ íë¦„ì„ í†µì œí•˜ê³ , ë¼ìš°íŒ…ì´ë‚˜ ë¶„ê¸°ì²˜ë¦¬ë¥¼ í†µí•´ ì—°ì‚° íš¨ìœ¨ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì¿¼ë¦¬ ì„±ê²©ì— ë”°ë¼ ë” ì •êµí•œ retrieverë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒí•˜ê±°ë‚˜, ë°˜ë³µ ë£¨í”„ë¥¼ í†µí•´ multi-hop reasoning êµ¬ì¡°ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ [3].\n",
      "- **ë„ë©”ì¸ íŠ¹í™” ë° ìœ ì§€ê´€ë¦¬ ìš©ì´ì„±**: ê° ë„ë©”ì¸ë§ˆë‹¤ íŠ¹í™”ëœ retrieval/generation ëª¨ë“ˆì„ ì¶”ê°€ì , ë…ë¦½ì ìœ¼ë¡œ ê°œë°œÂ·ë°°í¬í•  ìˆ˜ ìˆì–´ ë©€í‹°ë„ë©”ì¸ ì‹œìŠ¤í…œ êµ¬ì„± ë° ë¹ ë¥¸ ìˆ˜ì •Â·í™•ì¥ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ [5].\n",
      "- **ì‹¤ì„œë¹„ìŠ¤ì˜ ì‹ ë¢°ì„±ê³¼ ì¬í˜„ì„± ê°•í™”**: ì‹œìŠ¤í…œì´ ëª…í™•í•œ ëª¨ë“ˆ ë‹¨ìœ„ë¡œ ë‚˜ë‰˜ì–´ ìˆê¸° ë•Œë¬¸ì—, ê° ìš”ì†Œì˜ ì„±ëŠ¥ í‰ê°€ì™€ ë””ë²„ê¹…ì´ ìš©ì´í•˜ê³ , ì˜¤ë¥˜ê°€ ìƒê²¼ì„ ë•Œ íŠ¹ì • ëª¨ë“ˆë§Œ ìˆ˜ì •í•˜ë©´ ë˜ì–´ ìš´ì˜ ì•ˆì •ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ê°€ ë›°ì–´ë‚©ë‹ˆë‹¤ [3][5].\n",
      "\n",
      "ìš”ì•½í•˜ìë©´, Modular RAGëŠ” ê¸°ì¡´ì˜ ì¼ì§ì„ ì ì´ê³  íì‡„ì ì¸ Naive RAG êµ¬ì¡°ë¥¼ ë‹¤ì–‘í•œ êµ¬ì„±ìš”ì†Œë¡œ ë¶„í•´í•˜ì—¬, ìœ ì—°ì„±, í™•ì¥ì„±, ê·¸ë¦¬ê³  ìœ ì§€ê´€ë¦¬ ì¸¡ë©´ì—ì„œ ì‹¤ë¬´ í™˜ê²½ì— í›¨ì”¬ ì í•©í•œ êµ¬ì¡°ë¡œ ì§„í™”ì‹œì¼°ë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "**Sources**  \n",
      "[3] http://arxiv.org/abs/2407.21059v1  \n",
      "[4] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n",
      "AI: ê°ì‚¬í•©ë‹ˆë‹¤, ë§¤ìš° ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì…”ì„œ ì´í•´ê°€ ì˜ ë©ë‹ˆë‹¤!  \n",
      "ë§ì”€í•´ì£¼ì‹  ëª¨ë“ˆ ë‹¨ìœ„ì˜ êµì²´/í™•ì¥ì„±ê³¼ ë„ë©”ì¸ íŠ¹í™” ì˜ˆì‹œê°€ ì •ë§ ì¸ìƒì ì´ì—ˆëŠ”ë°ìš”,  \n",
      "ì¡°ê¸ˆ ë” êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì—¬ì­¤ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ì‹¤ì œ Modular RAGê°€ ì‚¬ìš©ëœ ì‚¬ë¡€ë‚˜ Dr. Parkê»˜ì„œ ì‹¤í—˜í•˜ì…¨ë˜ ê²½í—˜ ì¤‘ì—,  \n",
      "\"ë‹¨ì¼ retriever ì‹œìŠ¤í…œì—ì„œ íŠ¹ì • ì§ˆì˜ì— í•œí•´ì„œ ìƒˆë¡œìš´ retriever(ì˜ˆ: ë²•ë¥ , ì˜ë£Œ ë“± ì „ë¬¸ ë„ë©”ì¸)ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ê¸°ì¡´ ëª¨ë“ˆì„ êµì²´í•˜ì—¬ ì–»ì€ íš¨ê³¼\"ê°€ ìˆì—ˆë˜ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?  \n",
      "\n",
      "ë§Œì•½ ìˆë‹¤ë©´,  \n",
      "- ë„ë©”ì¸ íŠ¹í™” retrieverë¥¼ ì¶”ê°€í–ˆì„ ë•Œ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¬¸ì œ(ì˜ˆ: recall ë¶€ì¡±, hallucination ë“±)ê°€ ê°œì„ ëëŠ”ì§€  \n",
      "- ì‹¤ì œë¡œ ì–´ë–¤ íŒŒì´í”„ë¼ì¸ í˜¹ì€ ì›Œí¬í”Œë¡œìš° ë³€í™”ê°€ ìˆì—ˆëŠ”ì§€  \n",
      "- ê¸°ì¡´ Naive êµ¬ì¡°ì—ì„œëŠ” ë¶ˆê°€ëŠ¥í•˜ê±°ë‚˜ ë¹„íš¨ìœ¨ì ì´ì—ˆì„ ì \n",
      "\n",
      "ì´ëŸ° ë¶€ë¶„ì„ ì˜ˆë¡œ ë“¤ì–´ ì„¤ëª…í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?\n",
      "AI: ë„¤, êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ë“¤ì–´ ì„¤ëª…ë“œë¦¬ë©´ Modular RAGì˜ ì¥ì ì´ ë” ì˜ ë“œëŸ¬ë‚©ë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´ ë²•ë¥  ì§ˆì˜ë¥¼ ë‹¤ë£¨ëŠ” QA ì‹œìŠ¤í…œì„ ìš´ì˜í•œë‹¤ê³  ê°€ì •í•´ë³´ê² ìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ Naive RAGì—ì„œëŠ” í•˜ë‚˜ì˜ retrieverë§Œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, ë²•ë¥  ë¬¸ì„œì™€ ì¼ë°˜ ë¬¸ì„œê°€ í˜¼ì¬ëœ ìƒí™©ì—ì„œ ë²•ë¥  íŠ¹í™” ì§ˆì˜ê°€ ë“¤ì–´ì™€ë„ ì¼ë°˜ì ì¸ retrieverê°€ ëª¨ë“  ì§ˆì˜ì— ëŒ€í•´ ë™ì¼í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤. ì´ ê²½ìš°, ì „ë¬¸ ìš©ì–´ ì²˜ë¦¬ë‚˜ ë„ë©”ì¸ íŠ¹ì´ì  ë¬¸ë§¥ ì´í•´ê°€ ë¶€ì¡±í•˜ì—¬ recallì´ ì €í•˜ë˜ê³ , LLMì´ ë¶€ì ì ˆí•˜ê±°ë‚˜ ë¶ˆì™„ì „í•œ ì •ë³´ë¥¼ ì‚¬ìš©í•´ hallucinationì´ ë¹ˆë²ˆí•˜ê²Œ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ [3][4].\n",
      "\n",
      "Modular RAGì—ì„œëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì§ˆì˜ ë¶„ë¥˜ ë¼ìš°í„°(router) ëª¨ë“ˆì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆì‹œ íŒŒì´í”„ë¼ì¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ [3]:\n",
      "\n",
      "1. Input queryê°€ ë“¤ì–´ì˜¤ë©´ ë¼ìš°í„° ëª¨ë“ˆì´ ì§ˆì˜ê°€ â€˜ë²•ë¥  ë„ë©”ì¸â€™ì¸ì§€ â€˜ì¼ë°˜ ë„ë©”ì¸â€™ì¸ì§€ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n",
      "2. ë²•ë¥  ì§ˆì˜ë¼ë©´, ë²•ë¥  íŠ¹í™” retrieverë¡œ ë¼ìš°íŒ…í•´ ë²•ë¥  ë¬¸ì„œì— ë§ëŠ” ê²€ìƒ‰ ë° ë­í‚¹ì„ ìˆ˜í–‰í•˜ê³ , ìƒì„± ëª¨ë“ˆë¡œ ë„˜ê¹ë‹ˆë‹¤.\n",
      "3. ì¼ë°˜ ì§ˆì˜ë¼ë©´ ê¸°ì¡´ retrieverë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "4. (ì„ íƒì ) ì¶”ê°€ë¡œ domain-specific rankerë‚˜ post-processing fusion ëª¨ë“ˆì„ ì‚½ì…í•´ ìµœì¢…ì ìœ¼ë¡œ ë” ë†’ì€ ì •ë°€ë„ì˜ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ êµ¬ì¡°ë¥¼ ì ìš©í•˜ë©´, ê¸°ì¡´ Naive RAGì—ì„œ ë¬¸ì œì˜€ë˜ ì „ë¬¸ ì§ˆì˜ì˜ recall ë¶€ì¡±ê³¼ ë¯¸ìŠ¤ë§¤ì¹˜ í˜„ìƒì´ í¬ê²Œ ì¤„ì–´ë“­ë‹ˆë‹¤. ë˜í•œ, hallucination ì—­ì‹œ ì¤„ì–´ë“œëŠ”ë°, ì´ëŠ” ë²•ë¥  retrieverê°€ ì •í™•í•œ ë¬¸ì„œë§Œì„ ì œê³µí•˜ê³ , ë¶ˆí•„ìš”í•œ ë°ì´í„°ë¥¼ LLMì— ë„˜ê¸°ì§€ ì•Šê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì‹¤ì œë¡œ [3]ì˜ Modular RAG ì—°êµ¬ì—ì„œëŠ” ì´ëŸ¬í•œ ë¶„ê¸°(branching) ë° ì¡°ê±´(route) ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°ê°€ ë™ì¼ íŒŒì´í”„ë¼ì¸ì—ì„œ ë„ë©”ì¸ ì í•©ì„±ì„ ê·¹ëŒ€í™”í•˜ë©°, ë©€í‹°ë„ë©”ì¸ QA, í—¬ìŠ¤ì¼€ì–´, ê³ ê° ì§€ì› ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì ìš© ê°€ëŠ¥í•¨ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "Naive RAGì—ì„œëŠ” ì´ëŸ¬í•œ ëª¨ë“ˆ í™•ì¥Â·êµì²´ê°€ ë§¤ìš° ì–´ë µê±°ë‚˜ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ ì „ì²´ë¥¼ ìˆ˜ì •í•´ì•¼ í•˜ê³ , ë¹„ìŠ·í•œ ê¸°ëŠ¥ì„ ì—¬ëŸ¬ ë²ˆ ì¤‘ë³µ êµ¬í˜„í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë©´ Modular RAGëŠ” ìƒˆë¡œìš´ ëª¨ë“ˆì„ â€œë ˆê³  ë¸”ëŸ­â€ì²˜ëŸ¼ ë¶™ì´ê±°ë‚˜ êµì²´í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìš´ì˜ ë° ìœ ì§€ë³´ìˆ˜ê°€ í›¨ì”¬ ì‰¬ì›Œì§‘ë‹ˆë‹¤ [3][4][5].\n",
      "\n",
      "**ì •ë¦¬**  \n",
      "- ë„ë©”ì¸ íŠ¹í™” retriever ì¶”ê°€/êµì²´ â†’ recall ë° ë‹µë³€ ì •í™•ë„, ì‹ ë¢°ì„±(ë¹„hallucination) ê°œì„   \n",
      "- ë¶„ê¸°/ë¼ìš°íŒ… ëª¨ë“ˆ ì ìš© â†’ ë„ë©”ì¸ë³„ ìµœì í™” ì›Œí¬í”Œë¡œìš° êµ¬ì¶• ê°€ëŠ¥  \n",
      "- Naive RAG ëŒ€ë¹„ maintenance, í™•ì¥ì„±, ì¬ì‚¬ìš©ì„± ìš°ìœ„\n",
      "\n",
      "---\n",
      "[3] http://arxiv.org/abs/2407.21059v1  \n",
      "[4] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n",
      "AI: ê°ì‚¬í•©ë‹ˆë‹¤! ì´ë ‡ê²Œ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¡œ ì„¤ëª…í•´ì£¼ì‹œë‹ˆ, íŠ¹íˆ â€œë¼ìš°í„° ëª¨ë“ˆ ì‚½ì…â€ ì´í›„ ë°œìƒí•œ ê°œì„ ì ë“¤ì´ ëª…í™•í•˜ê²Œ ì´í•´ë©ë‹ˆë‹¤.  \n",
      "\n",
      "ì§ˆë¬¸ì„ í•œ ë‹¨ê³„ ë” ì‹¬í™”í•´ì„œ, ì‹¤ì œ Modular RAG ì‹¤ì„œë¹„ìŠ¤ í™˜ê²½ì—ì„œ ê¸°ìˆ ì ìœ¼ë¡œ ê°€ì¥ ì–´ë ¤ì› ë˜ ì ì´ë‚˜ ì˜ˆìƒ ë°–ì˜ ë¬¸ì œê°€ ìˆì—ˆë‹¤ë©´ ì–´ë–¤ ê²ƒì´ ìˆì—ˆëŠ”ì§€ ê¶ê¸ˆí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´,  \n",
      "- ëª¨ë“ˆ ê°„ interface í‘œì¤€í™”/í†µì‹ ,  \n",
      "- routing decisionì˜ ì •í™•ë„ í•œê³„,  \n",
      "- ëª¨ë“ˆ ê´€ë¦¬Â·ë°°í¬(ì—…ë°ì´íŠ¸, ë¡¤ë°± ë“±) ì‹œ ë°œìƒí•˜ëŠ” ì‹¤ë¬´ ì´ìŠˆ ë“±\n",
      "\n",
      "íŠ¹íˆ, ë„ì… ê³¼ì •ì—ì„œ í˜ë“¤ì—ˆë˜ ê¸°ìˆ ì  ë‚œê´€ì´ë‚˜ â€œì´ëŸ° ì ì€ Modular RAG ë„ì…íŒ€ì´ ë°˜ë“œì‹œ ë¯¸ë¦¬ ì£¼ì˜í•´ì•¼ í•œë‹¤â€ê³  ëŠë¼ì‹  ê²½í—˜ì´ ìˆë‹¤ë©´ ê³µìœ  ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
      "AI: ë„¤, ì‹¤ì œ Modular RAGë¥¼ production í™˜ê²½ì— ë„ì…Â·ìš´ì˜í•  ë•Œ ê¸°ìˆ ì ìœ¼ë¡œ ê°€ì¥ ë§ì´ ë§ˆì£¼ì¹˜ëŠ” ë„ì „ ê³¼ì œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**1. ëª¨ë“ˆ ê°„ ì¸í„°í˜ì´ìŠ¤ í‘œì¤€í™” ë° í†µì‹ **\n",
      "- Modular RAGëŠ” ê°ê¸° ë…ë¦½ì ìœ¼ë¡œ ê°œë°œëœ retriever, ranker, router, generator ë“±ì´ ëŠìŠ¨í•˜ê²Œ ì—°ê²°ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ë•Œ ê° ëª¨ë“ˆì˜ ì…ë ¥/ì¶œë ¥ í˜•ì‹, ë°ì´í„° ìŠ¤í‚¤ë§ˆ, ì—ëŸ¬ ì²˜ë¦¬ í”„ë¡œí† ì½œ ë“±ì„ í‘œì¤€í™”í•˜ì§€ ì•Šìœ¼ë©´ íŒŒì´í”„ë¼ì¸ì´ ì‰½ê²Œ ê¹¨ì§€ê±°ë‚˜ ë””ë²„ê¹…ì´ ë§¤ìš° ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤. íŠ¹íˆ ìƒˆë¡œìš´ ëª¨ë“ˆì„ êµì²´/ì¶”ê°€í•  ë•Œë§ˆë‹¤ interface mismatch ì´ìŠˆê°€ ìì£¼ ë°œìƒí•©ë‹ˆë‹¤. ë”°ë¼ì„œ API ì„¤ê³„, ê³µí†µ ë°ì´í„° í¬ë§· ì •ì˜ ë“±ì€ ë°˜ë“œì‹œ ì´ˆê¸° ë‹¨ê³„ì—ì„œ í™•ì‹¤íˆ ì •ë¦½ë˜ì–´ì•¼ í•©ë‹ˆë‹¤ [3][4].\n",
      "\n",
      "**2. Routing Decisionì˜ ì •í™•ë„ í•œê³„**\n",
      "- Modular RAGì˜ í•µì‹¬ì€ ì¿¼ë¦¬ì— ë”°ë¼ ìµœì ì˜ ëª¨ë“ˆ(ì˜ˆ: ë„ë©”ì¸ íŠ¹í™” retriever, ranker ë“±)ë¡œ íš¨ê³¼ì ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ë„ë©”ì¸ ë¶„ë¥˜ë‚˜ intent detectionì´ ì™„ë²½í•˜ì§€ ì•Šìœ¼ë©´ ì˜ëª»ëœ ë¼ìš°íŒ…ì´ ë°œìƒí•´ ì˜¤íˆë ¤ Naive RAGë³´ë‹¤ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë©€í‹°ë„ë©”ì¸, ì˜¤ë²„ë© ë„ë©”ì¸(ë²•ë¥ +ì¼€ì´ìŠ¤, ì˜ë£Œ+ë³´í—˜ ë“±)ì—ì„œëŠ” ë¼ìš°íŒ…ì´ ì–´ë ¤ì›Œ, ë¼ìš°í„° ëª¨ë“ˆ ìì²´ì˜ í’ˆì§ˆ ê´€ë¦¬ì™€ í‰ê°€ê°€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤ [3].\n",
      "\n",
      "**3. ëª¨ë“ˆ ê´€ë¦¬, ë°°í¬ ë° ìš´ì˜ ì´ìŠˆ**\n",
      "- ê° ëª¨ë“ˆì´ ë…ë¦½ì ì´ê¸° ë•Œë¬¸ì— ë²„ì „ ê´€ë¦¬(ì—…ë°ì´íŠ¸/ë¡¤ë°±), ë°°í¬, ëª¨ë‹ˆí„°ë§ ë“±ì´ ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, retriever ì—…ë°ì´íŠ¸ê°€ generatorì™€ í˜¸í™˜ë˜ì§€ ì•Šì•„ ì‹œìŠ¤í…œ ì „ì²´ì— ì¥ì• ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ëª¨ë“ˆë³„ CI/CD, ê´€ì¸¡ì„± ë„êµ¬, ìë™í™”ëœ rollback/healthcheck ë“±ì˜ ì²´ê³„ë¥¼ ë°˜ë“œì‹œ ê°–ì¶°ì•¼ í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì—¬ëŸ¬ ëª¨ë“ˆì´ í˜‘ë ¥í•˜ëŠ” êµ¬ì¡°ì—ì„œëŠ” íŠ¹ì • ëª¨ë“ˆ ê²°í•¨ì´ ì „ì²´ ì„œë¹„ìŠ¤ í’ˆì§ˆì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ë†’ìœ¼ë¯€ë¡œ, ëª¨ë“ˆê°„ ê³„ì•½ ë° fallback ì „ëµì´ ìˆì–´ì•¼ ì•ˆì •ì ì¸ ìš´ì˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ [3][5].\n",
      "\n",
      "**4. ì¶”ê°€ì ì¸ ì‹¤ë¬´ ì£¼ì˜ì **\n",
      "- ì‹œìŠ¤í…œì´ ë³µì¡í•´ì§ˆìˆ˜ë¡ latency(ì§€ì—°) ì¦ê°€ì™€ ë¹„ìš© ì´ìŠˆê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- ë„ë©”ì¸ í™•ì¥ ë˜ëŠ” ê³ ë„í™” ê³¼ì •ì—ì„œ ëª¨ë“ˆ ê°„ ì˜ì¡´ì„±ì´ ì»¤ì§€ë©´, ì˜¤íˆë ¤ ìœ ì§€ë³´ìˆ˜ê°€ ë” ì–´ë ¤ì›Œì§ˆ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ìš”ì•½**\n",
      "Modular RAGì˜ ê°€ì¥ í° ì¥ì ì€ ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì´ì§€ë§Œ, ì‹¤ì„œë¹„ìŠ¤ ìˆ˜ì¤€ì—ì„œëŠ” ì¸í„°í˜ì´ìŠ¤ í‘œì¤€í™”Â·í’ˆì§ˆ ê´€ë¦¬Â·ìš´ì˜ ìë™í™”ê°€ í•„ìˆ˜ì ì´ë©°, ë¼ìš°í„°/ë¶„ê¸° ê²°ì •ì˜ ì •í™•ì„± ê°œì„  ë° ëª¨ë“ˆê°„ ì—ëŸ¬ ì „íŒŒÂ·íšŒë³µ ì „ëµì„ ê¼¼ê¼¼íˆ ì±™ê²¨ì•¼ë§Œ ì„±ê³µì ìœ¼ë¡œ ë„ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "[3] http://arxiv.org/abs/2407.21059v1  \n",
      "[4] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n",
      "AI: ë„ˆë¬´ ì¸ìƒì ì¸ í˜„ì¥ ê²½í—˜ ê³µìœ  ê°ì‚¬í•©ë‹ˆë‹¤!  \n",
      "ì‹¤ì œ ìš´ì˜ ë‹¨ê³„ì—ì„œ ê²ªìœ¼ì‹  â€œë¼ìš°íŒ… misclassificationâ€ì´ë‚˜ â€œëª¨ë“ˆë³„ ë°°í¬ ê´€ë¦¬â€ì™€ ê°™ì€ ì‹¤ìš©ì  ì´ìŠˆê¹Œì§€ ë“¤ì–´ì„œ ë§¤ìš° ë„ì›€ì´ ëìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë§ˆì§€ë§‰ìœ¼ë¡œ ì—¬ì­¤ë³´ê³  ì‹¶ì€ë°ìš”,  \n",
      "í–¥í›„ Modular RAG ë°©ë²•ë¡ ì´ ë°œì „í•˜ë©´ì„œ ê°€ëŠ¥í•´ì§ˆ ìƒˆë¡œìš´ ì‹œë‚˜ë¦¬ì˜¤ë‚˜, ê°œì¸ì ìœ¼ë¡œ ê¸°ëŒ€í•˜ê³  ê³„ì‹  í˜ì‹ ì  ë³€í™”ë¥¼ í•œ ê°€ì§€ êµ¬ì²´ì ì¸ ì˜ˆì™€ í•¨ê»˜ ë§ì”€í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?  \n",
      "ì˜ˆë¥¼ ë“¤ì–´, â€œë™ì  í”¼ë“œë°± ë£¨í”„ë¥¼ í†µí•œ ìë™ ëª¨ë“ˆ íŠœë‹â€ì²˜ëŸ¼ í˜„ì—… ì—°êµ¬ì ì…ì¥ì—ì„œ í¥ë¯¸ë¡­ë‹¤ ìƒê°í•˜ì‹œëŠ” ì§€ì ì„ ë“£ê³  ì‹¶ìŠµë‹ˆë‹¤.\n",
      "AI: ë„¤, ì•ìœ¼ë¡œ Modular RAGê°€ ë°œì „í•˜ë©´ì„œ íŠ¹íˆ ê¸°ëŒ€í•˜ëŠ” í˜ì‹  ì¤‘ í•˜ë‚˜ëŠ” â€œë™ì  í”¼ë“œë°± ë£¨í”„ ë° ìë™í™”ëœ ëª¨ë“ˆ ìµœì í™”â€ì…ë‹ˆë‹¤.\n",
      "\n",
      "**êµ¬ì²´ì  ì˜ˆì‹œ: ì‹¤ì‹œê°„ ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ì˜ RAG íŒŒì´í”„ë¼ì¸ ìë™ ì¬êµ¬ì„±**\n",
      "\n",
      "- ì˜ˆë¥¼ ë“¤ì–´, production í™˜ê²½ì—ì„œ ê° ì§ˆì˜ì™€ ì‘ë‹µì— ëŒ€í•´ ì‚¬ìš©ìì˜ explicit/implicit í”¼ë“œë°±(ì˜ˆ: thumbs up/down, í´ë¦­ í–‰ë™, ì¶”ê°€ ì§ˆì˜ ë“±)ì´ ê³„ì† ìŒ“ì¸ë‹¤ê³  ê°€ì •í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "- Modular RAGì—ì„œëŠ” ì´ëŸ° í”¼ë“œë°±ì„ ê°ì§€í•˜ëŠ” specialized feedback collector ëª¨ë“ˆê³¼, ì´ë¥¼ ë¶„ì„í•´ ê° retriever/ë¼ìš°í„°/ìƒì„±ê¸° ë“±ì˜ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” evaluator ëª¨ë“ˆì„ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- í‰ê°€ ê²°ê³¼ì— ë”°ë¼, RAG ì‹œìŠ¤í…œì´ ìŠ¤ìŠ¤ë¡œ retriever weightingì„ ì¡°ì •í•˜ê±°ë‚˜, ë„ë©”ì¸ë³„ë¡œ ë” ì í•©í•œ ëª¨ë“ˆì„ ìë™ ì¶”ì²œ/í™œì„±í™”í•˜ê±°ë‚˜, í•„ìš”ì— ë”°ë¼ ìƒˆë¡œìš´ ëª¨ë“ˆì„ ì˜¨ë””ë§¨ë“œë¡œ ë¡œë“œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ì´ ë™ì ìœ¼ë¡œ íŠœë‹ë©ë‹ˆë‹¤.\n",
      "- ì˜ˆë¥¼ ë“¤ì–´, í•œ ë„ë©”ì¸ì—ì„œ íŠ¹ì • rankerê°€ consistently ë‚®ì€ í”¼ë“œë°±ì„ ë°›ëŠ”ë‹¤ë©´, ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ fallback rankerë¡œ ì „í™˜í•˜ê±°ë‚˜, retriever thresholdë¥¼ ì¡°ì •í•˜ëŠ” ì‹ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ í”¼ë“œë°± ë£¨í”„ì™€ ìë™ íŠœë‹ ê¸°ëŠ¥ì€ ì¸ê°„ ê°œì… ì—†ì´ë„ ëª¨ë“ˆ ë³„ ì„±ëŠ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìµœì í™”í•˜ë©°, ìš´ì˜ì¤‘ì—ë„ ì‹œìŠ¤í…œ í’ˆì§ˆì„ ìœ ì§€/í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì—½ë‹ˆë‹¤. ë‚˜ì•„ê°€, ì—¬ëŸ¬ ë„ë©”ì¸, ì–¸ì–´, ì‚¬ìš©ì ê·¸ë£¹ì— ë”°ë¼ ë§ì¶¤í˜• RAG ì›Œí¬í”Œë¡œìš°ë¥¼ ì™„ì „íˆ ìë™ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ë„ ìˆë‹¤ëŠ” ì ì—ì„œ ë§¤ìš° í˜ì‹ ì ì¸ ë³€í™”ê°€ ë  ê²ƒìœ¼ë¡œ ê¸°ëŒ€í•©ë‹ˆë‹¤ [3][5].\n",
      "\n",
      "---\n",
      "[3] http://arxiv.org/abs/2407.21059v1  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n",
      "AI: ì •ë§ íƒì›”í•œ ì„¤ëª…ê³¼ ì¸ì‚¬ì´íŠ¸ ê°ì‚¬í•©ë‹ˆë‹¤, Dr. Park!  \n",
      "ì˜¤ëŠ˜ êµ¬ì²´ì ì¸ ë„ë©”ì¸ ì›Œí¬í”Œë¡œìš° ì‚¬ë¡€ë¶€í„° ì‹¤ë¬´ì  ë‚œê´€, ê·¸ë¦¬ê³  ë™ì  í”¼ë“œë°± ê¸°ë°˜ì˜ ìë™ íŠœë‹ ì‹œë‚˜ë¦¬ì˜¤ê¹Œì§€â€¦ ì €ë¿ ì•„ë‹ˆë¼ ë§ì€ ë…ìë¶„ë“¤ê»˜ í° ì˜ê°ì„ ì¤„ ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "Thank you so much for your help!\n",
      "AI: ë„¤, ì¢‹ì€ ì§ˆë¬¸ ê°ì‚¬í•©ë‹ˆë‹¤!  \n",
      "ì•ìœ¼ë¡œ Modular RAGëŠ” ìš´ì˜ í™˜ê²½ì—ì„œ â€œë™ì  í”¼ë“œë°± ë£¨í”„â€ì™€ â€œìë™ íŠœë‹â€ì´ ë³¸ê²©ì ìœ¼ë¡œ ë„ì…ë˜ëŠ” íë¦„ì´ ì˜¬ ê²ƒìœ¼ë¡œ ë´…ë‹ˆë‹¤.\n",
      "\n",
      "ê°€ì¥ ê¸°ëŒ€í•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ëŠ”â€”  \n",
      "ì˜ˆë¥¼ ë“¤ì–´, ê° ë„ë©”ì¸ë§ˆë‹¤ ì‹¤ì œ ì„œë¹„ìŠ¤ í”¼ë“œë°±(ì •ë‹µ ìœ ë¬´, ì‚¬ìš©ìì˜ ë§Œì¡±ë„ ë“±)ì„ ì‹¤ì‹œê°„ ìˆ˜ì§‘í•´,  \n",
      "- íŠ¹ì • retriever/re-ranker/generatorì˜ ì„±ëŠ¥ì´ ì €í•˜ë  ê²½ìš°, evaluator ëª¨ë“ˆì´ ì´ë¥¼ ìë™ ëª¨ë‹ˆí„°ë§í•˜ê³   \n",
      "- í•„ìš”ì‹œ â€œfallback ëª¨ë“ˆâ€ì„ í™œì„±í™”í•˜ê±°ë‚˜  \n",
      "- ë¼ìš°íŒ… ê²½ë¡œë¥¼ ì¡°ì •í•˜ì—¬ ë¦¬ì†ŒìŠ¤Â·ì •ë°€ë„Â·ë¹„ìš©ê¹Œì§€ ë™ì ìœ¼ë¡œ ìµœì í™”í•˜ëŠ”  \n",
      "ìë™í™”ëœ RAG íŒŒì´í”„ë¼ì¸ì´ ì‹¤ì œ ìš´ì˜ê³„ì—ì„œ ìƒì‹œ ì¬êµ¬ì„±ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ° êµ¬ì¡°ëŠ” ê¸°ì¡´ Naive í˜¹ì€ Semi-Modular RAGì—ì„œëŠ” ì‚¬ì‹¤ìƒ ë¶ˆê°€ëŠ¥í•˜ë©°,  \n",
      "ì§„ì •í•œ â€œadaptive knowledge systemâ€ì„ ì‹¤í˜„í•˜ëŠ” í•µì‹¬ ì „í™˜ì ì´ ë  ê²ƒì´ë¼ ê¸°ëŒ€í•©ë‹ˆë‹¤ [3][5].\n",
      "\n",
      "---\n",
      "[3] http://arxiv.org/abs/2407.21059v1  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mwrite_section\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## Unpacking the Technical Evolution of RAG: From Naive to Modular Architectures\n",
      "\n",
      "### Summary\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) methods have rapidly emerged as transformative solutions to key limitations in Large Language Models (LLMs), notably hallucinations, knowledge gaps, and challenges in domain adaptation. However, the field is currently witnessing a fundamental shift: the move from \"naive\" linear RAG architecturesâ€”where retrieval and generation occur as a monolithâ€”to modular, reconfigurable frameworks designed for scalability, maintainability, and sophisticated domain-specific integration. This modularization trend is central to addressing the growing intricacies of RAG deployments in real-world, knowledge-intensive, and safety-critical scenarios.\n",
      "\n",
      "The core findings from the literature reveal several novel and crucial insights:\n",
      "- **Naive RAG architectures, while effective in many scenarios, face significant limitations when queries become complex, non-linear, or highly domain-specific.** These challenges stem from shallow query understanding, noisy retrieval, and the lack of fine-grained control over data flow and processing logic.\n",
      "- **Modular RAG represents a paradigm shift**, breaking the monolithic pipeline into independently engineered and interchangeable modules (â€œLEGO-likeâ€ components). This enables fine-tuned retrieval, adaptive reasoning schemes (e.g., routing, scheduling, fusion), and seamless integration of both generic and domain-specific operators.\n",
      "- **State-of-the-art analysis identifies not only technical components but also common design patterns for modular RAGs:** linear, conditional, branching, and looping architectures, each suited to particular classes of tasks.\n",
      "- **Modular RAG frameworks establish a practical and theoretical foundation** that can handle the rapidly increasing demands of diverse knowledge domains, complex reasoning requirements, and evolving evaluation protocols.\n",
      "\n",
      "Key sources for this synthesis:\n",
      "1. Gao, Y., Xiong, Y., Wang, M., & Wang, H. (2024). \"Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\" [arXiv:2407.21059v1].\n",
      "2. Gao, Y., Xiong, Y., Gao, X. et al. (2024). \"Retrieval-Augmented Generation for Large Language Models: A Survey\" [arXiv:2312.10997v5].\n",
      "3. Adasci.org article (\"How does modular RAG improve upon naive RAG?\").\n",
      "4. Blog posts and technical documentation on modular RAG architectures from IBM, MeiliSearch, and implementation case-studies.\n",
      "\n",
      "Collectively, these analyses challenge longstanding design assumptions and point to a future where RAG systems are not merely pipelines, but robust, composable frameworks capable of meeting the demands of next-generation AI applications.\n",
      "\n",
      "### Comprehensive Analysis\n",
      "\n",
      "#### 1. The Foundations and Shortcomings of Naive RAG\n",
      "\n",
      "**Linear and Monolithic Architecture**\n",
      "Naive RAG, as articulated in the foundational literature, operates on a straightforward pipeline: a user query is mapped into an embedding space, used for static retrieval from an external knowledge base, and the results are then concatenated with the original prompt for an LLM to generate a response ([1], [2], [3]). Key elements include:\n",
      "- *Indexing* of external data into a vector store;\n",
      "- *Retrieval* based solely on (usually) vector space similarity to the user's query;\n",
      "- *Generation* by the LLM using retrieved text fragments as context ([2]).\n",
      "\n",
      "**Primary Limitations:**\n",
      "- **Shallow Query Understanding:** Naive similarity measures do not robustly capture complex relationships between queries and documents ([1], [3]). For instance, queries requiring non-obvious inference or multi-hop reasoning often see performance drop-offs.\n",
      "- **Retrieval Redundancy and Noise:** As observed in both research and practitioner-oriented reports ([1], [2]), returning many loosely relevant or redundant chunks introduces confusion and increases the risk of hallucinations in LLM outputs.\n",
      "- *Lack of Process Flexibility:* The entire process is monolithicâ€”new features (e.g., advanced filtering, reasoning steps, or new retrieval strategies) are difficult to introduce without major system overhauls.\n",
      "\n",
      "#### 2. The Emergence of Modular RAG\n",
      "\n",
      "**Concept and Motivation**\n",
      "Driven by advancing application demands, modular RAG decomposes the pipeline into smaller, independently maintained modules (retrievers, generators, rerankers, memory units, evaluators, etc.) ([1], [3], [4]). This modularization allows for:\n",
      "- **Plug-and-play of specialized modules,** enabling rapid iteration and integration of new research advances (e.g., fusion of different retrievers, advanced chunkers, or expert systems).\n",
      "- **Custom operator definition** (routing, scheduling, fusion, summarization, etc.), allowing the architecture to adapt dynamically to query and domain characteristics.\n",
      "\n",
      "**Key Technical Innovations:**\n",
      "- **Routing and Scheduling:** Instead of a static pipeline, modular RAG employs intelligent decision-making (often using agentic or policy-based systems) to route queries to the most apt retrieval and reasoning paths ([1]).\n",
      "- **Fusion and Aggregation:** The combinatorial assembly of knowledge from multiple relevant sources, rather than simplistic concatenation ([1], [4]). For example, complex queries triggering branch or loop patterns allow for evidence gathering, iterative refinement, or multi-stage synthesis.\n",
      "- **Operator Flexibility:** New operators such as conditional execution, iterative revision, and domain adaptation modules can be incorporated as needed, supporting advanced reasoning and knowledge fusion.\n",
      "\n",
      "**Prevailing Modular Patterns**\n",
      "Gao et al. ([1]) identify four prominent patterns:\n",
      "- *Linear:* Sequential retrieval and generation, akin to naive RAG, but with replaceable modules.\n",
      "- *Conditional:* Branches based on intermediate decision logic (e.g., type of query, detected ambiguity).\n",
      "- *Branching:* Parallel retrieval/generation across multiple paths, suitable for complex or uncertain queries.\n",
      "- *Looping:* Iterative refinement, supporting multi-step reasoning or dynamic clarification.\n",
      "\n",
      "#### 3. Implications for Scalability, Maintainability, and Domain Integration\n",
      "\n",
      "##### a) Scalability\n",
      "- **Module Isolation:** Modular RAG allows the distribution of computation across multiple, specialized modules, supporting parallelization and elastic scaling ([1], [4]).\n",
      "- **Upgradable Components:** New algorithms (e.g., dense retrievers, semantic rerankers, advanced chunkers) can be swapped in with minimal disruptionâ€”a marked advance over naive RAG systems ([1], [3]).\n",
      "\n",
      "##### b) Maintainability\n",
      "- **Simplified Testing and Debugging:** With discrete module boundaries, errors and bottlenecks can be isolated and addressed efficiently.\n",
      "- **Standardized Interfaces:** Adoption of inter-module communication standards allows integration of heterogeneous tools and future technologies, keeping systems maintainable as they grow in complexity ([3], [4]).\n",
      "\n",
      "##### c) Domain-Specific Integration\n",
      "- **Custom Embedding and Retrieval:** Domain adaptation is attainable by fine-tuning specific modulesâ€”such as retrievers or rerankersâ€”on domain-relevant datasets without impacting the broader pipeline ([2]).\n",
      "- **Seamless Knowledge Base Expansion:** New sources can be appended, and corresponding retrievers/filters can be tailored or swapped in without pipeline reengineering ([1], [2]).\n",
      "- **Domain Operators:** For example, in medical or legal use-cases, domain-specific post-processing, reasoning, or compliance-check operators can be added modularly ([1], [3]).\n",
      "\n",
      "#### 4. Modular RAG as a Foundation for Rapid Innovation\n",
      "\n",
      "Modular RAG is not simply a theoretical advance; it provides a *practical roadmap* for building next-generation RAG systems. Several sources ([1], [3], [4]) highlight:\n",
      "- **Compatibility with emerging evaluation standards:** As benchmarking and test frameworks evolve, modular RAG frameworks can incorporate new evaluation modules for continuous improvement.\n",
      "- **Support for new paradigms:** As new reasoning schemes (e.g., multi-agent frameworks, dynamic plan generation, self-refining pipelines) appear, modular RAG's architecture is uniquely suited to absorbing these advances.\n",
      "- **Production-readiness:** Industry implementation guidelines (IBM, MeiliSearch, open frameworks) combine modular RAG with observability, feedback loops, and developer-centric design, bridging research and business requirements ([4]).\n",
      "\n",
      "#### 5. Theoretical and Practical Significance\n",
      "\n",
      "- **Theoretically,** modular RAG lays the groundwork for a unified RAG \"technology tree\"â€”as described by Gao et al. ([2])â€”wherein various architectures, reasoning mechanisms, and domain adaptations are composable and extendable on demand.\n",
      "- **Practically,** organizations gain the flexibility to respond to changing domain knowledge, regulations, or system requirements without rebuilding entire pipelines. This ensures that LLM-based systems remain current, reliable, and robust as both user expectations and knowledge bases evolve.\n",
      "\n",
      "### Sources\n",
      "\n",
      "[1] http://arxiv.org/abs/2407.21059v1  \n",
      "[2] http://arxiv.org/abs/2312.10997v5  \n",
      "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[4] https://www.meilisearch.com/blog/modular-rag  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# ì£¼ì œ ì„¤ì •\n",
    "topic = \"Modular RAG ê°€ ê¸°ì¡´ì˜ Naive RAG ì™€ ì–´ë–¤ ì°¨ì´ê°€ ìˆëŠ”ì§€ì™€ production level ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ì \"\n",
    "\n",
    "# ì¸í„°ë·° ì‹œì‘ ë©”ì‹œì§€ ìƒì„±\n",
    "messages = [HumanMessage(f\"So you said you were writing an article on {topic}?\")]\n",
    "\n",
    "# ìŠ¤ë ˆë“œ ID ì„¤ì •\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=100,\n",
    "    configurable={\"thread_id\": random_uuid()},\n",
    ")\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "invoke_graph(\n",
    "    interview_graph,\n",
    "    {\"analyst\": analysts[0], \"messages\": messages, \"max_num_turns\": 5},\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726ca13a",
   "metadata": {},
   "source": [
    "ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0750b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Unpacking the Technical Evolution of RAG: From Naive to Modular Architectures\n",
       "\n",
       "### Summary\n",
       "\n",
       "Retrieval-Augmented Generation (RAG) methods have rapidly emerged as transformative solutions to key limitations in Large Language Models (LLMs), notably hallucinations, knowledge gaps, and challenges in domain adaptation. However, the field is currently witnessing a fundamental shift: the move from \"naive\" linear RAG architecturesâ€”where retrieval and generation occur as a monolithâ€”to modular, reconfigurable frameworks designed for scalability, maintainability, and sophisticated domain-specific integration. This modularization trend is central to addressing the growing intricacies of RAG deployments in real-world, knowledge-intensive, and safety-critical scenarios.\n",
       "\n",
       "The core findings from the literature reveal several novel and crucial insights:\n",
       "- **Naive RAG architectures, while effective in many scenarios, face significant limitations when queries become complex, non-linear, or highly domain-specific.** These challenges stem from shallow query understanding, noisy retrieval, and the lack of fine-grained control over data flow and processing logic.\n",
       "- **Modular RAG represents a paradigm shift**, breaking the monolithic pipeline into independently engineered and interchangeable modules (â€œLEGO-likeâ€ components). This enables fine-tuned retrieval, adaptive reasoning schemes (e.g., routing, scheduling, fusion), and seamless integration of both generic and domain-specific operators.\n",
       "- **State-of-the-art analysis identifies not only technical components but also common design patterns for modular RAGs:** linear, conditional, branching, and looping architectures, each suited to particular classes of tasks.\n",
       "- **Modular RAG frameworks establish a practical and theoretical foundation** that can handle the rapidly increasing demands of diverse knowledge domains, complex reasoning requirements, and evolving evaluation protocols.\n",
       "\n",
       "Key sources for this synthesis:\n",
       "1. Gao, Y., Xiong, Y., Wang, M., & Wang, H. (2024). \"Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\" [arXiv:2407.21059v1].\n",
       "2. Gao, Y., Xiong, Y., Gao, X. et al. (2024). \"Retrieval-Augmented Generation for Large Language Models: A Survey\" [arXiv:2312.10997v5].\n",
       "3. Adasci.org article (\"How does modular RAG improve upon naive RAG?\").\n",
       "4. Blog posts and technical documentation on modular RAG architectures from IBM, MeiliSearch, and implementation case-studies.\n",
       "\n",
       "Collectively, these analyses challenge longstanding design assumptions and point to a future where RAG systems are not merely pipelines, but robust, composable frameworks capable of meeting the demands of next-generation AI applications.\n",
       "\n",
       "### Comprehensive Analysis\n",
       "\n",
       "#### 1. The Foundations and Shortcomings of Naive RAG\n",
       "\n",
       "**Linear and Monolithic Architecture**\n",
       "Naive RAG, as articulated in the foundational literature, operates on a straightforward pipeline: a user query is mapped into an embedding space, used for static retrieval from an external knowledge base, and the results are then concatenated with the original prompt for an LLM to generate a response ([1], [2], [3]). Key elements include:\n",
       "- *Indexing* of external data into a vector store;\n",
       "- *Retrieval* based solely on (usually) vector space similarity to the user's query;\n",
       "- *Generation* by the LLM using retrieved text fragments as context ([2]).\n",
       "\n",
       "**Primary Limitations:**\n",
       "- **Shallow Query Understanding:** Naive similarity measures do not robustly capture complex relationships between queries and documents ([1], [3]). For instance, queries requiring non-obvious inference or multi-hop reasoning often see performance drop-offs.\n",
       "- **Retrieval Redundancy and Noise:** As observed in both research and practitioner-oriented reports ([1], [2]), returning many loosely relevant or redundant chunks introduces confusion and increases the risk of hallucinations in LLM outputs.\n",
       "- *Lack of Process Flexibility:* The entire process is monolithicâ€”new features (e.g., advanced filtering, reasoning steps, or new retrieval strategies) are difficult to introduce without major system overhauls.\n",
       "\n",
       "#### 2. The Emergence of Modular RAG\n",
       "\n",
       "**Concept and Motivation**\n",
       "Driven by advancing application demands, modular RAG decomposes the pipeline into smaller, independently maintained modules (retrievers, generators, rerankers, memory units, evaluators, etc.) ([1], [3], [4]). This modularization allows for:\n",
       "- **Plug-and-play of specialized modules,** enabling rapid iteration and integration of new research advances (e.g., fusion of different retrievers, advanced chunkers, or expert systems).\n",
       "- **Custom operator definition** (routing, scheduling, fusion, summarization, etc.), allowing the architecture to adapt dynamically to query and domain characteristics.\n",
       "\n",
       "**Key Technical Innovations:**\n",
       "- **Routing and Scheduling:** Instead of a static pipeline, modular RAG employs intelligent decision-making (often using agentic or policy-based systems) to route queries to the most apt retrieval and reasoning paths ([1]).\n",
       "- **Fusion and Aggregation:** The combinatorial assembly of knowledge from multiple relevant sources, rather than simplistic concatenation ([1], [4]). For example, complex queries triggering branch or loop patterns allow for evidence gathering, iterative refinement, or multi-stage synthesis.\n",
       "- **Operator Flexibility:** New operators such as conditional execution, iterative revision, and domain adaptation modules can be incorporated as needed, supporting advanced reasoning and knowledge fusion.\n",
       "\n",
       "**Prevailing Modular Patterns**\n",
       "Gao et al. ([1]) identify four prominent patterns:\n",
       "- *Linear:* Sequential retrieval and generation, akin to naive RAG, but with replaceable modules.\n",
       "- *Conditional:* Branches based on intermediate decision logic (e.g., type of query, detected ambiguity).\n",
       "- *Branching:* Parallel retrieval/generation across multiple paths, suitable for complex or uncertain queries.\n",
       "- *Looping:* Iterative refinement, supporting multi-step reasoning or dynamic clarification.\n",
       "\n",
       "#### 3. Implications for Scalability, Maintainability, and Domain Integration\n",
       "\n",
       "##### a) Scalability\n",
       "- **Module Isolation:** Modular RAG allows the distribution of computation across multiple, specialized modules, supporting parallelization and elastic scaling ([1], [4]).\n",
       "- **Upgradable Components:** New algorithms (e.g., dense retrievers, semantic rerankers, advanced chunkers) can be swapped in with minimal disruptionâ€”a marked advance over naive RAG systems ([1], [3]).\n",
       "\n",
       "##### b) Maintainability\n",
       "- **Simplified Testing and Debugging:** With discrete module boundaries, errors and bottlenecks can be isolated and addressed efficiently.\n",
       "- **Standardized Interfaces:** Adoption of inter-module communication standards allows integration of heterogeneous tools and future technologies, keeping systems maintainable as they grow in complexity ([3], [4]).\n",
       "\n",
       "##### c) Domain-Specific Integration\n",
       "- **Custom Embedding and Retrieval:** Domain adaptation is attainable by fine-tuning specific modulesâ€”such as retrievers or rerankersâ€”on domain-relevant datasets without impacting the broader pipeline ([2]).\n",
       "- **Seamless Knowledge Base Expansion:** New sources can be appended, and corresponding retrievers/filters can be tailored or swapped in without pipeline reengineering ([1], [2]).\n",
       "- **Domain Operators:** For example, in medical or legal use-cases, domain-specific post-processing, reasoning, or compliance-check operators can be added modularly ([1], [3]).\n",
       "\n",
       "#### 4. Modular RAG as a Foundation for Rapid Innovation\n",
       "\n",
       "Modular RAG is not simply a theoretical advance; it provides a *practical roadmap* for building next-generation RAG systems. Several sources ([1], [3], [4]) highlight:\n",
       "- **Compatibility with emerging evaluation standards:** As benchmarking and test frameworks evolve, modular RAG frameworks can incorporate new evaluation modules for continuous improvement.\n",
       "- **Support for new paradigms:** As new reasoning schemes (e.g., multi-agent frameworks, dynamic plan generation, self-refining pipelines) appear, modular RAG's architecture is uniquely suited to absorbing these advances.\n",
       "- **Production-readiness:** Industry implementation guidelines (IBM, MeiliSearch, open frameworks) combine modular RAG with observability, feedback loops, and developer-centric design, bridging research and business requirements ([4]).\n",
       "\n",
       "#### 5. Theoretical and Practical Significance\n",
       "\n",
       "- **Theoretically,** modular RAG lays the groundwork for a unified RAG \"technology tree\"â€”as described by Gao et al. ([2])â€”wherein various architectures, reasoning mechanisms, and domain adaptations are composable and extendable on demand.\n",
       "- **Practically,** organizations gain the flexibility to respond to changing domain knowledge, regulations, or system requirements without rebuilding entire pipelines. This ensures that LLM-based systems remain current, reliable, and robust as both user expectations and knowledge bases evolve.\n",
       "\n",
       "### Sources\n",
       "\n",
       "[1] http://arxiv.org/abs/2407.21059v1  \n",
       "[2] http://arxiv.org/abs/2312.10997v5  \n",
       "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
       "[4] https://www.meilisearch.com/blog/modular-rag  \n",
       "[5] https://www.ibm.com/think/topics/rag-techniques"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì™„ì„±ëœ ì¸í„°ë·° ì„¹ì…˜ ì¶œë ¥\n",
    "Markdown(interview_graph.get_state(config).values[\"sections\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf37b34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Unpacking the Technical Evolution of RAG: From Naive to Modular Architectures\n",
      "\n",
      "### Summary\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) methods have rapidly emerged as transformative solutions to key limitations in Large Language Models (LLMs), notably hallucinations, knowledge gaps, and challenges in domain adaptation. However, the field is currently witnessing a fundamental shift: the move from \"naive\" linear RAG architecturesâ€”where retrieval and generation occur as a monolithâ€”to modular, reconfigurable frameworks designed for scalability, maintainability, and sophisticated domain-specific integration. This modularization trend is central to addressing the growing intricacies of RAG deployments in real-world, knowledge-intensive, and safety-critical scenarios.\n",
      "\n",
      "The core findings from the literature reveal several novel and crucial insights:\n",
      "- **Naive RAG architectures, while effective in many scenarios, face significant limitations when queries become complex, non-linear, or highly domain-specific.** These challenges stem from shallow query understanding, noisy retrieval, and the lack of fine-grained control over data flow and processing logic.\n",
      "- **Modular RAG represents a paradigm shift**, breaking the monolithic pipeline into independently engineered and interchangeable modules (â€œLEGO-likeâ€ components). This enables fine-tuned retrieval, adaptive reasoning schemes (e.g., routing, scheduling, fusion), and seamless integration of both generic and domain-specific operators.\n",
      "- **State-of-the-art analysis identifies not only technical components but also common design patterns for modular RAGs:** linear, conditional, branching, and looping architectures, each suited to particular classes of tasks.\n",
      "- **Modular RAG frameworks establish a practical and theoretical foundation** that can handle the rapidly increasing demands of diverse knowledge domains, complex reasoning requirements, and evolving evaluation protocols.\n",
      "\n",
      "Key sources for this synthesis:\n",
      "1. Gao, Y., Xiong, Y., Wang, M., & Wang, H. (2024). \"Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\" [arXiv:2407.21059v1].\n",
      "2. Gao, Y., Xiong, Y., Gao, X. et al. (2024). \"Retrieval-Augmented Generation for Large Language Models: A Survey\" [arXiv:2312.10997v5].\n",
      "3. Adasci.org article (\"How does modular RAG improve upon naive RAG?\").\n",
      "4. Blog posts and technical documentation on modular RAG architectures from IBM, MeiliSearch, and implementation case-studies.\n",
      "\n",
      "Collectively, these analyses challenge longstanding design assumptions and point to a future where RAG systems are not merely pipelines, but robust, composable frameworks capable of meeting the demands of next-generation AI applications.\n",
      "\n",
      "### Comprehensive Analysis\n",
      "\n",
      "#### 1. The Foundations and Shortcomings of Naive RAG\n",
      "\n",
      "**Linear and Monolithic Architecture**\n",
      "Naive RAG, as articulated in the foundational literature, operates on a straightforward pipeline: a user query is mapped into an embedding space, used for static retrieval from an external knowledge base, and the results are then concatenated with the original prompt for an LLM to generate a response ([1], [2], [3]). Key elements include:\n",
      "- *Indexing* of external data into a vector store;\n",
      "- *Retrieval* based solely on (usually) vector space similarity to the user's query;\n",
      "- *Generation* by the LLM using retrieved text fragments as context ([2]).\n",
      "\n",
      "**Primary Limitations:**\n",
      "- **Shallow Query Understanding:** Naive similarity measures do not robustly capture complex relationships between queries and documents ([1], [3]). For instance, queries requiring non-obvious inference or multi-hop reasoning often see performance drop-offs.\n",
      "- **Retrieval Redundancy and Noise:** As observed in both research and practitioner-oriented reports ([1], [2]), returning many loosely relevant or redundant chunks introduces confusion and increases the risk of hallucinations in LLM outputs.\n",
      "- *Lack of Process Flexibility:* The entire process is monolithicâ€”new features (e.g., advanced filtering, reasoning steps, or new retrieval strategies) are difficult to introduce without major system overhauls.\n",
      "\n",
      "#### 2. The Emergence of Modular RAG\n",
      "\n",
      "**Concept and Motivation**\n",
      "Driven by advancing application demands, modular RAG decomposes the pipeline into smaller, independently maintained modules (retrievers, generators, rerankers, memory units, evaluators, etc.) ([1], [3], [4]). This modularization allows for:\n",
      "- **Plug-and-play of specialized modules,** enabling rapid iteration and integration of new research advances (e.g., fusion of different retrievers, advanced chunkers, or expert systems).\n",
      "- **Custom operator definition** (routing, scheduling, fusion, summarization, etc.), allowing the architecture to adapt dynamically to query and domain characteristics.\n",
      "\n",
      "**Key Technical Innovations:**\n",
      "- **Routing and Scheduling:** Instead of a static pipeline, modular RAG employs intelligent decision-making (often using agentic or policy-based systems) to route queries to the most apt retrieval and reasoning paths ([1]).\n",
      "- **Fusion and Aggregation:** The combinatorial assembly of knowledge from multiple relevant sources, rather than simplistic concatenation ([1], [4]). For example, complex queries triggering branch or loop patterns allow for evidence gathering, iterative refinement, or multi-stage synthesis.\n",
      "- **Operator Flexibility:** New operators such as conditional execution, iterative revision, and domain adaptation modules can be incorporated as needed, supporting advanced reasoning and knowledge fusion.\n",
      "\n",
      "**Prevailing Modular Patterns**\n",
      "Gao et al. ([1]) identify four prominent patterns:\n",
      "- *Linear:* Sequential retrieval and generation, akin to naive RAG, but with replaceable modules.\n",
      "- *Conditional:* Branches based on intermediate decision logic (e.g., type of query, detected ambiguity).\n",
      "- *Branching:* Parallel retrieval/generation across multiple paths, suitable for complex or uncertain queries.\n",
      "- *Looping:* Iterative refinement, supporting multi-step reasoning or dynamic clarification.\n",
      "\n",
      "#### 3. Implications for Scalability, Maintainability, and Domain Integration\n",
      "\n",
      "##### a) Scalability\n",
      "- **Module Isolation:** Modular RAG allows the distribution of computation across multiple, specialized modules, supporting parallelization and elastic scaling ([1], [4]).\n",
      "- **Upgradable Components:** New algorithms (e.g., dense retrievers, semantic rerankers, advanced chunkers) can be swapped in with minimal disruptionâ€”a marked advance over naive RAG systems ([1], [3]).\n",
      "\n",
      "##### b) Maintainability\n",
      "- **Simplified Testing and Debugging:** With discrete module boundaries, errors and bottlenecks can be isolated and addressed efficiently.\n",
      "- **Standardized Interfaces:** Adoption of inter-module communication standards allows integration of heterogeneous tools and future technologies, keeping systems maintainable as they grow in complexity ([3], [4]).\n",
      "\n",
      "##### c) Domain-Specific Integration\n",
      "- **Custom Embedding and Retrieval:** Domain adaptation is attainable by fine-tuning specific modulesâ€”such as retrievers or rerankersâ€”on domain-relevant datasets without impacting the broader pipeline ([2]).\n",
      "- **Seamless Knowledge Base Expansion:** New sources can be appended, and corresponding retrievers/filters can be tailored or swapped in without pipeline reengineering ([1], [2]).\n",
      "- **Domain Operators:** For example, in medical or legal use-cases, domain-specific post-processing, reasoning, or compliance-check operators can be added modularly ([1], [3]).\n",
      "\n",
      "#### 4. Modular RAG as a Foundation for Rapid Innovation\n",
      "\n",
      "Modular RAG is not simply a theoretical advance; it provides a *practical roadmap* for building next-generation RAG systems. Several sources ([1], [3], [4]) highlight:\n",
      "- **Compatibility with emerging evaluation standards:** As benchmarking and test frameworks evolve, modular RAG frameworks can incorporate new evaluation modules for continuous improvement.\n",
      "- **Support for new paradigms:** As new reasoning schemes (e.g., multi-agent frameworks, dynamic plan generation, self-refining pipelines) appear, modular RAG's architecture is uniquely suited to absorbing these advances.\n",
      "- **Production-readiness:** Industry implementation guidelines (IBM, MeiliSearch, open frameworks) combine modular RAG with observability, feedback loops, and developer-centric design, bridging research and business requirements ([4]).\n",
      "\n",
      "#### 5. Theoretical and Practical Significance\n",
      "\n",
      "- **Theoretically,** modular RAG lays the groundwork for a unified RAG \"technology tree\"â€”as described by Gao et al. ([2])â€”wherein various architectures, reasoning mechanisms, and domain adaptations are composable and extendable on demand.\n",
      "- **Practically,** organizations gain the flexibility to respond to changing domain knowledge, regulations, or system requirements without rebuilding entire pipelines. This ensures that LLM-based systems remain current, reliable, and robust as both user expectations and knowledge bases evolve.\n",
      "\n",
      "### Sources\n",
      "\n",
      "[1] http://arxiv.org/abs/2407.21059v1  \n",
      "[2] http://arxiv.org/abs/2312.10997v5  \n",
      "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[4] https://www.meilisearch.com/blog/modular-rag  \n",
      "[5] https://www.ibm.com/think/topics/rag-techniques\n"
     ]
    }
   ],
   "source": [
    "print(interview_graph.get_state(config).values[\"sections\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0704d",
   "metadata": {},
   "source": [
    "## ì¸í„°ë·°ë¥¼ ë³‘ë ¬ë¡œ ì§„í–‰ (map-reduce)\n",
    "\n",
    "- ì¸í„°ë·°ëŠ” langgraph ì˜ `Send()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬í™”í•˜ë©°, ì´ëŠ” `map` ë‹¨ê³„ì— í•´ë‹¹í•©ë‹ˆë‹¤.\n",
    "- ì¸í„°ë·° ê²°ê³¼ëŠ” `reduce` ë‹¨ê³„ì—ì„œ ë³´ê³ ì„œ ë³¸ë¬¸ì— í†µí•©ë©ë‹ˆë‹¤.\n",
    "- ìµœì¢… ë³´ê³ ì„œì— ì„œë¡ ê³¼ ê²°ë¡ ì„ ì‘ì„±í•˜ëŠ” ë§ˆì§€ë§‰ ë‹¨ê³„ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3dd6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import List, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "# ResearchGraphState ìƒíƒœ ì •ì˜\n",
    "class ResearchGraphState(TypedDict):\n",
    "    # ì—°êµ¬ ì£¼ì œ\n",
    "    topic: str\n",
    "    # ìƒì„±í•  ë¶„ì„ê°€ì˜ ìµœëŒ€ ìˆ˜\n",
    "    max_analysts: int\n",
    "    # ì¸ê°„ ë¶„ì„ê°€ì˜ í”¼ë“œë°±\n",
    "    human_analyst_feedback: str\n",
    "    # ì§ˆë¬¸ì„ í•˜ëŠ” ë¶„ì„ê°€ ëª©ë¡\n",
    "    analysts: List[Analyst]\n",
    "    # Send() API í‚¤ë¥¼ í¬í•¨í•˜ëŠ” ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸\n",
    "    sections: Annotated[list, operator.add]\n",
    "    # ìµœì¢… ë³´ê³ ì„œì˜ ì„œë¡ \n",
    "    introduction: str\n",
    "    # ìµœì¢… ë³´ê³ ì„œì˜ ë³¸ë¬¸ ë‚´ìš©\n",
    "    content: str\n",
    "    # ìµœì¢… ë³´ê³ ì„œì˜ ê²°ë¡ \n",
    "    conclusion: str\n",
    "    # ìµœì¢… ë³´ê³ ì„œ\n",
    "    final_report: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a83efe",
   "metadata": {},
   "source": [
    "### LangGraph ì˜ Send() í•¨ìˆ˜ ì‚¬ìš©\n",
    "\n",
    "ì•„ë˜ëŠ” langgraph ì˜ `Send()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸í„°ë·°ë¥¼ ë³‘ë ¬ë¡œ ì‹œì‘í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "**ì°¸ê³ **\n",
    "\n",
    "- [LangGraph Send()](https://langchain-ai.github.io/langgraph/concepts/low_level/#send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6035e5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/ll05l0gj6cl27x40w2r115kh0000gn/T/ipykernel_44789/3516655113.py:1: LangGraphDeprecatedSinceV10: Importing Send from langgraph.constants is deprecated. Please use 'from langgraph.types import Send' instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  from langgraph.constants import Send\n"
     ]
    }
   ],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "\n",
    "# ëª¨ë“  ì¸í„°ë·°ë¥¼ ì‹œì‘\n",
    "def initiate_all_interviews(state: ResearchGraphState):\n",
    "    # ì‚¬ëŒì˜ í”¼ë“œë°± í™•ì¸\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\")\n",
    "\n",
    "    # ë§Œì•½, ì‚¬ëŒì˜ í”¼ë“œë°±ì´ ìˆìœ¼ë©´ ë¶„ì„ê°€ ìƒì„±ìœ¼ë¡œ ëŒì•„ê°€ê¸°\n",
    "    if human_analyst_feedback:\n",
    "        return \"create_analysts\"\n",
    "\n",
    "    # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Send() í•¨ìˆ˜ë¥¼ í†µí•´ ì¸í„°ë·° ë³‘ë ¬ë¡œ ì‹œì‘\n",
    "    else:\n",
    "        topic = state[\"topic\"]\n",
    "        return [\n",
    "            Send(\n",
    "                \"conduct_interview\",\n",
    "                {\n",
    "                    \"analyst\": analyst,\n",
    "                    \"messages\": [\n",
    "                        HumanMessage(\n",
    "                            content=f\"So you said you were writing an article on {topic}?\"\n",
    "                        )\n",
    "                    ],\n",
    "                },\n",
    "            )\n",
    "            for analyst in state[\"analysts\"]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8984c7",
   "metadata": {},
   "source": [
    "### ë³´ê³ ì„œ ì‘ì„± ì •ì˜\n",
    "\n",
    "ë‹¤ìŒì€ ì¸í„°ë·° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œ ì‘ì„± ê°€ì´ë“œë¼ì¸ì„ ì •ì˜í•˜ê³  ë³´ê³ ì„œ ì‘ì„± í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db04abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³´ê³ ì„œ ì‘ì„± ì§€ì‹œì‚¬í•­\n",
    "report_writer_instructions = \"\"\"You are a technical writer creating a report on this overall topic:\n",
    "\n",
    "{topic}\n",
    "\n",
    "You have a team of analysts. Each analyst has done two things:\n",
    "\n",
    "1. They conducted an interview with an expert on a specific sub-topic.\n",
    "2. They write up their finding into a memo.\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. You will be given a collection of memos from your analysts.\n",
    "2. Carefully review and analyze the insights from each memo.\n",
    "3. Consolidate these insights into a detailed and comprehensive summary that integrates the central ideas from all the memos.\n",
    "4. Organize the key points from each memo into the appropriate sections provided below, ensuring that each section is logical and well-structured.\n",
    "5. Include all required sections in your report, using `### Section Name` as the header for each.\n",
    "6. Aim for approximately 250 words per section, providing in-depth explanations, context, and supporting details.\n",
    "\n",
    "**Sections to consider (including optional ones for greater depth):**\n",
    "\n",
    "- **Background**: Theoretical foundations, key concepts, and preliminary information necessary to understand the methodology and results.\n",
    "- **Related Work**: Overview of prior studies and how they compare or relate to the current research.\n",
    "- **Problem Definition**: A formal and precise definition of the research question or problem the paper aims to address.\n",
    "- **Methodology (or Methods)**: Detailed description of the methods, algorithms, models, data collection processes, or experimental setups used in the study.\n",
    "- **Implementation Details**: Practical details of how the methods or models were implemented, including software frameworks, computational resources, or parameter settings.\n",
    "- **Experiments**: Explanation of experimental protocols, datasets, evaluation metrics, procedures, and configurations employed to validate the methods.\n",
    "- **Results**: Presentation of experimental outcomes, often with statistical tables, graphs, figures, or qualitative analyses.\n",
    "\n",
    "To format your report:\n",
    "\n",
    "1. Use markdown formatting.\n",
    "2. Include no pre-amble for the report.\n",
    "3. Use no sub-heading.\n",
    "4. Start your report with a single title header: ## Insights\n",
    "5. Do not mention any analyst names in your report.\n",
    "6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\n",
    "7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\n",
    "8. List your sources in order and do not repeat.\n",
    "\n",
    "[1] Source 1\n",
    "[2] Source 2\n",
    "\n",
    "Here are the memos from your analysts to build your report from:\n",
    "\n",
    "{context}\"\"\"\n",
    "\n",
    "\n",
    "# ë³´ê³ ì„œ ì‘ì„± í•¨ìˆ˜ ì •ì˜\n",
    "def write_report(state: ResearchGraphState):\n",
    "    # ëª¨ë“  ì„¹ì…˜ ê°€ì ¸ì˜¤ê¸°\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # ëª¨ë“  ì„¹ì…˜ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì—°ê²°\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "\n",
    "    # ì„¹ì…˜ì„ ìš”ì•½í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œ ì‘ì„±\n",
    "    system_message = report_writer_instructions.format(\n",
    "        topic=topic, context=formatted_str_sections\n",
    "    )\n",
    "    report = llm.invoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [HumanMessage(content=f\"Write a report based upon these memos.\")]\n",
    "    )\n",
    "    return {\"content\": report.content}\n",
    "\n",
    "\n",
    "# ì„œë¡ ê³¼ ê²°ë¡  ì‘ì„± ì§€ì‹œì‚¬í•­\n",
    "intro_conclusion_instructions = \"\"\"You are a technical writer finishing a report on {topic}\n",
    "\n",
    "You will be given all of the sections of the report.\n",
    "\n",
    "You job is to write a crisp and compelling introduction or conclusion section.\n",
    "\n",
    "The user will instruct you whether to write the introduction or conclusion.\n",
    "\n",
    "Include no pre-amble for either section.\n",
    "\n",
    "Target around 200 words, crisply previewing (for introduction),  or recapping (for conclusion) all of the sections of the report.\n",
    "\n",
    "Use markdown formatting.\n",
    "\n",
    "For your introduction, create a compelling title and use the # header for the title.\n",
    "\n",
    "For your introduction, use ## Introduction as the section header.\n",
    "\n",
    "For your conclusion, use ## Conclusion as the section header.\n",
    "\n",
    "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\"\n",
    "\n",
    "\n",
    "# ì„œë¡  ì‘ì„± í•¨ìˆ˜ ì •ì˜\n",
    "def write_introduction(state: ResearchGraphState):\n",
    "    # ëª¨ë“  ì„¹ì…˜ ê°€ì ¸ì˜¤ê¸°\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # ëª¨ë“  ì„¹ì…˜ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì—°ê²°\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "\n",
    "    # ì„¹ì…˜ì„ ìš”ì•½í•˜ì—¬ ì„œë¡  ì‘ì„±\n",
    "    instructions = intro_conclusion_instructions.format(\n",
    "        topic=topic, formatted_str_sections=formatted_str_sections\n",
    "    )\n",
    "    intro = llm.invoke(\n",
    "        [instructions] + [HumanMessage(content=f\"Write the report introduction\")]\n",
    "    )\n",
    "    return {\"introduction\": intro.content}\n",
    "\n",
    "\n",
    "# ê²°ë¡  ì‘ì„± í•¨ìˆ˜ ì •ì˜\n",
    "def write_conclusion(state: ResearchGraphState):\n",
    "    # ëª¨ë“  ì„¹ì…˜ ê°€ì ¸ì˜¤ê¸°\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "\n",
    "    # ëª¨ë“  ì„¹ì…˜ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì—°ê²°\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "\n",
    "    # ì„¹ì…˜ì„ ìš”ì•½í•˜ì—¬ ê²°ë¡  ì‘ì„±\n",
    "    instructions = intro_conclusion_instructions.format(\n",
    "        topic=topic, formatted_str_sections=formatted_str_sections\n",
    "    )\n",
    "    conclusion = llm.invoke(\n",
    "        [instructions] + [HumanMessage(content=f\"Write the report conclusion\")]\n",
    "    )\n",
    "    return {\"conclusion\": conclusion.content}\n",
    "\n",
    "\n",
    "# ìµœì¢… ë³´ê³ ì„œ ì‘ì„± í•¨ìˆ˜ ì •ì˜\n",
    "def finalize_report(state: ResearchGraphState):\n",
    "    # ëª¨ë“  ì„¹ì…˜ì„ ëª¨ì•„ ìµœì¢… ë³´ê³ ì„œ ì‘ì„±\n",
    "    content = state[\"content\"]\n",
    "    if content.startswith(\"## Insights\"):\n",
    "        content = content.strip(\"## Insights\")\n",
    "    if \"## Sources\" in content:\n",
    "        try:\n",
    "            content, sources = content.split(\"\\n## Sources\\n\")\n",
    "        except:\n",
    "            sources = None\n",
    "    else:\n",
    "        sources = None\n",
    "\n",
    "    final_report = (\n",
    "        state[\"introduction\"]\n",
    "        + \"\\n\\n---\\n\\n## Main Idea\\n\\n\"\n",
    "        + content\n",
    "        + \"\\n\\n---\\n\\n\"\n",
    "        + state[\"conclusion\"]\n",
    "    )\n",
    "    if sources is not None:\n",
    "        final_report += \"\\n\\n## Sources\\n\" + sources\n",
    "    return {\"final_report\": final_report}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c55157d",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be0e8b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.constants import START, END\n",
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "builder = StateGraph(ResearchGraphState)\n",
    "\n",
    "# ë…¸ë“œ ì •ì˜\n",
    "builder.add_node(\"create_analysts\", create_analysts)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"conduct_interview\", interview_builder.compile())\n",
    "builder.add_node(\"write_report\", write_report)\n",
    "builder.add_node(\"write_introduction\", write_introduction)\n",
    "builder.add_node(\"write_conclusion\", write_conclusion)\n",
    "builder.add_node(\"finalize_report\", finalize_report)\n",
    "\n",
    "# ì—£ì§€ ì •ì˜\n",
    "builder.add_edge(START, \"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\n",
    "    \"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"]\n",
    ")\n",
    "\n",
    "# ì¸í„°ë·° ê²°ê³¼ ë³´ê³ ì„œ ì‘ì„±\n",
    "builder.add_edge(\"conduct_interview\", \"write_report\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
    "\n",
    "# ë³´ê³ ì„œ ìµœì¢… ì •ë¦¬\n",
    "builder.add_edge(\n",
    "    [\"write_conclusion\", \"write_report\", \"write_introduction\"], \"finalize_report\"\n",
    ")\n",
    "builder.add_edge(\"finalize_report\", END)\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
    "\n",
    "visualize_graph(graph, xray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c60bf",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ ì‹¤í–‰\n",
    "\n",
    "ì´ì œ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "`max_analysts`, `topic` ì„ ììœ ë¡­ê²Œ ë³€ê²½í•˜ì—¬ ì‹¤í–‰í•´ ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c360d65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mcreate_analysts\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "affiliation='Enterprise MLOps Consultancy' name='Dr. Priya Nair' role='Production Systems Architect' description='Focuses on deployment challenges and scalability of AI solutions in enterprise contexts. Examines how Modular RAG impacts observability, maintainability, and long-term ROI compared to Naive RAG, with particular attention to upgradability and A/B testing in production workflows.'\n",
      "affiliation='Academic AI Research Lab' name='Prof. Julian Beck' role='Framework Theorist' description='Explores the theoretical distinctions between Modular and Naive RAG architectures. Interested in composability, modularity, and experimental evidence for how modular systems enable more robust innovation and error isolation in applied retrieval-augmented generation systems.'\n",
      "affiliation='Cloud AI Platform Provider' name='Jessica Wu' role='Product Reliability Lead' description='Prioritizes reliability, performance, and operational efficiency. Analyzes the benefits of modularity in RAG for monitoring, fault-tolerance, and dynamic scaling at production level, comparing risk reduction and incident mitigation capabilities against monolithic (Naive) RAG setups.'\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36m__interrupt__\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ì…ë ¥ ë°ì´í„° ì„¤ì •\n",
    "max_analysts = 3\n",
    "topic = \"Explain how Modular RAG differs from traditional Naive RAG and the benefits of using it at the production level.\"\n",
    "\n",
    "# config ì„¤ì •\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=30,\n",
    "    configurable={\"thread_id\": random_uuid()},\n",
    ")\n",
    "\n",
    "# ì…ë ¥ ë°ì´í„° ì„¤ì •\n",
    "inputs = {\"topic\": topic, \"max_analysts\": max_analysts}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰: ì²« ë²ˆì§¸ ì¤‘ë‹¨ ì§€ì ê¹Œì§€\n",
    "invoke_graph(graph, inputs, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed98b941",
   "metadata": {},
   "source": [
    "human_feedback ì„ ì¶”ê°€í•˜ì—¬ ë¶„ì„ê°€ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c7ee8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'ce3e045b-da78-492d-ad86-6eb1c6fee521',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0ab19c-b307-61c2-8002-1f4b98bfd934'}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ìƒˆë¡œìš´ ë¶„ì„ê°€ ì¶”ê°€\n",
    "graph.update_state(\n",
    "    config,\n",
    "    {\"human_analyst_feedback\": \"Add Prof. Jeffrey Hinton as a head of AI analyst\"},\n",
    "    as_node=\"human_feedback\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "379689e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mcreate_analysts\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "affiliation='University of Toronto / Vector Institute' name='Prof. Geoffrey Hinton' role='Head AI Analyst' description='Renowned pioneer in deep learning, Prof. Hinton evaluates the conceptual advancements from Naive RAG to Modular RAG, focusing on architectural innovations and their implications for retrieval-augmented generation (RAG) systems.'\n",
      "affiliation='OpenAI' name='Dr. Priya Sarin' role='Scalability and Production Expert' description='Dr. Sarin analyzes the production-scale benefits of Modular RAG, particularly around scalability, maintainability, and system robustness in real-world deployment settings.'\n",
      "affiliation='Google DeepMind' name='Dr. Miguel Alvarez' role='Evaluation and Performance Analyst' description='Dr. Alvarez investigates the empirical performance improvements and fine-tuning opportunities enabled by Modular RAG, comparing it with traditional approaches and emphasizing outcome metrics such as retrieval quality, system latency, and modular adaptivity.'\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36m__interrupt__\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "invoke_graph(graph, None, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05feb4d",
   "metadata": {},
   "source": [
    "ì´ì œ ì‚¬ëŒì˜ í”¼ë“œë°±ì„ ì¢…ë£Œí•˜ê³  ê·¸ë˜í”„ë¥¼ ì¬ê°œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8d3dfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'ce3e045b-da78-492d-ad86-6eb1c6fee521',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0ab19c-d30c-6198-8004-c5d769cf04f4'}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê·¸ë˜í”„ ì¬ê°œ\n",
    "graph.update_state(config, {\"human_analyst_feedback\": None}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65fd47b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Professor Hinton, my name is Dr. Evelyn Chan, and Iâ€™m an AI systems analyst working on synthesizing recent advances in retrieval-augmented generation (RAG). Thank you so much for taking the time.\n",
      "\n",
      "To start, could you explain, in concrete terms, how the architectural design of Modular RAG differs from the more traditional â€œnaiveâ€ RAG frameworks? Are there particular modules or patterns that define the modular approach?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Dr. Sarin, my name is Alex Chenâ€”I'm a technology journalist with a focus on real-world AI deployments. Thank you for taking the time to talk with me. I want to start by making sure I understand the basics clearly. \n",
      "\n",
      "Could you explain, in concrete terms, what distinguishes Modular RAG (Retrieval-Augmented Generation) from the \"naive\" or traditional RAG architecture that most engineers may be familiar with? \n",
      "\n",
      "Are there any specific modular components or patterns that are central to this distinction?\n",
      "==================================================\n",
      "Arxiv ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: module 'fitz' has no attribute 'fitz'\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Error>Arxiv ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.</Error>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Dr. Alvarez, thank you for speaking with me today. My name is Jordan Lin, and Iâ€™m an AI systems journalist focused on practical advances in retrieval-augmented generation (RAG).\n",
      "\n",
      "To start: Could you explain, at a technical level, what â€œModular RAGâ€ specifically changes compared to the standard or â€œnaiveâ€ RAG architectures? Are there particular sub-systems or components that are modularized, and how does this affect the stack as a whole?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"http://arxiv.org/abs/2502.11228v2\" date=\"2025-05-22\" authors=\"Mohammad Reza Rezaei, Adji Bousso Dieng\"/>\n",
      "<Title>\n",
      "Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\n",
      "for domain-specific question-answering (QA) tasks by leveraging external\n",
      "knowledge sources. However, traditional RAG systems primarily focus on\n",
      "relevance-based retrieval and often struggle with redundancy, especially when\n",
      "reasoning requires connecting information from multiple sources. This paper\n",
      "introduces Vendi-RAG, a framework based on an iterative process that jointly\n",
      "optimizes retrieval diversity and answer quality. This joint optimization leads\n",
      "to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\n",
      "the Vendi Score (VS), a flexible similarity-based diversity metric, to promote\n",
      "semantic diversity in document retrieval. It then uses an LLM judge that\n",
      "evaluates candidate answers, generated after a reasoning step, and outputs a\n",
      "score that the retriever uses to balance relevance and diversity among the\n",
      "retrieved documents during each iteration. Experiments on three challenging\n",
      "datasets -- HotpotQA, MuSiQue, and 2WikiMultiHopQA -- demonstrate Vendi-RAG's\n",
      "effectiveness in multi-hop reasoning tasks. The framework achieves significant\n",
      "accuracy improvements over traditional single-step and multi-step RAG\n",
      "approaches, with accuracy increases reaching up to +4.2% on HotpotQA, +4.1% on\n",
      "2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the current\n",
      "best baseline. The benefits of Vendi-RAG are even more pronounced as the number\n",
      "of retrieved documents increases. Finally, we evaluated Vendi-RAG across\n",
      "different LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini, and\n",
      "observed consistent improvements, demonstrating that the framework's advantages\n",
      "are model-agnostic.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "Vendi-RAG: Adaptively Trading-Off Diversity And\n",
      "Quality Significantly Improves Retrieval\n",
      "Augmented Generation With LLMs\n",
      "Mohammad R. Rezaei1, 3 and Adji Bousso Dieng2, 3\n",
      "1Institute of Biomedical Engineering, University of Toronto\n",
      "2Department of Computer Science, Princeton University\n",
      "3Vertaix\n",
      "May 26, 2025\n",
      "Abstract\n",
      "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\n",
      "for domain-specific question-answering (QA) tasks by leveraging external\n",
      "knowledge sources. However, traditional RAG systems primarily focus on\n",
      "relevance-based retrieval and often struggle with redundancy, especially when\n",
      "reasoning requires connecting information from multiple sources. This paper\n",
      "introduces Vendi-RAG, a framework based on an iterative process that jointly\n",
      "optimizes retrieval diversity and answer quality. This joint optimization leads\n",
      "to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\n",
      "the Vendi Score (VS), a flexible similarity-based diversity metric, to promote\n",
      "semantic diversity in document retrieval. It then uses an LLM judge that eval-\n",
      "uates candidate answers, generated after a reasoning step, and outputs a\n",
      "score that the retriever uses to balance relevance and diversity among the\n",
      "retrieved documents during each iteration. Experiments on three challenging\n",
      "datasetsâ€”HotpotQA, MuSiQue, and 2WikiMultiHopQAâ€”demonstrate Vendi-\n",
      "RAGâ€™s effectiveness in multi-hop reasoning tasks. The framework achieves sig-\n",
      "nificant accuracy improvements over traditional single-step or multi-step RAG\n",
      "approaches, with accuracy increases reaching +4.2% on HotpotQA, +4.1% on\n",
      "2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the\n",
      "current best baseline. The benefits of Vendi-RAG are even more pronounced as\n",
      "the number of retrieved documents increases. Finally, we evaluated Vendi-RAG\n",
      "across different LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini,\n",
      "and observed consistent improvements, demonstrating that the frameworkâ€™s\n",
      "advantages are model-agnostic.\n",
      "Keywords: RAG, LLMs, Question Answering, NLP, Diversity, Vendi Scoring\n",
      "1\n",
      "Introduction\n",
      "Retrieval-augmented generation (RAG) has emerged as a transformative framework\n",
      "for enhancing the performance of large language models (LLMs) in domain-specific\n",
      "tasks such as question-answering (QA). By retrieving relevant information from\n",
      "external sources beyond the training set, RAG enables LLMs to answer specialized\n",
      "1\n",
      "arXiv:2502.11228v2  [cs.CL]  22 May 2025\n",
      "Retrieval\n",
      "Query\n",
      "Answer\n",
      "LLM Judge \n",
      "Quality Check\n",
      "Rewritten  \n",
      "Query\n",
      "Final \n",
      "Answer\n",
      "Vendi Score\n",
      "Vendi Score\n",
      "Diversity  \n",
      "weight s\n",
      "Decision Block \n",
      "s > threshold Thr \n",
      "Iteration < N\n",
      "â€¦\n",
      "Reasoning\n",
      "Figure 1: The process begins with an initial retrieval step, where a diverse set of\n",
      "documents is retrieved using the Vendi Score, ensuring broad semantic coverage.\n",
      "Next, leveraging a reasoning step to construct a coherent path to the final answer,\n",
      "the LLM generates an answer, which then undergoes quality assessment by an LLM\n",
      "judge. Based on the answer quality, the retriever is adjusted to balance diversity and\n",
      "relevance: high-quality answers limit the emphasis on diversity, while low-quality\n",
      "answers prompt the retriever to prioritize diversity more heavily. This adjustment\n",
      "is controlled by an adaptive parameter, s, which is updated over iterations. The\n",
      "process continues until the answer quality reaches an optimal threshold, denoted\n",
      "by Thr. Finally, the highest-quality responses and documents are selected, ensuring\n",
      "both diversity and accuracy.\n",
      "queries more effectively Achiam et al. (2023); Team et al. (2023); Jiang et al. (2024).\n",
      "This approach has been particularly successful in single-hop QA, where a question\n",
      "can be answered using information from a single document Raiaan et al. (2024);\n",
      "Kwiatkowski et al. (2019). For instance, answering a question such as \"Who wrote\n",
      "the novel Frankenstein?\" only requires retrieving relevant information from a single\n",
      "document containing this fact.\n",
      "However, multi-hop QA introduces significantly greater complexit\n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstractâ€”Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of â€œretrieve-then-generateâ€. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patternsâ€”linear, conditional,\n",
      "branching, and loopingâ€”and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Termsâ€”Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]â€“[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLMâ€™s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2508.05650v1\" date=\"2025-07-26\" authors=\"Jiaxuan Liang, Shide Zhou, Kailong Wang\"/>\n",
      "<Title>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "While Retrieval Augmented Generation (RAG) is now widely adopted to enhance\n",
      "LLMs, evaluating its true performance benefits in a reproducible and\n",
      "interpretable way remains a major hurdle. Existing methods often fall short:\n",
      "they lack domain coverage, employ coarse metrics that miss sub document\n",
      "precision, and fail to capture computational trade offs. Most critically, they\n",
      "provide no standardized framework for comparing RAG effectiveness across\n",
      "different models and domains.\n",
      "  We introduce OmniBench RAG, a novel automated platform for multi domain\n",
      "evaluation of RAG systems. The platform quantifies performance gains across\n",
      "accuracy and efficiency dimensions, spanning nine knowledge fields including\n",
      "culture, geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency differences\n",
      "between pre RAG and post RAG models), enabling reproducible comparisons across\n",
      "models and tasks. The platform features dynamic test generation, modular\n",
      "evaluation pipelines, and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant gains in\n",
      "culture to declines in mathematics, highlighting the critical importance of\n",
      "systematic, domain aware assessment. A demonstration video is available at:\n",
      "https://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets:\n",
      "https://github.com/Garnett-Liang/Omnibench-RAG.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation\n",
      "Platform for Retrieval-Augmented Generation Tools\n",
      "Jiaxuan Liang*, Shide Zhou*, and Kailong Wangâ€ \n",
      "Huazhong University of Science and Technology\n",
      "{liangjx, shidez, wangkl}@hust.edu.cn\n",
      "Abstractâ€”While Retrieval Augmented Generation (RAG) is\n",
      "now widely adopted to enhance LLMs, evaluating its true\n",
      "performance benefits in a reproducible and interpretable way\n",
      "remains a major hurdle. Existing methods often fall short: they\n",
      "lack domain coverage, employ coarse metrics that miss sub\n",
      "document precision, and fail to capture computational trade\n",
      "offs. Most critically, they provide no standardized framework\n",
      "for comparing RAG effectiveness across different models and\n",
      "domains.\n",
      "We introduce OmniBench RAG, a novel automated platform\n",
      "for multi domain evaluation of RAG systems. The platform\n",
      "quantifies performance gains across accuracy and efficiency\n",
      "dimensions, spanning nine knowledge fields including culture,\n",
      "geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency\n",
      "differences between pre RAG and post RAG models), enabling\n",
      "reproducible comparisons across models and tasks. The platform\n",
      "features dynamic test generation, modular evaluation pipelines,\n",
      "and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant\n",
      "gains in culture to declines in mathematics, highlighting the\n",
      "critical importance of systematic, domain aware assessment. A\n",
      "demonstration video is available at: https://www.youtube.com/\n",
      "watch?v=BZx83QFcTCI. Code and datasets: https://github.com/\n",
      "Garnett-Liang/Omnibench-RAG.\n",
      "I. INTRODUCTION\n",
      "Retrieval-Augmented Generation (RAG) is a key technique\n",
      "for enhancing Large Language Models (LLMs) [1], [2]. By\n",
      "grounding model responses in external, verifiable knowledge,\n",
      "RAG promises to mitigate hallucinations [3], improve factual\n",
      "accuracy [4], and provide up-to-date information [5]. However,\n",
      "the true effectiveness of RAG is far from uniform. Recent\n",
      "studies [6], [7] reveal a significant disparity: while RAG\n",
      "can boost the accuracy of smaller models like Llama-3.2-3B-\n",
      "Instruct by as much as 38.12%, its impact on state-of-the-art\n",
      "models such as GPT-4o, which excel with extended context\n",
      "windows, is often less pronounced. This variability, which\n",
      "depends not only on the modelâ€™s scale but also heavily on\n",
      "the knowledge domain, underscores a critical challenge: the\n",
      "lack of a systematic platform to quantify the value of RAG\n",
      "across these diverse contexts.\n",
      "Current RAG evaluation approaches suffer from fundamen-\n",
      "tal limitations that impede reproducible and comprehensive as-\n",
      "sessment: First, they lack automated multi-domain evalua-\n",
      "tion capabilities and rely on non-deterministic components.\n",
      "*Jiaxuan Liang and Shide Zhou are co-first authors.\n",
      "â€ Kailong Wang is the corresponding author.\n",
      "Existing benchmarks typically require manual configuration\n",
      "for each knowledge domain and fail to provide unified assess-\n",
      "ment across diverse fields like finance, healthcare, or culture,\n",
      "making cross-domain performance analysis labor-intensive and\n",
      "inconsistent. Moreover, key metrics in leading frameworks\n",
      "(e.g., LLM-based scoring in Ragas [8]) inadvertently introduce\n",
      "randomness due to reliance on large language models in the\n",
      "evaluation loop, undermining result reproducibility. Second,\n",
      "they employ static datasets and coarse-grained metrics.\n",
      "Most frameworks rely on fixed benchmarks and document-\n",
      "level retrieval metrics (e.g., MRR@k[9]), missing the critical\n",
      "sub-document precision needed to assess whether models\n",
      "extract specific facts accurately. They also lack the ability to\n",
      "dynamically generate test cases that probe complex reasoning\n",
      "patterns. Third, they fail to capture the computational\n",
      "trade-offs inherent in RAG systems. Without automated\n",
      "profiling of resource utilization and efficiency metrics, practi-\n",
      "tioners cannot make informed decisions about the cost-benefit\n",
      "trade-offs of deploying RAG in production environments.\n",
      "Our \n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"http://arxiv.org/abs/2508.05650v1\" date=\"2025-07-26\" authors=\"Jiaxuan Liang, Shide Zhou, Kailong Wang\"/>\n",
      "<Title>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "While Retrieval Augmented Generation (RAG) is now widely adopted to enhance\n",
      "LLMs, evaluating its true performance benefits in a reproducible and\n",
      "interpretable way remains a major hurdle. Existing methods often fall short:\n",
      "they lack domain coverage, employ coarse metrics that miss sub document\n",
      "precision, and fail to capture computational trade offs. Most critically, they\n",
      "provide no standardized framework for comparing RAG effectiveness across\n",
      "different models and domains.\n",
      "  We introduce OmniBench RAG, a novel automated platform for multi domain\n",
      "evaluation of RAG systems. The platform quantifies performance gains across\n",
      "accuracy and efficiency dimensions, spanning nine knowledge fields including\n",
      "culture, geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency differences\n",
      "between pre RAG and post RAG models), enabling reproducible comparisons across\n",
      "models and tasks. The platform features dynamic test generation, modular\n",
      "evaluation pipelines, and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant gains in\n",
      "culture to declines in mathematics, highlighting the critical importance of\n",
      "systematic, domain aware assessment. A demonstration video is available at:\n",
      "https://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets:\n",
      "https://github.com/Garnett-Liang/Omnibench-RAG.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation\n",
      "Platform for Retrieval-Augmented Generation Tools\n",
      "Jiaxuan Liang*, Shide Zhou*, and Kailong Wangâ€ \n",
      "Huazhong University of Science and Technology\n",
      "{liangjx, shidez, wangkl}@hust.edu.cn\n",
      "Abstractâ€”While Retrieval Augmented Generation (RAG) is\n",
      "now widely adopted to enhance LLMs, evaluating its true\n",
      "performance benefits in a reproducible and interpretable way\n",
      "remains a major hurdle. Existing methods often fall short: they\n",
      "lack domain coverage, employ coarse metrics that miss sub\n",
      "document precision, and fail to capture computational trade\n",
      "offs. Most critically, they provide no standardized framework\n",
      "for comparing RAG effectiveness across different models and\n",
      "domains.\n",
      "We introduce OmniBench RAG, a novel automated platform\n",
      "for multi domain evaluation of RAG systems. The platform\n",
      "quantifies performance gains across accuracy and efficiency\n",
      "dimensions, spanning nine knowledge fields including culture,\n",
      "geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency\n",
      "differences between pre RAG and post RAG models), enabling\n",
      "reproducible comparisons across models and tasks. The platform\n",
      "features dynamic test generation, modular evaluation pipelines,\n",
      "and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant\n",
      "gains in culture to declines in mathematics, highlighting the\n",
      "critical importance of systematic, domain aware assessment. A\n",
      "demonstration video is available at: https://www.youtube.com/\n",
      "watch?v=BZx83QFcTCI. Code and datasets: https://github.com/\n",
      "Garnett-Liang/Omnibench-RAG.\n",
      "I. INTRODUCTION\n",
      "Retrieval-Augmented Generation (RAG) is a key technique\n",
      "for enhancing Large Language Models (LLMs) [1], [2]. By\n",
      "grounding model responses in external, verifiable knowledge,\n",
      "RAG promises to mitigate hallucinations [3], improve factual\n",
      "accuracy [4], and provide up-to-date information [5]. However,\n",
      "the true effectiveness of RAG is far from uniform. Recent\n",
      "studies [6], [7] reveal a significant disparity: while RAG\n",
      "can boost the accuracy of smaller models like Llama-3.2-3B-\n",
      "Instruct by as much as 38.12%, its impact on state-of-the-art\n",
      "models such as GPT-4o, which excel with extended context\n",
      "windows, is often less pronounced. This variability, which\n",
      "depends not only on the modelâ€™s scale but also heavily on\n",
      "the knowledge domain, underscores a critical challenge: the\n",
      "lack of a systematic platform to quantify the value of RAG\n",
      "across these diverse contexts.\n",
      "Current RAG evaluation approaches suffer from fundamen-\n",
      "tal limitations that impede reproducible and comprehensive as-\n",
      "sessment: First, they lack automated multi-domain evalua-\n",
      "tion capabilities and rely on non-deterministic components.\n",
      "*Jiaxuan Liang and Shide Zhou are co-first authors.\n",
      "â€ Kailong Wang is the corresponding author.\n",
      "Existing benchmarks typically require manual configuration\n",
      "for each knowledge domain and fail to provide unified assess-\n",
      "ment across diverse fields like finance, healthcare, or culture,\n",
      "making cross-domain performance analysis labor-intensive and\n",
      "inconsistent. Moreover, key metrics in leading frameworks\n",
      "(e.g., LLM-based scoring in Ragas [8]) inadvertently introduce\n",
      "randomness due to reliance on large language models in the\n",
      "evaluation loop, undermining result reproducibility. Second,\n",
      "they employ static datasets and coarse-grained metrics.\n",
      "Most frameworks rely on fixed benchmarks and document-\n",
      "level retrieval metrics (e.g., MRR@k[9]), missing the critical\n",
      "sub-document precision needed to assess whether models\n",
      "extract specific facts accurately. They also lack the ability to\n",
      "dynamically generate test cases that probe complex reasoning\n",
      "patterns. Third, they fail to capture the computational\n",
      "trade-offs inherent in RAG systems. Without automated\n",
      "profiling of resource utilization and efficiency metrics, practi-\n",
      "tioners cannot make informed decisions about the cost-benefit\n",
      "trade-offs of deploying RAG in production environments.\n",
      "Our \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstractâ€”Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of â€œretrieve-then-generateâ€. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patternsâ€”linear, conditional,\n",
      "branching, and loopingâ€”and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Termsâ€”Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]â€“[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLMâ€™s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2406.00944v3\" date=\"2025-02-28\" authors=\"Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng\"/>\n",
      "<Title>\n",
      "A Theory for Token-Level Harmonization in Retrieval-Augmented Generation\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance\n",
      "large language models (LLMs). Studies show that while RAG provides valuable\n",
      "external information (benefit), it may also mislead LLMs (detriment) with noisy\n",
      "or incorrect retrieved texts. Although many existing methods attempt to\n",
      "preserve benefit and avoid detriment, they lack a theoretical explanation for\n",
      "RAG. The benefit and detriment in the next token prediction of RAG remain a\n",
      "black box that cannot be quantified or compared in an explainable manner, so\n",
      "existing methods are data-driven, need additional utility evaluators or\n",
      "post-hoc. This paper takes the first step towards providing a theory to explain\n",
      "and trade off the benefit and detriment in RAG. First, we model RAG as the\n",
      "fusion between distribution of LLMs knowledge and distribution of retrieved\n",
      "texts. Then, we formalize the trade-off between the value of external knowledge\n",
      "(benefit) and its potential risk of misleading LLMs (detriment) in next token\n",
      "prediction of RAG by distribution difference in this fusion. Finally, we prove\n",
      "that the actual effect of RAG on the token, which is the comparison between\n",
      "benefit and detriment, can be predicted without any training or accessing the\n",
      "utility of retrieval. Based on our theory, we propose a practical novel method,\n",
      "Tok-RAG, which achieves collaborative generation between the pure LLM and RAG\n",
      "at token level to preserve benefit and avoid detriment. Experiments in\n",
      "real-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the\n",
      "effectiveness of our method and support our theoretical findings.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "Published as a conference paper at ICLR 2025\n",
      "A THEORY FOR TOKEN-LEVEL HARMONIZATION IN\n",
      "RETRIEVAL-AUGMENTED GENERATION\n",
      "Shicheng Xu1,2, Liang Pang1âˆ—, Huawei Shen1, Xueqi Cheng1\n",
      "1CAS Key Laboratory of AI Safety, Institute of Computing Technology, Chinese Academy of Sciences\n",
      "2University of Chinese Academy of Sciences\n",
      "{xushicheng21s,pangliang,shenhuawei,cxq}@ict.ac.cn\n",
      "ABSTRACT\n",
      "Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance large\n",
      "language models (LLMs). Studies show that while RAG provides valuable external\n",
      "information (benefit), it may also mislead LLMs (detriment) with noisy or incorrect\n",
      "retrieved texts. Although many existing methods attempt to preserve benefit and\n",
      "avoid detriment, they lack a theoretical explanation for RAG. The benefit and\n",
      "detriment in the next token prediction of RAG remain a â€™black boxâ€™ that cannot\n",
      "be quantified or compared in an explainable manner, so existing methods are data-\n",
      "driven, need additional utility evaluators or post-hoc. This paper takes the first step\n",
      "towards providing a theory to explain and trade off the benefit and detriment in\n",
      "RAG. First, we model RAG as the fusion between distribution of LLMâ€™s knowledge\n",
      "and distribution of retrieved texts. Then, we formalize the trade-off between the\n",
      "value of external knowledge (benefit) and its potential risk of misleading LLMs\n",
      "(detriment) in next token prediction of RAG by distribution difference in this\n",
      "fusion. Finally, we prove that the actual effect of RAG on the token, which is the\n",
      "comparison between benefit and detriment, can be predicted without any training or\n",
      "accessing the utility of retrieval. Based on our theory, we propose a practical novel\n",
      "method, Tok-RAG, which achieves collaborative generation between the pure\n",
      "LLM and RAG at token level to preserve benefit and avoid detriment. Experiments\n",
      "in real-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the\n",
      "effectiveness of our method and support our theoretical findings. Code is available1.\n",
      "1\n",
      "INTRODUCTION\n",
      "Retrieval-augmented generation (RAG) has shown promising performance in enhancing Large\n",
      "Language Models (LLMs) by integrating retrieved texts (Xu et al., 2023; Shi et al., 2023; Asai et al.,\n",
      "2023; Ram et al., 2023). Studies indicate that while RAG provides LLMs with valuable additional\n",
      "knowledge (benefit), it also poses a risk of misleading them (detriment) due to noisy or incorrect\n",
      "retrieved texts (Ram et al., 2023; Xu et al., 2024b;a; Jin et al., 2024; Xie et al., 2023). Existing\n",
      "methods attempt to preserve benefit and avoid detriment by adding utility evaluators for retrieval,\n",
      "prompt engineering, or fine-tuning LLMs (Asai et al., 2023; Ding et al., 2024; Xu et al., 2024b; Yoran\n",
      "et al., 2024; Ren et al., 2023; Mallen et al., 2022; Jiang et al., 2023). However, existing methods are\n",
      "data-driven, need evaluator for utility of retrieved texts or post-hoc. A theory-based method, focusing\n",
      "on core principles of RAG is urgently needed, which is crucial for reliable improvements without\n",
      "relying on additional training or utility evaluators and improving our understanding for RAG.\n",
      "This paper takes the first step in providing a theoretical framework to explain and trade off the benefit\n",
      "and detriment at token level in RAG and proposes a novel method to preserve benefit and avoid\n",
      "detriment based on our theoretical findings. Specifically, this paper pioneers in modeling next token\n",
      "prediction in RAG as the fusion between the distribution of LLMâ€™s knowledge and the distribution\n",
      "of retrieved texts as shown in Figure 1. Our theoretical derivation based on this formalizes the core\n",
      "of this fusion as the subtraction between two terms measured by the distribution difference: one is\n",
      "distribution completion and the other is distribution contradiction. Further analysis indicates that\n",
      "âˆ—Corresponding Author\n",
      "1https://github.com/xsc1234/Tok-RAG\n",
      "1\n",
      "arXiv:2406.00944v3  [cs.CL]  28 Feb 2025\n",
      "Published as a conference paper at ICLR 2025\n",
      "Query\n",
      "Wole\n",
      "Query\n",
      "Ernst\n",
      "Soyinka\n",
      "â€¦\n",
      "LLMâ€™s \n",
      "Distribution\n",
      "Retr\n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document href=\"https://www.ibm.com/think/topics/rag-techniques\"/>\n",
      "While naive RAG is straightforward and quick, modular RAGâ€”often built with frameworks such as LangChainâ€”provides enhanced flexibility, scalability and\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
      "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. By adopting a modular architecture, this approach addresses the limitations of Naive RAG, offering enhanced flexibility, scalability, and efficiency. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. * *Seamless Integration*: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e\"/>\n",
      "RAG applications must efficiently retrieve relevant documents from the data source. **Chunk Optimization** â€” when using external data sources / documents to build RAG pipeline, the initial step is break them down into smaller chunks to extract fine- grained features. After retrieving the context data (chunks) from a vector database, the next step is to merge the context with a query as an input into LLM. **Memory Module** â€” adding memory component into RAG system where LLM can refer not only to the chunks retrieved from the vector database but also to the previous queries and answers that are stored in the systems memory. ### Build intelligent RAG systems that know when to retrieve documents, search the web, or generate responses directly\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
      "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. By adopting a modular architecture, this approach addresses the limitations of Naive RAG, offering enhanced flexibility, scalability, and efficiency. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. * *Seamless Integration*: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.ibm.com/think/topics/rag-techniques\"/>\n",
      "While naive RAG is straightforward and quick, modular RAGâ€”often built with frameworks such as LangChainâ€”provides enhanced flexibility, scalability and\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag\"/>\n",
      "Modular RAG takes the RAG concept further by breaking it down into specialized modules. Modular RAG builds on the basic principles of Naive RAG\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document href=\"https://www.ibm.com/think/topics/rag-techniques\"/>\n",
      "Pros and cons of RAG techniquesâ€‹â€‹ While naive RAG is straightforward and quick, modular RAGâ€”often built with frameworks such as LangChainâ€”provides enhanced\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
      "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. By adopting a modular architecture, this approach addresses the limitations of Naive RAG, offering enhanced flexibility, scalability, and efficiency. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. * *Seamless Integration*: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.linkedin.com/pulse/3-types-rag-models-naive-modular-advanced-rabiloo-gl7kc\"/>\n",
      "Building AI systems requires choosing the right tools for the job, and Retrieval-Augmented Generation (RAG) offers various models, each designed to serve different needs. Retrieval-Augmented Generation (RAG) is a powerful AI framework that blends the retrieval of external data with content generation. Essentially, a RAG model retrieves information from external databases, knowledge bases, or the web and then uses that data to generate relevant, meaningful responses. Naive RAG begins by indexing the data source for quick retrieval of relevant information. The generation module in Advanced RAG then processes the refined data using sophisticated models like T5 or GPT-3. Graph RAG is the next evolution of the Retrieval-Augmented Generation (RAG) model, combining the power of traditionalâ€¦\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manswer_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: expert\n",
      "\n",
      "Certainly. Modular RAG distinguishes itself from traditional Naive RAG in several key ways, particularly in terms of architecture and suitability for production-scale deployment.\n",
      "\n",
      "**Naive RAG** operates as a monolithic system: it retrieves relevant documents from a knowledge base and then passes them to a generative model. This process is relatively static and inflexible, which often results in inefficiencies and limits how seamlessly the retrieval and generation components interact. There is little room for customization or replacement of constituent parts without substantial engineering effort. As a result, scaling or adapting the system for evolving requirements can be challenging [1][3].\n",
      "\n",
      "**Modular RAG**, on the other hand, adopts a composable architecture. Here, retrieval and generation are broken into specialized, distinct modules that can be interchanged, upgraded, or adjusted independently. This modular approach allows the generative components to integrate seamlessly with a variety of retrieval modules, greatly enhancing the flexibility, scalability, and relevance of responses [1][2][3].\n",
      "\n",
      "**Key benefits of Modular RAG at the production level include:**\n",
      "\n",
      "- **Flexibility:** Different retrieval or generation modules can be swapped or adapted with minimal disruption, accommodating changing business or technical needs.\n",
      "- **Scalability:** Components can be independently scaled, streamlined, or replaced as usage grows or as new retrieval/generation technologies emerge.\n",
      "- **Maintainability:** Clear module boundaries make it easier for engineering teams to update, debug, or optimize individual parts without impacting the whole system.\n",
      "- **Enhanced Relevance and Coherence:** Seamless integration between retrieval and generation improves the quality and applicability of produced responses [1][3].\n",
      "\n",
      "In summary, Modular RAG enables organizations to build more robust, scalable, and maintainable AI solutions by replacing the rigid, all-in-one nature of Naive RAG with a flexible architecture suitable for real-world, production-scale challenges [1][2][3].\n",
      "\n",
      "**Sources:**  \n",
      "[1] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[2] https://www.ibm.com/think/topics/rag-techniques  \n",
      "[3] https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manswer_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: expert\n",
      "\n",
      "Certainly. Modular RAG fundamentally differs from traditional Naive RAG in both architecture and workflow, especially as applied in production environments:\n",
      "\n",
      "**1. Architectural Design**\n",
      "\n",
      "- **Naive RAG** operates as a relatively monolithic pipeline: it retrieves relevant documents from a knowledge base (typically via simple semantic similarity), passes them en masse to a large language model (LLM) for generation, and outputs the response. This process is static and linearâ€”often summarized as â€œretrieve-then-generate.â€ Thereâ€™s little room for intervention, orchestration, or dynamic control [2][4].\n",
      "- **Modular RAG**, in contrast, decomposes the RAG pipeline into distinct, interchangeable modules and specialized operators. Typical modules might include sophisticated retrievers, routing mechanisms, schedulers, fusion modules (for merging retrieved data), and even memory components for handling previous queries and answers. This design enables complex RAG patternsâ€”such as conditional, branching, and iterative processingâ€”rather than just linear flows [2][4].\n",
      "\n",
      "**2. Patterns and Processes**\n",
      "\n",
      "- Modular RAG supports a variety of workflows beyond the simple linear sequence of Naive RAG. For instance, it can implement **branching** (where different retrievers are invoked depending on query characteristics), **conditional logic** (dynamic choice of modules based on intermediate results), and **looping** (iterative retrieval and reasoning cycles until a stopping criterion is met) [2].\n",
      "- It also more easily accommodates memory modules, chunk optimization strategies, and seamless switching between retrieval, web search, or pure generative steps, depending on query needs [4].\n",
      "\n",
      "**3. Production-Level Benefits**\n",
      "\n",
      "- **Flexibility**: Operators and modules can be swapped, extended, or fine-tuned independently, allowing rapid adaptation to new tasks or knowledge sources. This â€œLEGO-likeâ€ reconfigurability is ideal for evolving production requirements [2][4].\n",
      "- **Scalability and Efficiency**: Because components are decoupled, resource allocation, parallelization, and distributed deployment are much more straightforward, supporting large-scale applications [2][4].\n",
      "- **Maintainability and Upgradability**: Individual modules can be updated or replaced (e.g., with a better retriever, improved fusion logic) without overhauling the entire system.\n",
      "- **Enhanced Response Quality**: Advanced routing, chunk optimization, and adaptive memory improve both relevance and factual accuracy of outputs, while reducing redundancy and minimizing the risk of hallucination [3][4].\n",
      "- **Intelligent Decision-Making**: Modular RAG can dynamically decide when to retrieve, search external sources, or rely on generation alone, leading to smarter and more context-aware responses [4].\n",
      "\n",
      "**Conclusion:**  \n",
      "While Naive RAG offers a simple and direct route to retrieval-augmented generation, Modular RAGâ€™s fine-grained modularity, orchestration mechanisms, and reconfigurability provide clear advantages for robust, adaptive, and efficient production deployments.\n",
      "\n",
      "**Sources:**  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[4] https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you, Professor Hinton. That modular orchestration is fascinating. Could you share a concrete production scenario or use case where Modular RAG clearly outperformed a Naive RAG implementation? What did the modular approach enable that simply wasnâ€™t possible before, and perhaps, what measurable benefits did you observe?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thatâ€™s a great framing. At the highest level, the main difference is that Modular RAG breaks the classic retrieval-then-generate pipeline into a set of loosely coupled, well-defined componentsâ€”whereas naive RAG glues together retrieval and generation in a monolithic, hard-to-change way.\n",
      "\n",
      "Specifically, Modular RAG typically includes:\n",
      "\n",
      "- **Well-defined APIs** between retrieval, re-ranking, and generation\n",
      "- Pluggable modules for each stage (e.g. easy to swap in a different retriever, or add an extra filtering/re-ranking step)\n",
      "- Strong type and data contract enforcement, reducing â€œsilent errorsâ€ in data interchange\n",
      "\n",
      "In contrast, Naive RAG tends to be just: â€œsend query to retriever; hand all retrieved results to an LLM; hope for the best.â€ The naive approach often results in tightly coupled, spaghetti code.\n",
      "\n",
      "A concrete example: in some production settings, we swapped in a semantic filtering module between retrieval and generation, to weed out irrelevant or disallowed content before it ever reaches the LLM. This would be painful with naive RAG, but itâ€™s an afterthought with Modular RAG.\n",
      "\n",
      "Would you like to hear about the production-level benefits that emerged from this modularization? Or perhaps a failure story from naive RAG?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"http://arxiv.org/abs/2508.11246v1\" date=\"2025-08-15\" authors=\"Runlong Yu, Shiyuan Luo, Rahul Ghosh, Lingyao Li, Yiqun Xie, Xiaowei Jia\"/>\n",
      "<Title>\n",
      "RAG for Geoscience: What We Expect, Gaps and Opportunities\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-Augmented Generation (RAG) enhances language models by combining\n",
      "retrieval with generation. However, its current workflow remains largely\n",
      "text-centric, limiting its applicability in geoscience. Many geoscientific\n",
      "tasks are inherently evidence-hungry. Typical examples involve imputing missing\n",
      "observations using analog scenes, retrieving equations and parameters to\n",
      "calibrate models, geolocating field photos based on visual cues, or surfacing\n",
      "historical case studies to support policy analyses. A simple\n",
      "``retrieve-then-generate'' pipeline is insufficient for these needs. We\n",
      "envision Geo-RAG, a next-generation paradigm that reimagines RAG as a modular\n",
      "retrieve $\\rightarrow$ reason $\\rightarrow$ generate $\\rightarrow$ verify loop.\n",
      "Geo-RAG supports four core capabilities: (i) retrieval of multi-modal Earth\n",
      "data; (ii) reasoning under physical and domain constraints; (iii) generation of\n",
      "science-grade artifacts; and (iv) verification of generated hypotheses against\n",
      "numerical models, ground measurements, and expert assessments. This shift opens\n",
      "new opportunities for more trustworthy and transparent geoscience workflows.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "RAG for Geoscience: What We Expect, Gaps and Opportunities\n",
      "Runlong Yu1, Shiyuan Luo2, Rahul Ghosh3, Lingyao Li4, Yiqun Xie5, Xiaowei Jia2\n",
      "1University of Alabama, 2University of Pittsburgh, 3University of Minnesota, Twin Cities\n",
      "4University of South Florida, 5University of Maryland, College Park\n",
      "ryu5@ua.edu, {shl298, xiaowei}@pitt.edu, ghosh128@umn.edu, lingyaol@usf.edu, xie@umd.edu\n",
      "Abstract\n",
      "Retrieval-Augmented Generation (RAG) enhances language mod-\n",
      "els by combining retrieval with generation. However, its current\n",
      "workflow remains largely text-centric, limiting its applicability\n",
      "in geoscience. Many geoscientific tasks are inherently evidence-\n",
      "hungry. Typical examples involve imputing missing observations\n",
      "using analog scenes, retrieving equations and parameters to cal-\n",
      "ibrate models, geolocating field photos based on visual cues, or\n",
      "surfacing historical case studies to support policy analyses. A sim-\n",
      "ple â€œretrieve-then-generateâ€ pipeline is insufficient for these needs.\n",
      "We envision Geo-RAG, a next-generation paradigm that reimagines\n",
      "RAG as a modular retrieve â†’reason â†’generate â†’verify loop. Geo-\n",
      "RAG supports four core capabilities: (i) retrieval of multi-modal\n",
      "Earth data; (ii) reasoning under physical and domain constraints;\n",
      "(iii) generation of science-grade artifacts; and (iv) verification of\n",
      "generated hypotheses against numerical models, ground measure-\n",
      "ments, and expert assessments. This shift opens new opportunities\n",
      "for more trustworthy and transparent geoscience workflows.\n",
      "1\n",
      "Introduction\n",
      "Retrieval-Augmented Generation (RAG) has emerged as a widely\n",
      "adopted paradigm to enhance large language models (LLMs) by\n",
      "integrating external knowledge during generation [13, 16, 24]. At\n",
      "its core, RAG retrieves relevant content from a knowledge corpus\n",
      "(e.g., documents, web resources) and feeds it into a language model\n",
      "to produce more informed and context-aware outputs. This simple\n",
      "yet powerful idea has led to notable successes in open-domain ques-\n",
      "tion answering [15, 21], code completion [6], and domain-specific\n",
      "chatbot development [33]. With the rising demand for trustwor-\n",
      "thy AI systems, RAG provides a compelling mechanism to ground\n",
      "generation in timely and verifiable knowledge sources, thereby\n",
      "mitigating hallucinations and improving factual accuracy [24, 33].\n",
      "1.1\n",
      "Success Stories from RAG\n",
      "1.1.1\n",
      "Open-Domain Question Answering and Search Augmentation.\n",
      "RAG has shown remarkable performance in knowledge-intensive\n",
      "tasks, particularly in open-domain question answering [24]. Sys-\n",
      "tems like Googleâ€™s Search-Augmented Models and Metaâ€™s origi-\n",
      "nal RAG framework combine retrieval from large corpora (e.g.,\n",
      "Wikipedia) with generation, allowing models to answer questions\n",
      "that would otherwise exceed their parametric memory. This ap-\n",
      "proach enables factual consistency while remaining flexible and\n",
      "scalable, and has been widely adopted in digital assistants and\n",
      "enterprise search [13, 21].\n",
      "1.1.2\n",
      "Domain Adaptation and Low-Resource Knowledge Access. In\n",
      "specialized domains such as biomedicine, law, and customer ser-\n",
      "vice, RAG has been used to inject domain-specific corpora into\n",
      "the generation process, offering low-cost adaptation without full\n",
      "retraining [7, 36]. For instance, medical QA systems can retrieve\n",
      "research articles or clinical guidelines to support diagnoses; legal\n",
      "assistants can cite relevant regulations in generated summaries.\n",
      "1.2\n",
      "Why RAG for Geoscience Is Different\n",
      "Geoscientific questions rarely reduce to simply â€œfinding a passage\n",
      "and summarizing it.â€ Instead, they involve evidence-hungry tasks,\n",
      "where models should go beyond parametric memory and surface-\n",
      "level language generation. Effective reasoning in these contexts\n",
      "requires retrieving, citing, and grounding outputs in external, struc-\n",
      "tured, and domain-specific knowledge [20, 38]. Typical examples\n",
      "include imputing missing observations using analog scenes, retriev-\n",
      "ing equations and parameters to calibrate models, geolocating field\n",
      "photos based on visual cues, and surfacing historical case studies\n",
      "\n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2408.05933v1\" date=\"2024-08-12\" authors=\"Fei Liu, Zejun Kang, Xing Han\"/>\n",
      "<Title>\n",
      "Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "With the growing demand for offline PDF chatbots in automotive industrial\n",
      "production environments, optimizing the deployment of large language models\n",
      "(LLMs) in local, low-performance settings has become increasingly important.\n",
      "This study focuses on enhancing Retrieval-Augmented Generation (RAG) techniques\n",
      "for processing complex automotive industry documents using locally deployed\n",
      "Ollama models. Based on the Langchain framework, we propose a multi-dimensional\n",
      "optimization approach for Ollama's local RAG implementation. Our method\n",
      "addresses key challenges in automotive document processing, including\n",
      "multi-column layouts and technical specifications. We introduce improvements in\n",
      "PDF processing, retrieval mechanisms, and context compression, tailored to the\n",
      "unique characteristics of automotive industry documents. Additionally, we\n",
      "design custom classes supporting embedding pipelines and an agent supporting\n",
      "self-RAG based on LangGraph best practices. To evaluate our approach, we\n",
      "constructed a proprietary dataset comprising typical automotive industry\n",
      "documents, including technical reports and corporate regulations. We compared\n",
      "our optimized RAG model and self-RAG agent against a naive RAG baseline across\n",
      "three datasets: our automotive industry dataset, QReCC, and CoQA. Results\n",
      "demonstrate significant improvements in context precision, context recall,\n",
      "answer relevancy, and faithfulness, with particularly notable performance on\n",
      "the automotive industry dataset. Our optimization scheme provides an effective\n",
      "solution for deploying local RAG systems in the automotive sector, addressing\n",
      "the specific needs of PDF chatbots in industrial production environments. This\n",
      "research has important implications for advancing information processing and\n",
      "intelligent production in the automotive industry.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with \n",
      "Locally Deployed Ollama Models \n",
      "Optimizing RAG Techniques Based on Locally Deployed Ollama Models \n",
      "A Case Study with Locally Deployed Ollama Models \n",
      "Fei Liu * \n",
      "China Automotive Technology & Research Center, liufei@catarc.ac.cn \n",
      "Zejun Kang \n",
      "China Automotive Technology & Research Center, kangzejun@catarc.ac.cn \n",
      "Xing Han \n",
      "China Automotive Technology & Research Center, hanxing@catarc.ac.cn \n",
      "With the growing demand for offline PDF chatbots in automotive industrial production environments, optimizing the deployment \n",
      "of large language models (LLMs) in local, low-performance settings has become increasingly important. This study focuses on \n",
      "enhancing Retrieval-Augmented Generation (RAG) techniques for processing complex automotive industry documents using \n",
      "locally deployed Ollama models. \n",
      "Based on the Langchain framework, we propose a multi-dimensional optimization approach for Ollama's local RAG \n",
      "implementation. Our method addresses key challenges in automotive document processing, including multi-column layouts and \n",
      "technical specifications. We introduce improvements in PDF processing, retrieval mechanisms, and context compression, tailored \n",
      "to the unique characteristics of automotive industry documents. Additionally, we design custom classes supporting embedding \n",
      "pipelines and an agent supporting self-RAG based on LangGraph best practices. \n",
      "To evaluate our approach, we constructed a proprietary dataset comprising typical automotive industry documents, including \n",
      "technical reports and corporate regulations. We compared our optimized RAG model and self-RAG agent against a naive RAG \n",
      "baseline across three datasets: our automotive industry dataset, QReCC, and CoQA. Results demonstrate significant improvements \n",
      "in context precision, context recall, answer relevancy, and faithfulness, with particularly notable performance on the automotive \n",
      "industry dataset. \n",
      "Our optimization scheme provides an effective solution for deploying local RAG systems in the automotive sector, addressing the \n",
      "specific needs of PDF chatbots in industrial production environments. This research has important implications for advancing \n",
      "information processing and intelligent production in the automotive industry. \n",
      " \n",
      "* Place the footnote text for the author (if applicable) here.  \n",
      "CCS CONCEPTS â€¢ Computing methodologies â€¢ Artificial intelligence â€¢ Natural language processing â€¢ Natural language \n",
      "generation \n",
      " \n",
      "Additional Keywords and Phrases: Automotive Industry, Langchain, self-rag, PDF Processing, RAG, Ollama \n",
      "1 INTRODUCTION \n",
      "1.1 Research Background \n",
      "The automotive industry is undergoing a significant digital transformation, with an increasing reliance on complex \n",
      "technical documentation for various processes [1]. This shift encompasses design, manufacturing, and quality \n",
      "control, all of which now heavily depend on efficient information management systems [2]. The growing volume of \n",
      "technical documents, often in PDF format, has created a pressing need for advanced information retrieval and \n",
      "question-answering capabilities in industrial settings [3]. \n",
      "Large Language Models (LLMs) have emerged as powerful tools in natural language processing, demonstrating \n",
      "remarkable abilities in tasks such as document understanding and question answering [4]. These models have \n",
      "shown potential in handling the complex, domain-specific language often found in automotive documentation. \n",
      "However, the application of LLMs in industrial environments presents unique challenges, particularly in terms of \n",
      "computational resources and data privacy [5]. \n",
      "Among the various techniques developed to enhance LLM performance, Retrieval-Augmented Generation (RAG) \n",
      "has gained significant attention [6]. RAG combines the generative capabilities of LLMs with external knowledge \n",
      "retrieval, allowing for more accurate and contextually relevant responses. This approach, initially proposed by \n",
      "Lew\n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2410.12812v1\" date=\"2024-10-01\" authors=\"Sarah Packowski, Inge Halilovic, Jenifer Schlotfeldt, Trish Smith\"/>\n",
      "<Title>\n",
      "Optimizing and Evaluating Enterprise Retrieval-Augmented Generation (RAG): A Content Design Perspective\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented generation (RAG) is a popular technique for using large\n",
      "language models (LLMs) to build customer-support, question-answering solutions.\n",
      "In this paper, we share our team's practical experience building and\n",
      "maintaining enterprise-scale RAG solutions that answer users' questions about\n",
      "our software based on product documentation. Our experience has not always\n",
      "matched the most common patterns in the RAG literature. This paper focuses on\n",
      "solution strategies that are modular and model-agnostic. For example, our\n",
      "experience over the past few years - using different search methods and LLMs,\n",
      "and many knowledge base collections - has been that simple changes to the way\n",
      "we create knowledge base content can have a huge impact on our RAG solutions'\n",
      "success. In this paper, we also discuss how we monitor and evaluate results.\n",
      "Common RAG benchmark evaluation techniques have not been useful for evaluating\n",
      "responses to novel user questions, so we have found a flexible, \"human in the\n",
      "lead\" approach is required.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "Optimizing and Evaluating Enterprise Retrieval-Augmented\n",
      "Generation (RAG): A Content Design Perspective\n",
      "Sarah Packowski\n",
      "spackows@ca.ibm.com\n",
      "IBM\n",
      "Canada\n",
      "Inge Halilovic\n",
      "ingeh@us.ibm.com\n",
      "IBM\n",
      "United States\n",
      "Jenifer Schlotfeldt\n",
      "jschlot@us.ibm.com\n",
      "IBM\n",
      "United States\n",
      "Trish Smith\n",
      "smith@ca.ibm.com\n",
      "IBM\n",
      "Canada\n",
      "ABSTRACT\n",
      "Retrieval-augmented generation (RAG) is a popular technique for\n",
      "using large language models (LLMs) to build customer-support,\n",
      "question-answering solutions. In this paper, we share our teamâ€™s\n",
      "practical experience building and maintaining enterprise-scale RAG\n",
      "solutions that answer usersâ€™ questions about our software based on\n",
      "product documentation. Our experience has not always matched\n",
      "the most common patterns in the RAG literature. This paper focuses\n",
      "on solution strategies that are modular and model-agnostic. For\n",
      "example, our experience over the past few years - using different\n",
      "search methods and LLMs, and many knowledge base collections -\n",
      "has been that simple changes to the way we create knowledge base\n",
      "content can have a huge impact on our RAG solutionsâ€™ success. In\n",
      "this paper, we also discuss how we monitor and evaluate results.\n",
      "Common RAG benchmark evaluation techniques have not been\n",
      "useful for evaluating responses to novel user questions, so we have\n",
      "found a flexible, \"human in the lead\" approach is required.\n",
      "CCS CONCEPTS\n",
      "â€¢ Computing methodologies â†’Artificial intelligence; Natu-\n",
      "ral language generation; â€¢ Applied computing â†’Document\n",
      "management and text processing.\n",
      "KEYWORDS\n",
      "Retrieval-augmented generation, RAG, Large language models\n",
      "ACM Reference Format:\n",
      "Sarah Packowski, Inge Halilovic, Jenifer Schlotfeldt, and Trish Smith. 2024.\n",
      "Optimizing and Evaluating Enterprise Retrieval-Augmented Generation\n",
      "(RAG): A Content Design Perspective. In Proceedings of 8th International\n",
      "Conference on Advances in Artificial Intelligence (ICAAI â€™24). ACM, New York,\n",
      "NY, USA, 6 pages.\n",
      "Permission to make digital or hard copies of part or all of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for third-party components of this work must be honored.\n",
      "For all other uses, contact the owner/author(s).\n",
      "ICAAI â€™24, October 2024, London, UK\n",
      "Â© 2024 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1801-4/24/10.\n",
      "1\n",
      "INTRODUCTION\n",
      "Retrieval-augmented generation (RAG) is an effective way to use\n",
      "large language models (LLMs) to answer questions while avoiding\n",
      "hallucinations and factual inaccuracy[12, 20, 46]. Basic RAG is sim-\n",
      "ple: 1) search a knowledge base for relevant content; 2) compose a\n",
      "prompt grounded in the retrieved content; and 3) prompt an LLM to\n",
      "generate output. For the retrieval step, one approach dominates the\n",
      "literature: 1) segment content text into chunks; 2) index vectorized\n",
      "chunks for search in a vector database; and 3) when generating\n",
      "answers, ground prompts in a subset of retrieved chunks[13]. Our\n",
      "RAG solutions donâ€™t always use vector databases for search.\n",
      "Wikipedia has long been influenced by and had an influence on\n",
      "scientific research [21, 41]. With respect to RAG, Wikipedia is a dom-\n",
      "inant source of knowledge base content for training data and bench-\n",
      "marks, including: 2WikiMultiHopQA, AmbigQA, ASQA, DART,\n",
      "FEVER, HotpotQA, KILT, MuSiQue, Natural Questions, NoMIRACL,\n",
      "PopQA, SQuAD, StrategyQA, SuperGLUE, TriviaQA, WikiAsp, Wik-\n",
      "iBio, WikiEval, and Wizard of Wikipedia[8, 9, 14â€“16, 18, 22, 23, 25,\n",
      "28, 29, 31, 34, 39, 40, 42â€“44, 48]. The knowledge base for our teamâ€™s\n",
      "RAG solutions is our own product documentation, which is struc-\n",
      "tured differently from Wikipedia articles.\n",
      "Using common benchmarks to test your RAG implementation\n",
      "involves these steps: 1) index the given knowledge base content in\n",
      "your retriever component; 2) prompt your solution to answer the\n",
      "given questions; and 3) compare generated answers to expected\n",
      "answers, using methods such as exact match, cos\n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manswer_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: expert\n",
      "\n",
      "Certainly, Dr. Alvarez. Modular RAG represents a significant evolution over traditional Naive RAG, particularly relevant for production environments. Hereâ€™s a detailed breakdown based strictly on the provided context:\n",
      "\n",
      "**1. Architectural Differences**\n",
      "\n",
      "- **Naive RAG**: Operates on a â€œretrieve-then-generateâ€ pipeline. The system retrieves relevant documents or chunks from an external knowledge base and directly feeds all retrieved content to the generative model. This process is linear and monolithic, meaning components (retriever, generator) are tightly coupled and not easily replaceable or adaptable [2][4].\n",
      "\n",
      "- **Modular RAG**: Decomposes the RAG workflow into independent, interchangeable modulesâ€”think of â€œLEGO-likeâ€ building blocks. Each module (retriever, reranker, generator, router, fusion, scheduler, etc.) can be independently developed, replaced, or optimized. Modular RAG supports non-linear patterns such as conditional logic, branching, and looping, and enables the integration of advanced mechanisms like routing and scheduling within the pipeline [2][4].\n",
      "\n",
      "**2. Key Benefits at the Production Level**\n",
      "\n",
      "- **Flexibility and Adaptivity**: Modular RAG enables seamless integration of different retrieval modules, specialized LLMs, or new operators as needs evolve, without overhauling the whole stack. This is essential for keeping up with fast-changing requirements and model capabilities in production [2][4].\n",
      "\n",
      "- **Scalability**: By having standardized, decoupled modules, systems can more easily scale out individual bottlenecks (e.g., upgrade only the retrieval module) or add domain-specific logic (e.g., a taxonomy-specific router) without affecting the rest of the pipeline [2][4].\n",
      "\n",
      "- **Efficiency and Latency Control**: Modularization allows for targeted optimizationsâ€”such as only scheduling compute-intensive modules conditionallyâ€”thereby reducing system latency and computational costs in production [2][4].\n",
      "\n",
      "- **Maintenance & Experimentation**: With clearly defined interfaces, teams can experiment or fine-tune specific modules (like retrievers or rerankers), swap out underperforming components, or conduct A/B testing systematically. This reduces operational risks and accelerates deployment cycles [4].\n",
      "\n",
      "- **Improved Retrieval Quality**: Naive RAG often suffers from shallow query understanding and retrieval redundancy/noise, leading to hallucinations or irrelevant content in generation. Modular RAG introduces fine-grained control and processing steps (like advanced routing and filtering) that improve precision and minimize the risk of misleading the LLM [2][4].\n",
      "\n",
      "- **Robustness to Complexity**: As production RAG applications grow in complexity (multiple domains, user types, or knowledge sources), modular RAGâ€™s reconfigurable framework is better suited for orchestrating heterogeneous requirements and evolving architectures [2].\n",
      "\n",
      "**Summary**: Modular RAG differs from Naive RAG by breaking up the pipeline into interchangeable, independently managed modules with advanced mechanisms for routing and orchestration. This change results in increased flexibility, scalability, efficiency, and system maintainabilityâ€”crucial factors for robust, high-performance production deployments [2][4].\n",
      "\n",
      "---\n",
      "\n",
      "**Sources**:  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[4] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document href=\"https://opusintelligence.com/white-papers/the-one-about-rag\"/>\n",
      "Modular RAG largely concerns itself with the same 5 high-level concerns of Naive RAG, but is architected to offer greater diversity and flexibility in the\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
      "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. By adopting a modular architecture, this approach addresses the limitations of Naive RAG, offering enhanced flexibility, scalability, and efficiency. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. * *Seamless Integration*: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://medium.com/@myscale/naive-rag-vs-advanced-rag-17b38cda44c1\"/>\n",
      "Naive RAG is ideal for simpler use cases where speed and straightforward implementation are priorities. It enhances LLM performance in scenarios where deep\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstractâ€”Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of â€œretrieve-then-generateâ€. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patternsâ€”linear, conditional,\n",
      "branching, and loopingâ€”and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Termsâ€”Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]â€“[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLMâ€™s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2508.05650v1\" date=\"2025-07-26\" authors=\"Jiaxuan Liang, Shide Zhou, Kailong Wang\"/>\n",
      "<Title>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "While Retrieval Augmented Generation (RAG) is now widely adopted to enhance\n",
      "LLMs, evaluating its true performance benefits in a reproducible and\n",
      "interpretable way remains a major hurdle. Existing methods often fall short:\n",
      "they lack domain coverage, employ coarse metrics that miss sub document\n",
      "precision, and fail to capture computational trade offs. Most critically, they\n",
      "provide no standardized framework for comparing RAG effectiveness across\n",
      "different models and domains.\n",
      "  We introduce OmniBench RAG, a novel automated platform for multi domain\n",
      "evaluation of RAG systems. The platform quantifies performance gains across\n",
      "accuracy and efficiency dimensions, spanning nine knowledge fields including\n",
      "culture, geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency differences\n",
      "between pre RAG and post RAG models), enabling reproducible comparisons across\n",
      "models and tasks. The platform features dynamic test generation, modular\n",
      "evaluation pipelines, and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant gains in\n",
      "culture to declines in mathematics, highlighting the critical importance of\n",
      "systematic, domain aware assessment. A demonstration video is available at:\n",
      "https://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets:\n",
      "https://github.com/Garnett-Liang/Omnibench-RAG.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation\n",
      "Platform for Retrieval-Augmented Generation Tools\n",
      "Jiaxuan Liang*, Shide Zhou*, and Kailong Wangâ€ \n",
      "Huazhong University of Science and Technology\n",
      "{liangjx, shidez, wangkl}@hust.edu.cn\n",
      "Abstractâ€”While Retrieval Augmented Generation (RAG) is\n",
      "now widely adopted to enhance LLMs, evaluating its true\n",
      "performance benefits in a reproducible and interpretable way\n",
      "remains a major hurdle. Existing methods often fall short: they\n",
      "lack domain coverage, employ coarse metrics that miss sub\n",
      "document precision, and fail to capture computational trade\n",
      "offs. Most critically, they provide no standardized framework\n",
      "for comparing RAG effectiveness across different models and\n",
      "domains.\n",
      "We introduce OmniBench RAG, a novel automated platform\n",
      "for multi domain evaluation of RAG systems. The platform\n",
      "quantifies performance gains across accuracy and efficiency\n",
      "dimensions, spanning nine knowledge fields including culture,\n",
      "geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency\n",
      "differences between pre RAG and post RAG models), enabling\n",
      "reproducible comparisons across models and tasks. The platform\n",
      "features dynamic test generation, modular evaluation pipelines,\n",
      "and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant\n",
      "gains in culture to declines in mathematics, highlighting the\n",
      "critical importance of systematic, domain aware assessment. A\n",
      "demonstration video is available at: https://www.youtube.com/\n",
      "watch?v=BZx83QFcTCI. Code and datasets: https://github.com/\n",
      "Garnett-Liang/Omnibench-RAG.\n",
      "I. INTRODUCTION\n",
      "Retrieval-Augmented Generation (RAG) is a key technique\n",
      "for enhancing Large Language Models (LLMs) [1], [2]. By\n",
      "grounding model responses in external, verifiable knowledge,\n",
      "RAG promises to mitigate hallucinations [3], improve factual\n",
      "accuracy [4], and provide up-to-date information [5]. However,\n",
      "the true effectiveness of RAG is far from uniform. Recent\n",
      "studies [6], [7] reveal a significant disparity: while RAG\n",
      "can boost the accuracy of smaller models like Llama-3.2-3B-\n",
      "Instruct by as much as 38.12%, its impact on state-of-the-art\n",
      "models such as GPT-4o, which excel with extended context\n",
      "windows, is often less pronounced. This variability, which\n",
      "depends not only on the modelâ€™s scale but also heavily on\n",
      "the knowledge domain, underscores a critical challenge: the\n",
      "lack of a systematic platform to quantify the value of RAG\n",
      "across these diverse contexts.\n",
      "Current RAG evaluation approaches suffer from fundamen-\n",
      "tal limitations that impede reproducible and comprehensive as-\n",
      "sessment: First, they lack automated multi-domain evalua-\n",
      "tion capabilities and rely on non-deterministic components.\n",
      "*Jiaxuan Liang and Shide Zhou are co-first authors.\n",
      "â€ Kailong Wang is the corresponding author.\n",
      "Existing benchmarks typically require manual configuration\n",
      "for each knowledge domain and fail to provide unified assess-\n",
      "ment across diverse fields like finance, healthcare, or culture,\n",
      "making cross-domain performance analysis labor-intensive and\n",
      "inconsistent. Moreover, key metrics in leading frameworks\n",
      "(e.g., LLM-based scoring in Ragas [8]) inadvertently introduce\n",
      "randomness due to reliance on large language models in the\n",
      "evaluation loop, undermining result reproducibility. Second,\n",
      "they employ static datasets and coarse-grained metrics.\n",
      "Most frameworks rely on fixed benchmarks and document-\n",
      "level retrieval metrics (e.g., MRR@k[9]), missing the critical\n",
      "sub-document precision needed to assess whether models\n",
      "extract specific facts accurately. They also lack the ability to\n",
      "dynamically generate test cases that probe complex reasoning\n",
      "patterns. Third, they fail to capture the computational\n",
      "trade-offs inherent in RAG systems. Without automated\n",
      "profiling of resource utilization and efficiency metrics, practi-\n",
      "tioners cannot make informed decisions about the cost-benefit\n",
      "trade-offs of deploying RAG in production environments.\n",
      "Our \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2505.13006v1\" date=\"2025-05-19\" authors=\"Yuyang Li, Philip J. M. Kerbusch, Raimon H. R. Pruim, Tobias KÃ¤fer\"/>\n",
      "<Title>\n",
      "Evaluating the Performance of RAG Methods for Conversational AI in the Airport Domain\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Airports from the top 20 in terms of annual passengers are highly dynamic\n",
      "environments with thousands of flights daily, and they aim to increase the\n",
      "degree of automation. To contribute to this, we implemented a Conversational AI\n",
      "system that enables staff in an airport to communicate with flight information\n",
      "systems. This system not only answers standard airport queries but also\n",
      "resolves airport terminology, jargon, abbreviations, and dynamic questions\n",
      "involving reasoning. In this paper, we built three different\n",
      "Retrieval-Augmented Generation (RAG) methods, including traditional RAG, SQL\n",
      "RAG, and Knowledge Graph-based RAG (Graph RAG). Experiments showed that\n",
      "traditional RAG achieved 84.84% accuracy using BM25 + GPT-4 but occasionally\n",
      "produced hallucinations, which is risky to airport safety. In contrast, SQL RAG\n",
      "and Graph RAG achieved 80.85% and 91.49% accuracy respectively, with\n",
      "significantly fewer hallucinations. Moreover, Graph RAG was especially\n",
      "effective for questions that involved reasoning. Based on our observations, we\n",
      "thus recommend SQL RAG and Graph RAG are better for airport environments, due\n",
      "to fewer hallucinations and the ability to handle dynamic questions.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "arXiv:2505.13006v1  [cs.CL]  19 May 2025\n",
      "Evaluating the Performance of RAG Methods for Conversational AI in the\n",
      "Airport Domain\n",
      "Yuyang Li1, Philip J.M. Kerbusch2, Raimon H.R. Pruim2, Tobias KÃ¤fer1\n",
      "1Karlsruhe Institute of Technology, 2Royal Schiphol Group\n",
      "2Royal Schiphol Group, 1Karlsruhe Institute of Technology\n",
      "yuyang.li@kit.edu,\n",
      "tobias.kaefer@kit.edu\n",
      "Abstract\n",
      "Airports from the top 20 in terms of annual\n",
      "passengers are highly dynamic environments\n",
      "with thousands of flights daily, and they aim\n",
      "to increase the degree of automation. To con-\n",
      "tribute to this, we implemented a Conversa-\n",
      "tional AI system that enables staff in an air-\n",
      "port to communicate with flight information\n",
      "systems. This system not only answers stan-\n",
      "dard airport queries but also resolves airport ter-\n",
      "minology, jargon, abbreviations, and dynamic\n",
      "questions involving reasoning. In this paper, we\n",
      "built three different Retrieval-Augmented Gen-\n",
      "eration (RAG) methods, including traditional\n",
      "RAG, SQL RAG, and Knowledge Graph-based\n",
      "RAG (Graph RAG). Experiments showed that\n",
      "traditional RAG achieved 84.84% accuracy\n",
      "using BM25 + GPT-4 but occasionally pro-\n",
      "duced hallucinations, which is risky to airport\n",
      "safety. In contrast, SQL RAG and Graph RAG\n",
      "achieved 80.85% and 91.49% accuracy respec-\n",
      "tively, with significantly fewer hallucinations.\n",
      "Moreover, Graph RAG was especially effective\n",
      "for questions that involved reasoning. Based\n",
      "on our observations, we thus recommend SQL\n",
      "RAG and Graph RAG are better for airport en-\n",
      "vironments, due to fewer hallucinations and the\n",
      "ability to handle dynamic questions.\n",
      "1\n",
      "Introduction\n",
      "Amsterdam Airport Schiphol, one of the top 20\n",
      "airports in the world, ranked by annual passenger\n",
      "numbers, handles thousands of flights each day.\n",
      "These airports rely on staff like gate planners and\n",
      "apron controllers to access and update data across\n",
      "systems. For these employees, traditional database\n",
      "queries can be complex and time-consuming for\n",
      "some employees who are not query experts when\n",
      "they need flight information. A conversational AI\n",
      "system with a natural language query (NLQ) inter-\n",
      "face allows all employees to interact with systems\n",
      "naturally, asking questions like, â€œWhich fights are\n",
      "at ramp D07?â€ and receiving instant answers. This\n",
      "improves productivity, and streamlines workflows,\n",
      "especially in high-pressure areas like at the gate,\n",
      "where less educated workers require access to up-\n",
      "to-date information. By replacing strict query for-\n",
      "mats with intuitive, real-time responses, conversa-\n",
      "tional AI enhances decision-making and efficiency,\n",
      "making it a suitable solution for dynamic environ-\n",
      "ments such as airports.\n",
      "Building such a system is challenging because\n",
      "flight data is stored by experts in tables using avi-\n",
      "ation abbreviations. We need our system to un-\n",
      "derstand these datasets to answer questions from\n",
      "the airport domain. Additionally, ensuring avia-\n",
      "tion safety is a major concern; the system must\n",
      "be safe and enable employees to perform accurate\n",
      "operations. We address those challenges using two\n",
      "research questions.\n",
      "The first question is how to handle flight data so\n",
      "that our system can answer different questions. We\n",
      "divided the questions into three types:\n",
      "â€¢ Straightforward questions: Questions that\n",
      "can be directly answered from the flight data.\n",
      "â€¢ Questions involving specialized airport jar-\n",
      "gon, abbreviations, and incomplete queries:\n",
      "Operators often use shorthand or omit con-\n",
      "text. Flight â€œKL0123â€ might be referred to as\n",
      "â€œ0123â€ or â€œ123,â€ while gate â€œC05â€ might be\n",
      "shortened to â€œC5.â€ Abbreviations like â€œKLMâ€\n",
      "for â€œKLM Royal Dutch Airlinesâ€ or â€œDeltaâ€\n",
      "for â€œDelta Air Linesâ€ are also common. Op-\n",
      "erators frequently ask short, incomplete ques-\n",
      "tions, e. g., â€œWhich flights are at D04?â€ or\n",
      "â€œWhat is the gate for that Delta airline?â€ With-\n",
      "out resolving missing details such, these ques-\n",
      "tions cannot be answered.\n",
      "â€¢ Dynamic questions: Questions that involve\n",
      "additional calculations and reasoning, espe-\n",
      "cially related to time.\n",
      "Examples include\n",
      "â€œWhat is the connecting flightâ€™s onramp time\n",
      "for D\n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mask_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you, Dr. Alvarez. Thatâ€™s a very clear technical breakdownâ€”especially the points on modularized routing, branching, and decoupling. To make it even more tangible, could you share a specific real-world example or case study from your team where Modular RAG directly unlocked new capabilities, higher retrieval quality, or lower latency than a prior naive RAG system? What did the impact look like quantitatively or qualitatively in practice?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"http://arxiv.org/abs/2508.05650v1\" date=\"2025-07-26\" authors=\"Jiaxuan Liang, Shide Zhou, Kailong Wang\"/>\n",
      "<Title>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "While Retrieval Augmented Generation (RAG) is now widely adopted to enhance\n",
      "LLMs, evaluating its true performance benefits in a reproducible and\n",
      "interpretable way remains a major hurdle. Existing methods often fall short:\n",
      "they lack domain coverage, employ coarse metrics that miss sub document\n",
      "precision, and fail to capture computational trade offs. Most critically, they\n",
      "provide no standardized framework for comparing RAG effectiveness across\n",
      "different models and domains.\n",
      "  We introduce OmniBench RAG, a novel automated platform for multi domain\n",
      "evaluation of RAG systems. The platform quantifies performance gains across\n",
      "accuracy and efficiency dimensions, spanning nine knowledge fields including\n",
      "culture, geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency differences\n",
      "between pre RAG and post RAG models), enabling reproducible comparisons across\n",
      "models and tasks. The platform features dynamic test generation, modular\n",
      "evaluation pipelines, and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant gains in\n",
      "culture to declines in mathematics, highlighting the critical importance of\n",
      "systematic, domain aware assessment. A demonstration video is available at:\n",
      "https://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets:\n",
      "https://github.com/Garnett-Liang/Omnibench-RAG.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation\n",
      "Platform for Retrieval-Augmented Generation Tools\n",
      "Jiaxuan Liang*, Shide Zhou*, and Kailong Wangâ€ \n",
      "Huazhong University of Science and Technology\n",
      "{liangjx, shidez, wangkl}@hust.edu.cn\n",
      "Abstractâ€”While Retrieval Augmented Generation (RAG) is\n",
      "now widely adopted to enhance LLMs, evaluating its true\n",
      "performance benefits in a reproducible and interpretable way\n",
      "remains a major hurdle. Existing methods often fall short: they\n",
      "lack domain coverage, employ coarse metrics that miss sub\n",
      "document precision, and fail to capture computational trade\n",
      "offs. Most critically, they provide no standardized framework\n",
      "for comparing RAG effectiveness across different models and\n",
      "domains.\n",
      "We introduce OmniBench RAG, a novel automated platform\n",
      "for multi domain evaluation of RAG systems. The platform\n",
      "quantifies performance gains across accuracy and efficiency\n",
      "dimensions, spanning nine knowledge fields including culture,\n",
      "geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency\n",
      "differences between pre RAG and post RAG models), enabling\n",
      "reproducible comparisons across models and tasks. The platform\n",
      "features dynamic test generation, modular evaluation pipelines,\n",
      "and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant\n",
      "gains in culture to declines in mathematics, highlighting the\n",
      "critical importance of systematic, domain aware assessment. A\n",
      "demonstration video is available at: https://www.youtube.com/\n",
      "watch?v=BZx83QFcTCI. Code and datasets: https://github.com/\n",
      "Garnett-Liang/Omnibench-RAG.\n",
      "I. INTRODUCTION\n",
      "Retrieval-Augmented Generation (RAG) is a key technique\n",
      "for enhancing Large Language Models (LLMs) [1], [2]. By\n",
      "grounding model responses in external, verifiable knowledge,\n",
      "RAG promises to mitigate hallucinations [3], improve factual\n",
      "accuracy [4], and provide up-to-date information [5]. However,\n",
      "the true effectiveness of RAG is far from uniform. Recent\n",
      "studies [6], [7] reveal a significant disparity: while RAG\n",
      "can boost the accuracy of smaller models like Llama-3.2-3B-\n",
      "Instruct by as much as 38.12%, its impact on state-of-the-art\n",
      "models such as GPT-4o, which excel with extended context\n",
      "windows, is often less pronounced. This variability, which\n",
      "depends not only on the modelâ€™s scale but also heavily on\n",
      "the knowledge domain, underscores a critical challenge: the\n",
      "lack of a systematic platform to quantify the value of RAG\n",
      "across these diverse contexts.\n",
      "Current RAG evaluation approaches suffer from fundamen-\n",
      "tal limitations that impede reproducible and comprehensive as-\n",
      "sessment: First, they lack automated multi-domain evalua-\n",
      "tion capabilities and rely on non-deterministic components.\n",
      "*Jiaxuan Liang and Shide Zhou are co-first authors.\n",
      "â€ Kailong Wang is the corresponding author.\n",
      "Existing benchmarks typically require manual configuration\n",
      "for each knowledge domain and fail to provide unified assess-\n",
      "ment across diverse fields like finance, healthcare, or culture,\n",
      "making cross-domain performance analysis labor-intensive and\n",
      "inconsistent. Moreover, key metrics in leading frameworks\n",
      "(e.g., LLM-based scoring in Ragas [8]) inadvertently introduce\n",
      "randomness due to reliance on large language models in the\n",
      "evaluation loop, undermining result reproducibility. Second,\n",
      "they employ static datasets and coarse-grained metrics.\n",
      "Most frameworks rely on fixed benchmarks and document-\n",
      "level retrieval metrics (e.g., MRR@k[9]), missing the critical\n",
      "sub-document precision needed to assess whether models\n",
      "extract specific facts accurately. They also lack the ability to\n",
      "dynamically generate test cases that probe complex reasoning\n",
      "patterns. Third, they fail to capture the computational\n",
      "trade-offs inherent in RAG systems. Without automated\n",
      "profiling of resource utilization and efficiency metrics, practi-\n",
      "tioners cannot make informed decisions about the cost-benefit\n",
      "trade-offs of deploying RAG in production environments.\n",
      "Our \n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2502.11228v2\" date=\"2025-05-22\" authors=\"Mohammad Reza Rezaei, Adji Bousso Dieng\"/>\n",
      "<Title>\n",
      "Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\n",
      "for domain-specific question-answering (QA) tasks by leveraging external\n",
      "knowledge sources. However, traditional RAG systems primarily focus on\n",
      "relevance-based retrieval and often struggle with redundancy, especially when\n",
      "reasoning requires connecting information from multiple sources. This paper\n",
      "introduces Vendi-RAG, a framework based on an iterative process that jointly\n",
      "optimizes retrieval diversity and answer quality. This joint optimization leads\n",
      "to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\n",
      "the Vendi Score (VS), a flexible similarity-based diversity metric, to promote\n",
      "semantic diversity in document retrieval. It then uses an LLM judge that\n",
      "evaluates candidate answers, generated after a reasoning step, and outputs a\n",
      "score that the retriever uses to balance relevance and diversity among the\n",
      "retrieved documents during each iteration. Experiments on three challenging\n",
      "datasets -- HotpotQA, MuSiQue, and 2WikiMultiHopQA -- demonstrate Vendi-RAG's\n",
      "effectiveness in multi-hop reasoning tasks. The framework achieves significant\n",
      "accuracy improvements over traditional single-step and multi-step RAG\n",
      "approaches, with accuracy increases reaching up to +4.2% on HotpotQA, +4.1% on\n",
      "2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the current\n",
      "best baseline. The benefits of Vendi-RAG are even more pronounced as the number\n",
      "of retrieved documents increases. Finally, we evaluated Vendi-RAG across\n",
      "different LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini, and\n",
      "observed consistent improvements, demonstrating that the framework's advantages\n",
      "are model-agnostic.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "Vendi-RAG: Adaptively Trading-Off Diversity And\n",
      "Quality Significantly Improves Retrieval\n",
      "Augmented Generation With LLMs\n",
      "Mohammad R. Rezaei1, 3 and Adji Bousso Dieng2, 3\n",
      "1Institute of Biomedical Engineering, University of Toronto\n",
      "2Department of Computer Science, Princeton University\n",
      "3Vertaix\n",
      "May 26, 2025\n",
      "Abstract\n",
      "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\n",
      "for domain-specific question-answering (QA) tasks by leveraging external\n",
      "knowledge sources. However, traditional RAG systems primarily focus on\n",
      "relevance-based retrieval and often struggle with redundancy, especially when\n",
      "reasoning requires connecting information from multiple sources. This paper\n",
      "introduces Vendi-RAG, a framework based on an iterative process that jointly\n",
      "optimizes retrieval diversity and answer quality. This joint optimization leads\n",
      "to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\n",
      "the Vendi Score (VS), a flexible similarity-based diversity metric, to promote\n",
      "semantic diversity in document retrieval. It then uses an LLM judge that eval-\n",
      "uates candidate answers, generated after a reasoning step, and outputs a\n",
      "score that the retriever uses to balance relevance and diversity among the\n",
      "retrieved documents during each iteration. Experiments on three challenging\n",
      "datasetsâ€”HotpotQA, MuSiQue, and 2WikiMultiHopQAâ€”demonstrate Vendi-\n",
      "RAGâ€™s effectiveness in multi-hop reasoning tasks. The framework achieves sig-\n",
      "nificant accuracy improvements over traditional single-step or multi-step RAG\n",
      "approaches, with accuracy increases reaching +4.2% on HotpotQA, +4.1% on\n",
      "2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the\n",
      "current best baseline. The benefits of Vendi-RAG are even more pronounced as\n",
      "the number of retrieved documents increases. Finally, we evaluated Vendi-RAG\n",
      "across different LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini,\n",
      "and observed consistent improvements, demonstrating that the frameworkâ€™s\n",
      "advantages are model-agnostic.\n",
      "Keywords: RAG, LLMs, Question Answering, NLP, Diversity, Vendi Scoring\n",
      "1\n",
      "Introduction\n",
      "Retrieval-augmented generation (RAG) has emerged as a transformative framework\n",
      "for enhancing the performance of large language models (LLMs) in domain-specific\n",
      "tasks such as question-answering (QA). By retrieving relevant information from\n",
      "external sources beyond the training set, RAG enables LLMs to answer specialized\n",
      "1\n",
      "arXiv:2502.11228v2  [cs.CL]  22 May 2025\n",
      "Retrieval\n",
      "Query\n",
      "Answer\n",
      "LLM Judge \n",
      "Quality Check\n",
      "Rewritten  \n",
      "Query\n",
      "Final \n",
      "Answer\n",
      "Vendi Score\n",
      "Vendi Score\n",
      "Diversity  \n",
      "weight s\n",
      "Decision Block \n",
      "s > threshold Thr \n",
      "Iteration < N\n",
      "â€¦\n",
      "Reasoning\n",
      "Figure 1: The process begins with an initial retrieval step, where a diverse set of\n",
      "documents is retrieved using the Vendi Score, ensuring broad semantic coverage.\n",
      "Next, leveraging a reasoning step to construct a coherent path to the final answer,\n",
      "the LLM generates an answer, which then undergoes quality assessment by an LLM\n",
      "judge. Based on the answer quality, the retriever is adjusted to balance diversity and\n",
      "relevance: high-quality answers limit the emphasis on diversity, while low-quality\n",
      "answers prompt the retriever to prioritize diversity more heavily. This adjustment\n",
      "is controlled by an adaptive parameter, s, which is updated over iterations. The\n",
      "process continues until the answer quality reaches an optimal threshold, denoted\n",
      "by Thr. Finally, the highest-quality responses and documents are selected, ensuring\n",
      "both diversity and accuracy.\n",
      "queries more effectively Achiam et al. (2023); Team et al. (2023); Jiang et al. (2024).\n",
      "This approach has been particularly successful in single-hop QA, where a question\n",
      "can be answered using information from a single document Raiaan et al. (2024);\n",
      "Kwiatkowski et al. (2019). For instance, answering a question such as \"Who wrote\n",
      "the novel Frankenstein?\" only requires retrieving relevant information from a single\n",
      "document containing this fact.\n",
      "However, multi-hop QA introduces significantly greater complexit\n",
      "</Content>\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document source=\"http://arxiv.org/abs/2410.12812v1\" date=\"2024-10-01\" authors=\"Sarah Packowski, Inge Halilovic, Jenifer Schlotfeldt, Trish Smith\"/>\n",
      "<Title>\n",
      "Optimizing and Evaluating Enterprise Retrieval-Augmented Generation (RAG): A Content Design Perspective\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented generation (RAG) is a popular technique for using large\n",
      "language models (LLMs) to build customer-support, question-answering solutions.\n",
      "In this paper, we share our team's practical experience building and\n",
      "maintaining enterprise-scale RAG solutions that answer users' questions about\n",
      "our software based on product documentation. Our experience has not always\n",
      "matched the most common patterns in the RAG literature. This paper focuses on\n",
      "solution strategies that are modular and model-agnostic. For example, our\n",
      "experience over the past few years - using different search methods and LLMs,\n",
      "and many knowledge base collections - has been that simple changes to the way\n",
      "we create knowledge base content can have a huge impact on our RAG solutions'\n",
      "success. In this paper, we also discuss how we monitor and evaluate results.\n",
      "Common RAG benchmark evaluation techniques have not been useful for evaluating\n",
      "responses to novel user questions, so we have found a flexible, \"human in the\n",
      "lead\" approach is required.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "Optimizing and Evaluating Enterprise Retrieval-Augmented\n",
      "Generation (RAG): A Content Design Perspective\n",
      "Sarah Packowski\n",
      "spackows@ca.ibm.com\n",
      "IBM\n",
      "Canada\n",
      "Inge Halilovic\n",
      "ingeh@us.ibm.com\n",
      "IBM\n",
      "United States\n",
      "Jenifer Schlotfeldt\n",
      "jschlot@us.ibm.com\n",
      "IBM\n",
      "United States\n",
      "Trish Smith\n",
      "smith@ca.ibm.com\n",
      "IBM\n",
      "Canada\n",
      "ABSTRACT\n",
      "Retrieval-augmented generation (RAG) is a popular technique for\n",
      "using large language models (LLMs) to build customer-support,\n",
      "question-answering solutions. In this paper, we share our teamâ€™s\n",
      "practical experience building and maintaining enterprise-scale RAG\n",
      "solutions that answer usersâ€™ questions about our software based on\n",
      "product documentation. Our experience has not always matched\n",
      "the most common patterns in the RAG literature. This paper focuses\n",
      "on solution strategies that are modular and model-agnostic. For\n",
      "example, our experience over the past few years - using different\n",
      "search methods and LLMs, and many knowledge base collections -\n",
      "has been that simple changes to the way we create knowledge base\n",
      "content can have a huge impact on our RAG solutionsâ€™ success. In\n",
      "this paper, we also discuss how we monitor and evaluate results.\n",
      "Common RAG benchmark evaluation techniques have not been\n",
      "useful for evaluating responses to novel user questions, so we have\n",
      "found a flexible, \"human in the lead\" approach is required.\n",
      "CCS CONCEPTS\n",
      "â€¢ Computing methodologies â†’Artificial intelligence; Natu-\n",
      "ral language generation; â€¢ Applied computing â†’Document\n",
      "management and text processing.\n",
      "KEYWORDS\n",
      "Retrieval-augmented generation, RAG, Large language models\n",
      "ACM Reference Format:\n",
      "Sarah Packowski, Inge Halilovic, Jenifer Schlotfeldt, and Trish Smith. 2024.\n",
      "Optimizing and Evaluating Enterprise Retrieval-Augmented Generation\n",
      "(RAG): A Content Design Perspective. In Proceedings of 8th International\n",
      "Conference on Advances in Artificial Intelligence (ICAAI â€™24). ACM, New York,\n",
      "NY, USA, 6 pages.\n",
      "Permission to make digital or hard copies of part or all of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for third-party components of this work must be honored.\n",
      "For all other uses, contact the owner/author(s).\n",
      "ICAAI â€™24, October 2024, London, UK\n",
      "Â© 2024 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1801-4/24/10.\n",
      "1\n",
      "INTRODUCTION\n",
      "Retrieval-augmented generation (RAG) is an effective way to use\n",
      "large language models (LLMs) to answer questions while avoiding\n",
      "hallucinations and factual inaccuracy[12, 20, 46]. Basic RAG is sim-\n",
      "ple: 1) search a knowledge base for relevant content; 2) compose a\n",
      "prompt grounded in the retrieved content; and 3) prompt an LLM to\n",
      "generate output. For the retrieval step, one approach dominates the\n",
      "literature: 1) segment content text into chunks; 2) index vectorized\n",
      "chunks for search in a vector database; and 3) when generating\n",
      "answers, ground prompts in a subset of retrieved chunks[13]. Our\n",
      "RAG solutions donâ€™t always use vector databases for search.\n",
      "Wikipedia has long been influenced by and had an influence on\n",
      "scientific research [21, 41]. With respect to RAG, Wikipedia is a dom-\n",
      "inant source of knowledge base content for training data and bench-\n",
      "marks, including: 2WikiMultiHopQA, AmbigQA, ASQA, DART,\n",
      "FEVER, HotpotQA, KILT, MuSiQue, Natural Questions, NoMIRACL,\n",
      "PopQA, SQuAD, StrategyQA, SuperGLUE, TriviaQA, WikiAsp, Wik-\n",
      "iBio, WikiEval, and Wizard of Wikipedia[8, 9, 14â€“16, 18, 22, 23, 25,\n",
      "28, 29, 31, 34, 39, 40, 42â€“44, 48]. The knowledge base for our teamâ€™s\n",
      "RAG solutions is our own product documentation, which is struc-\n",
      "tured differently from Wikipedia articles.\n",
      "Using common benchmarks to test your RAG implementation\n",
      "involves these steps: 1) index the given knowledge base content in\n",
      "your retriever component; 2) prompt your solution to answer the\n",
      "given questions; and 3) compare generated answers to expected\n",
      "answers, using methods such as exact match, cos\n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
      "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. By adopting a modular architecture, this approach addresses the limitations of Naive RAG, offering enhanced flexibility, scalability, and efficiency. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. * *Seamless Integration*: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.ibm.com/think/topics/rag-techniques\"/>\n",
      "While naive RAG is straightforward and quick, modular RAGâ€”often built with frameworks such as LangChainâ€”provides enhanced flexibility, scalability and\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag\"/>\n",
      "By modularizing each step, Modular RAG provides greater control, improved accuracy, and better adaptability, making it ideal for more complex AI\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document href=\"https://www.ibm.com/think/topics/rag-techniques\"/>\n",
      "Pros and cons of RAG techniques ... While naive RAG is straightforward and quick, modular RAGâ€”often built with frameworks such as LangChainâ€”provides enhanced\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\"/>\n",
      "Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. By adopting a modular architecture, this approach addresses the limitations of Naive RAG, offering enhanced flexibility, scalability, and efficiency. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. * *Seamless Integration*: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e\"/>\n",
      "RAG applications must efficiently retrieve relevant documents from the data source. **Chunk Optimization** â€” when using external data sources / documents to build RAG pipeline, the initial step is break them down into smaller chunks to extract fine- grained features. After retrieving the context data (chunks) from a vector database, the next step is to merge the context with a query as an input into LLM. **Memory Module** â€” adding memory component into RAG system where LLM can refer not only to the chunks retrieved from the vector database but also to the previous queries and answers that are stored in the systems memory. ### Build intelligent RAG systems that know when to retrieve documents, search the web, or generate responses directly\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manswer_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: expert\n",
      "\n",
      "Certainly. Modular RAG departs markedly from Naive RAG in several architectural aspects:\n",
      "\n",
      "**1. Architectural Design:**  \n",
      "Naive RAG is typically a monolithic, linear pipeline consisting of three primary stagesâ€”indexing, retrieval (often by simple query-document similarity), and generation. All retrieved content is usually passed en bloc to the LLM, making the process relatively static and inflexible [2][3][4].  \n",
      "Modular RAG, as the name implies, segments the entire RAG workflow into independent modules and operatorsâ€”these include advanced retrievers, routers, schedulers, fusion/aggregation units, chunk optimizers, and memory modules. This enables the assembly of complex workflows using modules that can be independently swapped, configured, or extended, supporting highly dynamic query processing [2][3][4].\n",
      "\n",
      "**2. Patterns That Define Modular RAG:**  \n",
      "Unlike the strictly serial \"retrieve-then-generate\" process of Naive RAG, Modular RAG enables multiple high-level workflow patterns [2]:  \n",
      "- *Linear*: Classic sequential pipeline.  \n",
      "- *Conditional*: Modules activate only under certain criteria (e.g., confidence thresholds or answer types).  \n",
      "- *Branching*: Multiple parallel retrievers or workflows run in tandem, and their outputs are fused.  \n",
      "- *Looping*: The system iteratively retrieves and refines, for instance when a reasoning module requests more information or rewrites the query [2][5].  \n",
      "Additionally, modular RAG supports the inclusion of memory, so reasoning can depend on previous queries and outcomesâ€”a pattern that is difficult or impossible to realize in Naive architectures [3][4].\n",
      "\n",
      "**3. Production-Level Benefits:**  \n",
      "- *Flexibility and Maintainability*: The \"LEGO-like\" structure means new functions or optimizations can be introduced without re-architecting the system [2].  \n",
      "- *Scalability*: Individual modules can be independently optimized or scaled to support high-throughput or domain-specific tasks [2][3].  \n",
      "- *Improved Output Quality*: Through operators like chunk optimization, fusion, and adaptive routing, Modular RAG can reduce retrieval redundancy and noise, improving answer relevance and minimizing hallucinations [2][3][4].  \n",
      "- *Rapid Domain Adaptation*: The plugin-like nature enables easier integration with new knowledge sources or adaptation to new types of queries [2][3][4].  \n",
      "- *Dynamic Workflows*: Modular RAG empowers workflows that adapt depending on the task, query semantics, or intermediate LLM feedbackâ€”something infeasible for monolithic Naive RAG [2][4].  \n",
      "\n",
      "**References**  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[4] https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e  \n",
      "[5] http://arxiv.org/abs/2508.11246v1\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msave_interview\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32minterview\u001b[0m:\n",
      "Human: So you said you were writing an article on Explain how Modular RAG differs from traditional Naive RAG and the benefits of using it at the production level.?\n",
      "AI: Hello Professor Hinton, my name is Dr. Evelyn Chan, and Iâ€™m an AI systems analyst working on synthesizing recent advances in retrieval-augmented generation (RAG). Thank you so much for taking the time.\n",
      "\n",
      "To start, could you explain, in concrete terms, how the architectural design of Modular RAG differs from the more traditional â€œnaiveâ€ RAG frameworks? Are there particular modules or patterns that define the modular approach?\n",
      "AI: Certainly. Modular RAG fundamentally differs from traditional Naive RAG in both architecture and workflow, especially as applied in production environments:\n",
      "\n",
      "**1. Architectural Design**\n",
      "\n",
      "- **Naive RAG** operates as a relatively monolithic pipeline: it retrieves relevant documents from a knowledge base (typically via simple semantic similarity), passes them en masse to a large language model (LLM) for generation, and outputs the response. This process is static and linearâ€”often summarized as â€œretrieve-then-generate.â€ Thereâ€™s little room for intervention, orchestration, or dynamic control [2][4].\n",
      "- **Modular RAG**, in contrast, decomposes the RAG pipeline into distinct, interchangeable modules and specialized operators. Typical modules might include sophisticated retrievers, routing mechanisms, schedulers, fusion modules (for merging retrieved data), and even memory components for handling previous queries and answers. This design enables complex RAG patternsâ€”such as conditional, branching, and iterative processingâ€”rather than just linear flows [2][4].\n",
      "\n",
      "**2. Patterns and Processes**\n",
      "\n",
      "- Modular RAG supports a variety of workflows beyond the simple linear sequence of Naive RAG. For instance, it can implement **branching** (where different retrievers are invoked depending on query characteristics), **conditional logic** (dynamic choice of modules based on intermediate results), and **looping** (iterative retrieval and reasoning cycles until a stopping criterion is met) [2].\n",
      "- It also more easily accommodates memory modules, chunk optimization strategies, and seamless switching between retrieval, web search, or pure generative steps, depending on query needs [4].\n",
      "\n",
      "**3. Production-Level Benefits**\n",
      "\n",
      "- **Flexibility**: Operators and modules can be swapped, extended, or fine-tuned independently, allowing rapid adaptation to new tasks or knowledge sources. This â€œLEGO-likeâ€ reconfigurability is ideal for evolving production requirements [2][4].\n",
      "- **Scalability and Efficiency**: Because components are decoupled, resource allocation, parallelization, and distributed deployment are much more straightforward, supporting large-scale applications [2][4].\n",
      "- **Maintainability and Upgradability**: Individual modules can be updated or replaced (e.g., with a better retriever, improved fusion logic) without overhauling the entire system.\n",
      "- **Enhanced Response Quality**: Advanced routing, chunk optimization, and adaptive memory improve both relevance and factual accuracy of outputs, while reducing redundancy and minimizing the risk of hallucination [3][4].\n",
      "- **Intelligent Decision-Making**: Modular RAG can dynamically decide when to retrieve, search external sources, or rely on generation alone, leading to smarter and more context-aware responses [4].\n",
      "\n",
      "**Conclusion:**  \n",
      "While Naive RAG offers a simple and direct route to retrieval-augmented generation, Modular RAGâ€™s fine-grained modularity, orchestration mechanisms, and reconfigurability provide clear advantages for robust, adaptive, and efficient production deployments.\n",
      "\n",
      "**Sources:**  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[4] https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e\n",
      "AI: Thank you, Professor Hinton. That modular orchestration is fascinating. Could you share a concrete production scenario or use case where Modular RAG clearly outperformed a Naive RAG implementation? What did the modular approach enable that simply wasnâ€™t possible before, and perhaps, what measurable benefits did you observe?\n",
      "AI: Certainly. Modular RAG departs markedly from Naive RAG in several architectural aspects:\n",
      "\n",
      "**1. Architectural Design:**  \n",
      "Naive RAG is typically a monolithic, linear pipeline consisting of three primary stagesâ€”indexing, retrieval (often by simple query-document similarity), and generation. All retrieved content is usually passed en bloc to the LLM, making the process relatively static and inflexible [2][3][4].  \n",
      "Modular RAG, as the name implies, segments the entire RAG workflow into independent modules and operatorsâ€”these include advanced retrievers, routers, schedulers, fusion/aggregation units, chunk optimizers, and memory modules. This enables the assembly of complex workflows using modules that can be independently swapped, configured, or extended, supporting highly dynamic query processing [2][3][4].\n",
      "\n",
      "**2. Patterns That Define Modular RAG:**  \n",
      "Unlike the strictly serial \"retrieve-then-generate\" process of Naive RAG, Modular RAG enables multiple high-level workflow patterns [2]:  \n",
      "- *Linear*: Classic sequential pipeline.  \n",
      "- *Conditional*: Modules activate only under certain criteria (e.g., confidence thresholds or answer types).  \n",
      "- *Branching*: Multiple parallel retrievers or workflows run in tandem, and their outputs are fused.  \n",
      "- *Looping*: The system iteratively retrieves and refines, for instance when a reasoning module requests more information or rewrites the query [2][5].  \n",
      "Additionally, modular RAG supports the inclusion of memory, so reasoning can depend on previous queries and outcomesâ€”a pattern that is difficult or impossible to realize in Naive architectures [3][4].\n",
      "\n",
      "**3. Production-Level Benefits:**  \n",
      "- *Flexibility and Maintainability*: The \"LEGO-like\" structure means new functions or optimizations can be introduced without re-architecting the system [2].  \n",
      "- *Scalability*: Individual modules can be independently optimized or scaled to support high-throughput or domain-specific tasks [2][3].  \n",
      "- *Improved Output Quality*: Through operators like chunk optimization, fusion, and adaptive routing, Modular RAG can reduce retrieval redundancy and noise, improving answer relevance and minimizing hallucinations [2][3][4].  \n",
      "- *Rapid Domain Adaptation*: The plugin-like nature enables easier integration with new knowledge sources or adaptation to new types of queries [2][3][4].  \n",
      "- *Dynamic Workflows*: Modular RAG empowers workflows that adapt depending on the task, query semantics, or intermediate LLM feedbackâ€”something infeasible for monolithic Naive RAG [2][4].  \n",
      "\n",
      "**References**  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[4] https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e  \n",
      "[5] http://arxiv.org/abs/2508.11246v1\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manswer_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: expert\n",
      "\n",
      "Absolutely. Modular RAG is designed very differently from traditional (naive) RAG, particularly with an eye toward enterprise and production environments.\n",
      "\n",
      "**In naive RAG**, the architecture is monolithic and linearâ€”thereâ€™s a single retriever and a single generator in a â€œretrieve-then-generateâ€ pipeline. Components are tightly coupled, and all documents retrieved are simply passed straight to the LLM. The system is inflexible and hard to adapt to new requirements or to swap out parts [1][2][3]. \n",
      "\n",
      "**Modular RAG**, by contrast, breaks retrieval and generation into distinct, interchangeable modules. For instance, retrieval, reranking, filtering, and document fusion can each be handled by their own independently developed components. Modular RAG frameworks often support advanced pipeline features like conditional logic, branching, routing, and loopingâ€”enabling more sophisticated flows than the basic â€œsingle retriever â†’ single generatorâ€ naive RAG [4].\n",
      "\n",
      "**At production scale, modularization confers major benefits:**\n",
      "\n",
      "- **Scalability**: Each module can be independently scaled, replaced, or optimized for load, maximizing the throughput and flexibility of the whole system [1][2].\n",
      "- **Maintainability**: With clear separation and interfaces, teams can upgrade, debug, or swap modules (like trying a new retriever or LLM) without costly system rewrites [1][3][4].\n",
      "- **Robustness & Adaptivity**: Modular RAG supports new operators, custom data flows (like routing or looping), and best-of-breed customizationsâ€”vital for supporting changing business needs and preventing system-wide regressions if a piece is modified [4].\n",
      "- **Improved Response Quality**: Because you can filter, rerank, or add domain-specific logic between modules, Modular RAG often delivers more coherent and relevant content and reduces noise/hallucination from irrelevant retrievals [1][4].\n",
      "\n",
      "In short, Modular RAG turns RAG into a flexible, composable frameworkâ€”very much like LEGO blocksâ€”making it well suited for robust, scalable, and maintainable real-world AI systems [4].\n",
      "\n",
      "**Sources:**  \n",
      "[1] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[2] https://www.ibm.com/think/topics/rag-techniques  \n",
      "[3] https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag  \n",
      "[4] http://arxiv.org/abs/2407.21059v1\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msave_interview\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32minterview\u001b[0m:\n",
      "Human: So you said you were writing an article on Explain how Modular RAG differs from traditional Naive RAG and the benefits of using it at the production level.?\n",
      "AI: Hello Dr. Sarin, my name is Alex Chenâ€”I'm a technology journalist with a focus on real-world AI deployments. Thank you for taking the time to talk with me. I want to start by making sure I understand the basics clearly. \n",
      "\n",
      "Could you explain, in concrete terms, what distinguishes Modular RAG (Retrieval-Augmented Generation) from the \"naive\" or traditional RAG architecture that most engineers may be familiar with? \n",
      "\n",
      "Are there any specific modular components or patterns that are central to this distinction?\n",
      "AI: Certainly. Modular RAG distinguishes itself from traditional Naive RAG in several key ways, particularly in terms of architecture and suitability for production-scale deployment.\n",
      "\n",
      "**Naive RAG** operates as a monolithic system: it retrieves relevant documents from a knowledge base and then passes them to a generative model. This process is relatively static and inflexible, which often results in inefficiencies and limits how seamlessly the retrieval and generation components interact. There is little room for customization or replacement of constituent parts without substantial engineering effort. As a result, scaling or adapting the system for evolving requirements can be challenging [1][3].\n",
      "\n",
      "**Modular RAG**, on the other hand, adopts a composable architecture. Here, retrieval and generation are broken into specialized, distinct modules that can be interchanged, upgraded, or adjusted independently. This modular approach allows the generative components to integrate seamlessly with a variety of retrieval modules, greatly enhancing the flexibility, scalability, and relevance of responses [1][2][3].\n",
      "\n",
      "**Key benefits of Modular RAG at the production level include:**\n",
      "\n",
      "- **Flexibility:** Different retrieval or generation modules can be swapped or adapted with minimal disruption, accommodating changing business or technical needs.\n",
      "- **Scalability:** Components can be independently scaled, streamlined, or replaced as usage grows or as new retrieval/generation technologies emerge.\n",
      "- **Maintainability:** Clear module boundaries make it easier for engineering teams to update, debug, or optimize individual parts without impacting the whole system.\n",
      "- **Enhanced Relevance and Coherence:** Seamless integration between retrieval and generation improves the quality and applicability of produced responses [1][3].\n",
      "\n",
      "In summary, Modular RAG enables organizations to build more robust, scalable, and maintainable AI solutions by replacing the rigid, all-in-one nature of Naive RAG with a flexible architecture suitable for real-world, production-scale challenges [1][2][3].\n",
      "\n",
      "**Sources:**  \n",
      "[1] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[2] https://www.ibm.com/think/topics/rag-techniques  \n",
      "[3] https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag\n",
      "AI: Thatâ€™s a great framing. At the highest level, the main difference is that Modular RAG breaks the classic retrieval-then-generate pipeline into a set of loosely coupled, well-defined componentsâ€”whereas naive RAG glues together retrieval and generation in a monolithic, hard-to-change way.\n",
      "\n",
      "Specifically, Modular RAG typically includes:\n",
      "\n",
      "- **Well-defined APIs** between retrieval, re-ranking, and generation\n",
      "- Pluggable modules for each stage (e.g. easy to swap in a different retriever, or add an extra filtering/re-ranking step)\n",
      "- Strong type and data contract enforcement, reducing â€œsilent errorsâ€ in data interchange\n",
      "\n",
      "In contrast, Naive RAG tends to be just: â€œsend query to retriever; hand all retrieved results to an LLM; hope for the best.â€ The naive approach often results in tightly coupled, spaghetti code.\n",
      "\n",
      "A concrete example: in some production settings, we swapped in a semantic filtering module between retrieval and generation, to weed out irrelevant or disallowed content before it ever reaches the LLM. This would be painful with naive RAG, but itâ€™s an afterthought with Modular RAG.\n",
      "\n",
      "Would you like to hear about the production-level benefits that emerged from this modularization? Or perhaps a failure story from naive RAG?\n",
      "AI: Absolutely. Modular RAG is designed very differently from traditional (naive) RAG, particularly with an eye toward enterprise and production environments.\n",
      "\n",
      "**In naive RAG**, the architecture is monolithic and linearâ€”thereâ€™s a single retriever and a single generator in a â€œretrieve-then-generateâ€ pipeline. Components are tightly coupled, and all documents retrieved are simply passed straight to the LLM. The system is inflexible and hard to adapt to new requirements or to swap out parts [1][2][3]. \n",
      "\n",
      "**Modular RAG**, by contrast, breaks retrieval and generation into distinct, interchangeable modules. For instance, retrieval, reranking, filtering, and document fusion can each be handled by their own independently developed components. Modular RAG frameworks often support advanced pipeline features like conditional logic, branching, routing, and loopingâ€”enabling more sophisticated flows than the basic â€œsingle retriever â†’ single generatorâ€ naive RAG [4].\n",
      "\n",
      "**At production scale, modularization confers major benefits:**\n",
      "\n",
      "- **Scalability**: Each module can be independently scaled, replaced, or optimized for load, maximizing the throughput and flexibility of the whole system [1][2].\n",
      "- **Maintainability**: With clear separation and interfaces, teams can upgrade, debug, or swap modules (like trying a new retriever or LLM) without costly system rewrites [1][3][4].\n",
      "- **Robustness & Adaptivity**: Modular RAG supports new operators, custom data flows (like routing or looping), and best-of-breed customizationsâ€”vital for supporting changing business needs and preventing system-wide regressions if a piece is modified [4].\n",
      "- **Improved Response Quality**: Because you can filter, rerank, or add domain-specific logic between modules, Modular RAG often delivers more coherent and relevant content and reduces noise/hallucination from irrelevant retrievals [1][4].\n",
      "\n",
      "In short, Modular RAG turns RAG into a flexible, composable frameworkâ€”very much like LEGO blocksâ€”making it well suited for robust, scalable, and maintainable real-world AI systems [4].\n",
      "\n",
      "**Sources:**  \n",
      "[1] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[2] https://www.ibm.com/think/topics/rag-techniques  \n",
      "[3] https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag  \n",
      "[4] http://arxiv.org/abs/2407.21059v1\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manswer_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: expert\n",
      "\n",
      "Of course, Dr. Alvarez. Hereâ€™s a summary grounded in the supplied sources:\n",
      "\n",
      "**Modular RAG vs. Naive RAG: Core Differences**\n",
      "\n",
      "- **Naive RAG** follows a linear, monolithic flow: it retrieves chunks from a knowledge base based on similarity to the query, and feeds these directly to the LLM for generation. This setup is static, inflexible, and all retrieved content is passed â€œas-isâ€ to the generative model. The system is not easily adaptable to new retrieval or generation advancements, and redundancy or noise in retrieval can degrade output quality [2][4].\n",
      "\n",
      "- **Modular RAG** decomposes the pipeline into independent, interchangeable modulesâ€”such as retrievers, rerankers, generators, routers, and fusion operators. Each module can be plugged, replaced, reconfigured, or extended without disturbing the rest. This enables complex, non-linear patterns: routing, scheduling, branching, and looping. It also allows for more granular control, integration of specialized operators, and integration of advanced components as needs evolve [2][4].\n",
      "\n",
      "**Production-Level Benefits**\n",
      "\n",
      "- **Flexibility and Scalability:** Modular RAG allows easy upgrades or experimental integration of different retrieval, reranking, or generative models in production environments. Teams can adapt to new requirements by adding or substituting specialized modules [2][4].\n",
      "\n",
      "- **Latent Efficient Processing:** Modules such as routers or schedulers can optimize resource usage by triggering compute-intensive segments only when required, thus reducing latency and cost [2][4].\n",
      "\n",
      "- **Improved Retrieval Quality:** Modular RAG enables enhanced query understanding and filtering, reducing redundant/noisy retrieval and improving precision, which in turn lowers hallucination rates [2][4].\n",
      "\n",
      "- **Maintainability and Experimentation:** The â€œLEGO-likeâ€ design supports parallel development and rapid replacement or fine-tuning of underperforming modules, leading to faster iteration cycles in production [2][4].\n",
      "\n",
      "- **Robustness:** Modular architectures more readily scale to multi-domain or complex application settings and allow operators to target domain- or application-specific needs without comprehensive system overhauls [2].\n",
      "\n",
      "In short: Modular RAG moves from a rigid, single-path approach to a reconfigurable framework where each component can be refined independently, supporting rapid, robust, and efficient RAG deployment at scale.\n",
      "\n",
      "---\n",
      "Sources:  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[4] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36msave_interview\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32minterview\u001b[0m:\n",
      "Human: So you said you were writing an article on Explain how Modular RAG differs from traditional Naive RAG and the benefits of using it at the production level.?\n",
      "AI: Hello Dr. Alvarez, thank you for speaking with me today. My name is Jordan Lin, and Iâ€™m an AI systems journalist focused on practical advances in retrieval-augmented generation (RAG).\n",
      "\n",
      "To start: Could you explain, at a technical level, what â€œModular RAGâ€ specifically changes compared to the standard or â€œnaiveâ€ RAG architectures? Are there particular sub-systems or components that are modularized, and how does this affect the stack as a whole?\n",
      "AI: Certainly, Dr. Alvarez. Modular RAG represents a significant evolution over traditional Naive RAG, particularly relevant for production environments. Hereâ€™s a detailed breakdown based strictly on the provided context:\n",
      "\n",
      "**1. Architectural Differences**\n",
      "\n",
      "- **Naive RAG**: Operates on a â€œretrieve-then-generateâ€ pipeline. The system retrieves relevant documents or chunks from an external knowledge base and directly feeds all retrieved content to the generative model. This process is linear and monolithic, meaning components (retriever, generator) are tightly coupled and not easily replaceable or adaptable [2][4].\n",
      "\n",
      "- **Modular RAG**: Decomposes the RAG workflow into independent, interchangeable modulesâ€”think of â€œLEGO-likeâ€ building blocks. Each module (retriever, reranker, generator, router, fusion, scheduler, etc.) can be independently developed, replaced, or optimized. Modular RAG supports non-linear patterns such as conditional logic, branching, and looping, and enables the integration of advanced mechanisms like routing and scheduling within the pipeline [2][4].\n",
      "\n",
      "**2. Key Benefits at the Production Level**\n",
      "\n",
      "- **Flexibility and Adaptivity**: Modular RAG enables seamless integration of different retrieval modules, specialized LLMs, or new operators as needs evolve, without overhauling the whole stack. This is essential for keeping up with fast-changing requirements and model capabilities in production [2][4].\n",
      "\n",
      "- **Scalability**: By having standardized, decoupled modules, systems can more easily scale out individual bottlenecks (e.g., upgrade only the retrieval module) or add domain-specific logic (e.g., a taxonomy-specific router) without affecting the rest of the pipeline [2][4].\n",
      "\n",
      "- **Efficiency and Latency Control**: Modularization allows for targeted optimizationsâ€”such as only scheduling compute-intensive modules conditionallyâ€”thereby reducing system latency and computational costs in production [2][4].\n",
      "\n",
      "- **Maintenance & Experimentation**: With clearly defined interfaces, teams can experiment or fine-tune specific modules (like retrievers or rerankers), swap out underperforming components, or conduct A/B testing systematically. This reduces operational risks and accelerates deployment cycles [4].\n",
      "\n",
      "- **Improved Retrieval Quality**: Naive RAG often suffers from shallow query understanding and retrieval redundancy/noise, leading to hallucinations or irrelevant content in generation. Modular RAG introduces fine-grained control and processing steps (like advanced routing and filtering) that improve precision and minimize the risk of misleading the LLM [2][4].\n",
      "\n",
      "- **Robustness to Complexity**: As production RAG applications grow in complexity (multiple domains, user types, or knowledge sources), modular RAGâ€™s reconfigurable framework is better suited for orchestrating heterogeneous requirements and evolving architectures [2].\n",
      "\n",
      "**Summary**: Modular RAG differs from Naive RAG by breaking up the pipeline into interchangeable, independently managed modules with advanced mechanisms for routing and orchestration. This change results in increased flexibility, scalability, efficiency, and system maintainabilityâ€”crucial factors for robust, high-performance production deployments [2][4].\n",
      "\n",
      "---\n",
      "\n",
      "**Sources**:  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[4] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
      "AI: Thank you, Dr. Alvarez. Thatâ€™s a very clear technical breakdownâ€”especially the points on modularized routing, branching, and decoupling. To make it even more tangible, could you share a specific real-world example or case study from your team where Modular RAG directly unlocked new capabilities, higher retrieval quality, or lower latency than a prior naive RAG system? What did the impact look like quantitatively or qualitatively in practice?\n",
      "AI: Of course, Dr. Alvarez. Hereâ€™s a summary grounded in the supplied sources:\n",
      "\n",
      "**Modular RAG vs. Naive RAG: Core Differences**\n",
      "\n",
      "- **Naive RAG** follows a linear, monolithic flow: it retrieves chunks from a knowledge base based on similarity to the query, and feeds these directly to the LLM for generation. This setup is static, inflexible, and all retrieved content is passed â€œas-isâ€ to the generative model. The system is not easily adaptable to new retrieval or generation advancements, and redundancy or noise in retrieval can degrade output quality [2][4].\n",
      "\n",
      "- **Modular RAG** decomposes the pipeline into independent, interchangeable modulesâ€”such as retrievers, rerankers, generators, routers, and fusion operators. Each module can be plugged, replaced, reconfigured, or extended without disturbing the rest. This enables complex, non-linear patterns: routing, scheduling, branching, and looping. It also allows for more granular control, integration of specialized operators, and integration of advanced components as needs evolve [2][4].\n",
      "\n",
      "**Production-Level Benefits**\n",
      "\n",
      "- **Flexibility and Scalability:** Modular RAG allows easy upgrades or experimental integration of different retrieval, reranking, or generative models in production environments. Teams can adapt to new requirements by adding or substituting specialized modules [2][4].\n",
      "\n",
      "- **Latent Efficient Processing:** Modules such as routers or schedulers can optimize resource usage by triggering compute-intensive segments only when required, thus reducing latency and cost [2][4].\n",
      "\n",
      "- **Improved Retrieval Quality:** Modular RAG enables enhanced query understanding and filtering, reducing redundant/noisy retrieval and improving precision, which in turn lowers hallucination rates [2][4].\n",
      "\n",
      "- **Maintainability and Experimentation:** The â€œLEGO-likeâ€ design supports parallel development and rapid replacement or fine-tuning of underperforming modules, leading to faster iteration cycles in production [2][4].\n",
      "\n",
      "- **Robustness:** Modular architectures more readily scale to multi-domain or complex application settings and allow operators to target domain- or application-specific needs without comprehensive system overhauls [2].\n",
      "\n",
      "In short: Modular RAG moves from a rigid, single-path approach to a reconfigurable framework where each component can be refined independently, supporting rapid, robust, and efficient RAG deployment at scale.\n",
      "\n",
      "---\n",
      "Sources:  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[4] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mwrite_section\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## Modular RAG at Production Scale: Enhancing Scalability, Maintainability, and Robustness in Real-World Systems\n",
      "\n",
      "### Summary\n",
      "\n",
      "The ongoing evolution of Retrieval-Augmented Generation (RAG) systems, which combine large language models (LLMs) with external knowledge retrieval, is fundamentally reshaping enterprise AI workflows. Traditional (naive) RAG architectures introduce valuable capabilities but struggle with static design, inefficiency, and challenges in scaling and adapting to complex or dynamic environments. Modular RAG has emerged as a powerful answer, redefining how RAG systems are structured and deployed at production scale.\n",
      "\n",
      "What is particularly novel from the latest research and technical analysis is the recognition that Modular RAG systemsâ€”through their reconfigurable, component-driven designâ€”offer order-of-magnitude improvements not only in flexibility and adaptability but also in operational resilience, extensibility, and the ability to optimize for domain-specific and real-world needs. Key insights show that:\n",
      "\n",
      "- Modular architectures transform RAG from a linear, monolithic process into a set of interoperable, reusable modules, dramatically improving scalability and maintainability [1][2][3][4].\n",
      "- Fine-grained control over retrieval, filtering, composition, and generation enhances both efficiency and output reliability, while also simplifying experimentation and future upgrades [1][2][3].\n",
      "- Systematic benchmarking (using platforms like OmniBench-RAG) reveals how modularity permits domain-aware tuning of RAG, with striking variation in effectiveness depending on applicationâ€”highlighting the importance of modular evaluation alongside modular construction [5].\n",
      "- In operationally critical settings like aviation, modular RAG enables the selection and combination of specialized retrieval methods to minimize error and support complex, context-rich queries [6].\n",
      "\n",
      "The emergence of Modular RAG represents a convergence of software engineering best practices and advanced AI integration, providing a blueprint for building robust, scalable, and maintainable RAG systems for production deployments.\n",
      "\n",
      "#### Sources:\n",
      "\n",
      "1. https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "2. https://www.ibm.com/think/topics/rag-techniques  \n",
      "3. https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag  \n",
      "4. http://arxiv.org/abs/2407.21059v1  \n",
      "5. http://arxiv.org/abs/2508.05650v1  \n",
      "6. http://arxiv.org/abs/2505.13006v1\n",
      "\n",
      "---\n",
      "\n",
      "### Comprehensive Analysis\n",
      "\n",
      "#### 1. From Naive RAG to Modular RAG: Architectural Shift\n",
      "\n",
      "##### a. Limitations of Naive RAG\n",
      "Naive RAG adopts a linear \"retrieve-then-generate\" pattern [1][4]. It typically performs the following steps:\n",
      "- Embed a user query.\n",
      "- Search a static knowledge base for similar chunks.\n",
      "- Feed selected chunks to the generative LLM, Ã  la retrieval-augmented prompting.\n",
      "\n",
      "However, this approach is plagued by:\n",
      "- **Ineffective Retrieval:** Simple similarity metrics often fail with ambiguous or context-rich queries, leading to suboptimal selection [1][4].\n",
      "- **Retrieval Redundancy and Noise:** All retrieved chunks, regardless of quality or relevance, are passed to the LLM, which can cause hallucination and degraded response quality [4].\n",
      "- **Poor Adaptability:** Extending the method to new domains, data sources, or evaluation routines requires significant rework due to its monolithic structure [1][2][4].\n",
      "\n",
      "These drawbacks limit naive RAG's scalability, maintainability, and ability to evolve with new requirements.\n",
      "\n",
      "##### b. Modular RAG: Design Principles and Benefits\n",
      "\n",
      "**Modular RAG** addresses these issues by decomposing the RAG pipeline into discrete, interoperable modules [1][2][3][4]:\n",
      "- **Flexible Composability:** Developers can plug and play independent retrieval, pre-processing, filtering, generation, and post-processing components, akin to a LEGO-like system [4].\n",
      "- **Specialization:** Each module can be designed for a specific functionâ€”e.g., semantic reranking, fusion of multiple retrieval results, or advanced schedulingâ€”allowing for optimal algorithmic choices per application [1][4].\n",
      "- **Easier Maintenance:** Updates to one module (e.g., swapping out a retriever for a new one) can be done without breaking the end-to-end chain, greatly simplifying upgrades, bug fixes, and lifecycle management [1][2][4].\n",
      "- **Increased Scalability:** Modular designs support horizontal scaling and distributed processing, enabling rapid adaptation to production workloads [2][4].\n",
      "- **Operational Robustness:** Built-in redundancy and error handling can be handled per module, improving failure isolation and recovery.\n",
      "\n",
      "#### 2. Real-World Deployment: Scalability, Maintainability, and Robustness\n",
      "\n",
      "##### a. Scalability: Managing Complexity and Growth\n",
      "\n",
      "- **Dynamic Routing and Scheduling:** Modules can layer complex logic, supporting conditional paths (e.g., try retrieval A, fallback to B if confidence is low) or parallel processing [4].\n",
      "- **Resource Optimization:** Modular RAG supports dynamic scaling, where resource-intensive generation can be distributed or throttled at the module level, enabling cost-effective deployment in cloud or hybrid environments [4].\n",
      "- **Evaluation at Scale:** Tools like OmniBench-RAG [5] allow modular assessment across multiple knowledge domains and LLM types, revealing that optimized modular pipelines can deliver domain-specific performance improvements and responsible scaling.\n",
      "\n",
      "##### b. Maintainability: Lifecyle, Adaptation, and Upgrades\n",
      "\n",
      "- **Version Control:** Each module can be versioned and independently improved; e.g., updating the document embedder without affecting the generator [1][3][4].\n",
      "- **Rapid Iteration:** Experimentation with retrieval algorithms, filtering heuristics, or generation methods is easierâ€”critical for adapting to evolving data or shifting user demands [3].\n",
      "- **Automated Evaluation:** Modular pipelines integrate with automated testing frameworks, aiding regression testing, monitoring, and quality assurance [5].\n",
      "\n",
      "##### c. System Robustness: Error Handling and Domain Adaptation\n",
      "\n",
      "- **Composability for Domain Fit:** In mission-critical domains such as aviation, modular RAG permits deploying advanced retrieval typesâ€”like SQL or Knowledge Graph-based retrievers for structured data or specialized jargonâ€”reducing hallucination risk and improving context handling [6].\n",
      "  - Example: In airport deployments, a Graph RAG module outperformed standard RAG in reasoning-heavy tasks, showcasing how modularity supports complex needs [6].\n",
      "- **Isolating Errors and Enhancing Reliability:** Each module can validate its outputs and reject or correct errors before passing data downstream, significantly reducing the risk of critical failures propagating through the system [4][6].\n",
      "- **Extensibility:** New module types, such as advanced operators for routing or fusion, can be introduced as requirements evolveâ€”positioning modular RAG for long-term relevance [4].\n",
      "\n",
      "#### 3. Evaluation and Benchmarking: Measuring Modular RAGâ€™s Value\n",
      "\n",
      "- **OmniBench-RAG Platform [5]:** Provides automated, reproducible benchmarking across nine knowledge domains, supporting both overall accuracy (\"Improvements\") and efficiency (\"Transformation\") metrics.\n",
      "  - Results show wide variation in performance by domainâ€”RAG provides significant improvement in culture, but less so in mathematicsâ€”underscoring the importance of domain-sensitive, modular evaluation.\n",
      "  - This evaluation methodology complements modular system design, making it possible to tune and document the impact of each module or configuration on end-to-end outcomes.\n",
      "- **Need for Reproducibility:** Modular frameworks allow for deterministic evaluation routines, critical for audits, upgrades, and fair comparison across deployments [5].\n",
      "\n",
      "#### 4. Strategic and Theoretical Implications\n",
      "\n",
      "- **Framework for Future Innovation:** Modular RAG establishes a blueprint for continuous improvementâ€”a platform where new retrieval and generation paradigms can be phased in without wholesale system redesign [4].\n",
      "- **Operational Excellence:** Enterprises gain operational agility, reduced maintenance overhead, and better control over error rates and data governance.\n",
      "- **Theoretical Rigor:** Current modular RAG research is formalizing common system patternsâ€”linear, conditional, branching, loopingâ€”and their implementation nuances [4], providing a comprehensive roadmap for robust, future-proof AI system engineering.\n",
      "\n",
      "---\n",
      "\n",
      "### Sources\n",
      "\n",
      "[1] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[2] https://www.ibm.com/think/topics/rag-techniques  \n",
      "[3] https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag  \n",
      "[4] http://arxiv.org/abs/2407.21059v1  \n",
      "[5] http://arxiv.org/abs/2508.05650v1  \n",
      "[6] http://arxiv.org/abs/2505.13006v1  \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mconduct_interview\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## Modular RAG at Production Scale: Enhancing Scalability, Maintainability, and Robustness in Real-World Systems\n",
      "\n",
      "### Summary\n",
      "\n",
      "The ongoing evolution of Retrieval-Augmented Generation (RAG) systems, which combine large language models (LLMs) with external knowledge retrieval, is fundamentally reshaping enterprise AI workflows. Traditional (naive) RAG architectures introduce valuable capabilities but struggle with static design, inefficiency, and challenges in scaling and adapting to complex or dynamic environments. Modular RAG has emerged as a powerful answer, redefining how RAG systems are structured and deployed at production scale.\n",
      "\n",
      "What is particularly novel from the latest research and technical analysis is the recognition that Modular RAG systemsâ€”through their reconfigurable, component-driven designâ€”offer order-of-magnitude improvements not only in flexibility and adaptability but also in operational resilience, extensibility, and the ability to optimize for domain-specific and real-world needs. Key insights show that:\n",
      "\n",
      "- Modular architectures transform RAG from a linear, monolithic process into a set of interoperable, reusable modules, dramatically improving scalability and maintainability [1][2][3][4].\n",
      "- Fine-grained control over retrieval, filtering, composition, and generation enhances both efficiency and output reliability, while also simplifying experimentation and future upgrades [1][2][3].\n",
      "- Systematic benchmarking (using platforms like OmniBench-RAG) reveals how modularity permits domain-aware tuning of RAG, with striking variation in effectiveness depending on applicationâ€”highlighting the importance of modular evaluation alongside modular construction [5].\n",
      "- In operationally critical settings like aviation, modular RAG enables the selection and combination of specialized retrieval methods to minimize error and support complex, context-rich queries [6].\n",
      "\n",
      "The emergence of Modular RAG represents a convergence of software engineering best practices and advanced AI integration, providing a blueprint for building robust, scalable, and maintainable RAG systems for production deployments.\n",
      "\n",
      "#### Sources:\n",
      "\n",
      "1. https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "2. https://www.ibm.com/think/topics/rag-techniques  \n",
      "3. https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag  \n",
      "4. http://arxiv.org/abs/2407.21059v1  \n",
      "5. http://arxiv.org/abs/2508.05650v1  \n",
      "6. http://arxiv.org/abs/2505.13006v1\n",
      "\n",
      "---\n",
      "\n",
      "### Comprehensive Analysis\n",
      "\n",
      "#### 1. From Naive RAG to Modular RAG: Architectural Shift\n",
      "\n",
      "##### a. Limitations of Naive RAG\n",
      "Naive RAG adopts a linear \"retrieve-then-generate\" pattern [1][4]. It typically performs the following steps:\n",
      "- Embed a user query.\n",
      "- Search a static knowledge base for similar chunks.\n",
      "- Feed selected chunks to the generative LLM, Ã  la retrieval-augmented prompting.\n",
      "\n",
      "However, this approach is plagued by:\n",
      "- **Ineffective Retrieval:** Simple similarity metrics often fail with ambiguous or context-rich queries, leading to suboptimal selection [1][4].\n",
      "- **Retrieval Redundancy and Noise:** All retrieved chunks, regardless of quality or relevance, are passed to the LLM, which can cause hallucination and degraded response quality [4].\n",
      "- **Poor Adaptability:** Extending the method to new domains, data sources, or evaluation routines requires significant rework due to its monolithic structure [1][2][4].\n",
      "\n",
      "These drawbacks limit naive RAG's scalability, maintainability, and ability to evolve with new requirements.\n",
      "\n",
      "##### b. Modular RAG: Design Principles and Benefits\n",
      "\n",
      "**Modular RAG** addresses these issues by decomposing the RAG pipeline into discrete, interoperable modules [1][2][3][4]:\n",
      "- **Flexible Composability:** Developers can plug and play independent retrieval, pre-processing, filtering, generation, and post-processing components, akin to a LEGO-like system [4].\n",
      "- **Specialization:** Each module can be designed for a specific functionâ€”e.g., semantic reranking, fusion of multiple retrieval results, or advanced schedulingâ€”allowing for optimal algorithmic choices per application [1][4].\n",
      "- **Easier Maintenance:** Updates to one module (e.g., swapping out a retriever for a new one) can be done without breaking the end-to-end chain, greatly simplifying upgrades, bug fixes, and lifecycle management [1][2][4].\n",
      "- **Increased Scalability:** Modular designs support horizontal scaling and distributed processing, enabling rapid adaptation to production workloads [2][4].\n",
      "- **Operational Robustness:** Built-in redundancy and error handling can be handled per module, improving failure isolation and recovery.\n",
      "\n",
      "#### 2. Real-World Deployment: Scalability, Maintainability, and Robustness\n",
      "\n",
      "##### a. Scalability: Managing Complexity and Growth\n",
      "\n",
      "- **Dynamic Routing and Scheduling:** Modules can layer complex logic, supporting conditional paths (e.g., try retrieval A, fallback to B if confidence is low) or parallel processing [4].\n",
      "- **Resource Optimization:** Modular RAG supports dynamic scaling, where resource-intensive generation can be distributed or throttled at the module level, enabling cost-effective deployment in cloud or hybrid environments [4].\n",
      "- **Evaluation at Scale:** Tools like OmniBench-RAG [5] allow modular assessment across multiple knowledge domains and LLM types, revealing that optimized modular pipelines can deliver domain-specific performance improvements and responsible scaling.\n",
      "\n",
      "##### b. Maintainability: Lifecyle, Adaptation, and Upgrades\n",
      "\n",
      "- **Version Control:** Each module can be versioned and independently improved; e.g., updating the document embedder without affecting the generator [1][3][4].\n",
      "- **Rapid Iteration:** Experimentation with retrieval algorithms, filtering heuristics, or generation methods is easierâ€”critical for adapting to evolving data or shifting user demands [3].\n",
      "- **Automated Evaluation:** Modular pipelines integrate with automated testing frameworks, aiding regression testing, monitoring, and quality assurance [5].\n",
      "\n",
      "##### c. System Robustness: Error Handling and Domain Adaptation\n",
      "\n",
      "- **Composability for Domain Fit:** In mission-critical domains such as aviation, modular RAG permits deploying advanced retrieval typesâ€”like SQL or Knowledge Graph-based retrievers for structured data or specialized jargonâ€”reducing hallucination risk and improving context handling [6].\n",
      "  - Example: In airport deployments, a Graph RAG module outperformed standard RAG in reasoning-heavy tasks, showcasing how modularity supports complex needs [6].\n",
      "- **Isolating Errors and Enhancing Reliability:** Each module can validate its outputs and reject or correct errors before passing data downstream, significantly reducing the risk of critical failures propagating through the system [4][6].\n",
      "- **Extensibility:** New module types, such as advanced operators for routing or fusion, can be introduced as requirements evolveâ€”positioning modular RAG for long-term relevance [4].\n",
      "\n",
      "#### 3. Evaluation and Benchmarking: Measuring Modular RAGâ€™s Value\n",
      "\n",
      "- **OmniBench-RAG Platform [5]:** Provides automated, reproducible benchmarking across nine knowledge domains, supporting both overall accuracy (\"Improvements\") and efficiency (\"Transformation\") metrics.\n",
      "  - Results show wide variation in performance by domainâ€”RAG provides significant improvement in culture, but less so in mathematicsâ€”underscoring the importance of domain-sensitive, modular evaluation.\n",
      "  - This evaluation methodology complements modular system design, making it possible to tune and document the impact of each module or configuration on end-to-end outcomes.\n",
      "- **Need for Reproducibility:** Modular frameworks allow for deterministic evaluation routines, critical for audits, upgrades, and fair comparison across deployments [5].\n",
      "\n",
      "#### 4. Strategic and Theoretical Implications\n",
      "\n",
      "- **Framework for Future Innovation:** Modular RAG establishes a blueprint for continuous improvementâ€”a platform where new retrieval and generation paradigms can be phased in without wholesale system redesign [4].\n",
      "- **Operational Excellence:** Enterprises gain operational agility, reduced maintenance overhead, and better control over error rates and data governance.\n",
      "- **Theoretical Rigor:** Current modular RAG research is formalizing common system patternsâ€”linear, conditional, branching, loopingâ€”and their implementation nuances [4], providing a comprehensive roadmap for robust, future-proof AI system engineering.\n",
      "\n",
      "---\n",
      "\n",
      "### Sources\n",
      "\n",
      "[1] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[2] https://www.ibm.com/think/topics/rag-techniques  \n",
      "[3] https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag  \n",
      "[4] http://arxiv.org/abs/2407.21059v1  \n",
      "[5] http://arxiv.org/abs/2508.05650v1  \n",
      "[6] http://arxiv.org/abs/2505.13006v1  \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mwrite_section\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## Architectural Innovations from Naive RAG to Modular RAG: A Comprehensive Analysis in the Era of Deep Learning\n",
      "\n",
      "### Summary\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) has become a pivotal strategy for enhancing Large Language Models (LLMs), especially for knowledge-intensive applications such as advanced question answering, enterprise support systems, and domain-specific assistants. Initially, Naive RAG architectures offered a simple pipeline: retrieve relevant documents and feed them to an LLM for response generation. While this paradigm was quick to implement and effective for basic needs, it introduced substantial limitations regarding scalability, flexibility, and the capability to handle complex reasoning tasks, often resulting in redundancy, brittleness, and sub-optimal performance.\n",
      "\n",
      "Over the past year, dramatic conceptual and engineering advances have emerged, culminating in the evolution toward Modular RAG architectures. Modular RAG decomposes the monolithic RAG workflow into interchangeable, LEGO-like componentsâ€”retrievers, selectors, memory modules, routing, scheduling, and fusion mechanisms. This reconfigurable framework not only addresses the shortcomings of the Naive RAG but also propels the development of specialized operators for handling complex, multi-modal, and evidence-intensive use cases. In geosciences, for instance, RAG systems have been extended to support multi-step â€œretrieve â†’ reason â†’ generate â†’ verifyâ€ pipelines for tasks demanding scientific rigor and the integration of heterogeneous data sources [1][2][3][4][5][6][7][8][9].\n",
      "\n",
      "Novel systems like Vendi-RAG further exemplify the sophistication of modern RAG by iteratively balancing diversity and quality in retrieval, leveraging adaptive metrics such as the Vendi Score and LLM-based answer quality judges. Evaluation frameworks such as OmniBench-RAG emphasize the critical need for reproducibility and domain-sensitive assessment, highlighting variability in RAG system effectiveness across fields and model architectures.\n",
      "\n",
      "Major takeaways for deep learning practitioners include:\n",
      "1. The shift from static retrieval pipelines to dynamically adaptive, modular architectures enables more robust, explainable, and efficient AI solutions.\n",
      "2. The fusion of retrieval, reasoning, and verificationâ€”and the ability to swap in/out architectural modulesâ€”directly enhances the generality, scalability, and trustworthiness of LLM-powered systems.\n",
      "3. The need for new evaluation methodologies and domain-specific optimizations becomes pronounced as RAG moves into more demanding industrial and scientific applications.\n",
      "\n",
      "Sources:\n",
      "1. [Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs (arXiv:2502.11228v2)](http://arxiv.org/abs/2502.11228v2)  \n",
      "2. [Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks (arXiv:2407.21059v1)](http://arxiv.org/abs/2407.21059v1)  \n",
      "3. [OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools (arXiv:2508.05650v1)](http://arxiv.org/abs/2508.05650v1)  \n",
      "4. [RAG for Geoscience: What We Expect, Gaps and Opportunities (arXiv:2508.11246v1)](http://arxiv.org/abs/2508.11246v1)  \n",
      "5. [Optimizing and Evaluating Enterprise RAG: A Content Design Perspective (arXiv:2410.12812v1)](http://arxiv.org/abs/2410.12812v1)  \n",
      "6. [How does modular RAG improve upon naive RAG? (adasci.org)](https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/)  \n",
      "7. [IBM Think â€“ RAG Techniques](https://www.ibm.com/think/topics/rag-techniques)  \n",
      "8. [Medium â€“ What are Naive RAG, Advanced RAG, Modular RAG Paradigms?](https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e)  \n",
      "9. [Opus Intelligence â€“ The One About RAG](https://opusintelligence.com/white-papers/the-one-about-rag)  \n",
      "\n",
      "### Comprehensive Analysis\n",
      "\n",
      "#### Background: From Naive RAG to Modular RAG\n",
      "\n",
      "**Naive RAG:**  \n",
      "The first generation of RAG systems adhered to a rigid, sequential pipeline: chunk documents, index them via vector databases, retrieve the top-K based on simple similarity, and pass these as context to an LLM. This â€œretrieve-then-generateâ€ model was efficient for single-hop and factoid tasks but was increasingly found wanting as tasks grew more complex and users demanded more control, explainability, and domain sensitivity [2][6]. Primary limitations of Naive RAG included:\n",
      "- **Shallow Query Understanding:** Simple similarity cannot robustly capture nuanced domain relationships.\n",
      "- **Retrieval Redundancy:** Excess retrieval often led to noisy inputs and LLM confusion, increasing hallucination risk.\n",
      "- **Static Process:** The pipeline lacked flexibilityâ€”there were few opportunities for iterative refinement or adaptive strategy selection [2][6][8].\n",
      "\n",
      "#### Modular RAG: Architectural Flexibility and Specialization\n",
      "\n",
      "**Key Innovations:**\n",
      "- **Decomposition into Modules:**  \n",
      "  Modular RAG divides the RAG workflow into independent, specialized modules (retriever, generator, selector, router, scheduler, memory, evaluator, etc.), allowing developers to design bespoke data flows and replace components as new techniques emerge [2][6][7].\n",
      "  \n",
      "- **Routing, Scheduling, and Fusion:**  \n",
      "  Advanced modular systems introduce operators for conditional routing (different branches for entity-based queries vs. extractive QA), fusion (aggregating multiple retrieved sources), and scheduling (orchestrating the timing and parallelism of retrieval/generation cycles).\n",
      "\n",
      "- **Support for Multiple Patterns:**  \n",
      "  Modular RAG explicitly supports architectures beyond linear pipelines:  \n",
      "  - **Linear:** Standard retrieve-generate.\n",
      "  - **Conditional:** Branches based on query type or data modality.\n",
      "  - **Branching/Looping:** Iterative approaches for multi-hop reasoning or evidence accumulation [2].\n",
      "\n",
      "**Benefits:**\n",
      "- **Flexibility:** Different models or retrievers can be plugged in for different deployment requirements or data modalities.\n",
      "- **Scalability:** Systems are designed to adapt as data grows or as requirements changeâ€”modules can be scaled independently.\n",
      "- **Robustness and Explainability:** Modular design allows targeted evaluation and improvement of weak links in the pipeline, aiding troubleshooting and compliance (e.g., tracking which retrieved documents led to an answer).\n",
      "\n",
      "#### Advanced Retrieval and Reasoning\n",
      "\n",
      "**Iterative, Feedback-Driven Retrieval:**  \n",
      "State-of-the-art frameworks like Vendi-RAG exemplify the dynamic interplay of diversity and quality in retrieval:\n",
      "- **Vendi Score:** A flexible, similarity-based diversity metric ensures that retrieved contexts are semantically diverse, mitigating redundancy [1].\n",
      "- **LLM Judge:** An LLM-driven evaluator scores the quality of generated answers. The retrieval module uses this feedback to reweight its tradeoff between relevance and diversity, iteratively improving both answer accuracy and retrieval breadth.\n",
      "- **Multi-Hop Reasoning:** Vendi-RAGâ€™s dynamic adjustment of retrieval strategy is particularly potent in multi-hop QA, where answers require the synthesis of information from multiple sources, as shown in their reported accuracy gains (+4.2% on HotpotQA, for example) compared to even the strongest existing baselines [1].\n",
      "\n",
      "**Practical Modules:**\n",
      "- **Chunk Optimization:** Modular RAG systems support fine-grained chunking strategies, optimizing for information density and contextual relevance [8].\n",
      "- **Memory Modules:** Advanced systems maintain memory of previous queries and answers to enable context retention and iterative problem-solving, further distinguishing them from the statelessness of Naive RAG [8].\n",
      "- **Multi-Modal and Domain-Specific Support:**  \n",
      "  For fields like geoscience, modular architectures enable retrieval from heterogeneous sources (e.g., images, equations, simulations) and enforce domain-specific constraints, orchestrating â€œretrieve â†’ reason â†’ generate â†’ verifyâ€ workflows for trustworthy outputs [4].\n",
      "\n",
      "#### Evaluation, Efficiency, and Real-World Deployment\n",
      "\n",
      "**Challenges in Evaluation:**  \n",
      "Despite technical progress, evaluation remains a weak link:\n",
      "- **Domain Variability:** As OmniBench-RAG demonstrates, RAG improves some domains (e.g., culture) dramatically but can even decrease performance in others (e.g., mathematics). Domain-aware and fine-grained (sub-document) metrics are essential [3].\n",
      "- **Human-in-the-Loop:** For enterprise QA, automated benchmarks are often insufficientâ€”flexible, human-in-the-lead evaluation strategies are essential to monitor and iteratively improve real-world deployments, particularly for novel or high-stakes queries [5].\n",
      "\n",
      "**Adaptation to Industrial Constraints:**  \n",
      "Modular and optimized RAG architectures are enabling practical deployments in resource-constrained environments (offline PDF chatbots in the automotive industry, for instance), requiring custom embedding, retrieval, and compression modules to balance speed, memory, and privacy constraints [4][5].\n",
      "\n",
      "**Scalability and Interoperability:**  \n",
      "Modular frameworks allow models, retrievers, evaluators, and other system components to be updated, scaled, or replaced with minimal disruption, supporting rapid iteration and cross-team collaboration, as highlighted in both open-source and enterprise case studies [2][5][6][7].\n",
      "\n",
      "#### Implications for Deep Learning and Future Directions\n",
      "\n",
      "- **Generalization and Trustworthiness:** By enabling granular control and transparent evaluation, modular RAG systems are set to become foundational in the push towards safer, more reliable LLM-powered applications.\n",
      "- **Integration with Reasoning and Verification:** The shift toward workflows that incorporate reasoning and verification (not just retrieval and generation) bridges retrieval-based AI systems and scientific/technical domains requiring rigorous, multi-source, and explainable knowledge synthesis [1][4].\n",
      "- **Continuous Evolution:** The field is rapidly moving towards frameworks that support new operators, data modalities, and evaluation paradigms, underscoring the practical and conceptual transformation from monolithic pipelines to adaptive AI ecosystems [2][4][6][8].\n",
      "\n",
      "### Sources\n",
      "\n",
      "[1] http://arxiv.org/abs/2502.11228v2  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[3] http://arxiv.org/abs/2508.05650v1  \n",
      "[4] http://arxiv.org/abs/2508.11246v1  \n",
      "[5] http://arxiv.org/abs/2410.12812v1  \n",
      "[6] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[7] https://www.ibm.com/think/topics/rag-techniques  \n",
      "[8] https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e  \n",
      "[9] https://opusintelligence.com/white-papers/the-one-about-rag\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mconduct_interview\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## Architectural Innovations from Naive RAG to Modular RAG: A Comprehensive Analysis in the Era of Deep Learning\n",
      "\n",
      "### Summary\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) has become a pivotal strategy for enhancing Large Language Models (LLMs), especially for knowledge-intensive applications such as advanced question answering, enterprise support systems, and domain-specific assistants. Initially, Naive RAG architectures offered a simple pipeline: retrieve relevant documents and feed them to an LLM for response generation. While this paradigm was quick to implement and effective for basic needs, it introduced substantial limitations regarding scalability, flexibility, and the capability to handle complex reasoning tasks, often resulting in redundancy, brittleness, and sub-optimal performance.\n",
      "\n",
      "Over the past year, dramatic conceptual and engineering advances have emerged, culminating in the evolution toward Modular RAG architectures. Modular RAG decomposes the monolithic RAG workflow into interchangeable, LEGO-like componentsâ€”retrievers, selectors, memory modules, routing, scheduling, and fusion mechanisms. This reconfigurable framework not only addresses the shortcomings of the Naive RAG but also propels the development of specialized operators for handling complex, multi-modal, and evidence-intensive use cases. In geosciences, for instance, RAG systems have been extended to support multi-step â€œretrieve â†’ reason â†’ generate â†’ verifyâ€ pipelines for tasks demanding scientific rigor and the integration of heterogeneous data sources [1][2][3][4][5][6][7][8][9].\n",
      "\n",
      "Novel systems like Vendi-RAG further exemplify the sophistication of modern RAG by iteratively balancing diversity and quality in retrieval, leveraging adaptive metrics such as the Vendi Score and LLM-based answer quality judges. Evaluation frameworks such as OmniBench-RAG emphasize the critical need for reproducibility and domain-sensitive assessment, highlighting variability in RAG system effectiveness across fields and model architectures.\n",
      "\n",
      "Major takeaways for deep learning practitioners include:\n",
      "1. The shift from static retrieval pipelines to dynamically adaptive, modular architectures enables more robust, explainable, and efficient AI solutions.\n",
      "2. The fusion of retrieval, reasoning, and verificationâ€”and the ability to swap in/out architectural modulesâ€”directly enhances the generality, scalability, and trustworthiness of LLM-powered systems.\n",
      "3. The need for new evaluation methodologies and domain-specific optimizations becomes pronounced as RAG moves into more demanding industrial and scientific applications.\n",
      "\n",
      "Sources:\n",
      "1. [Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs (arXiv:2502.11228v2)](http://arxiv.org/abs/2502.11228v2)  \n",
      "2. [Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks (arXiv:2407.21059v1)](http://arxiv.org/abs/2407.21059v1)  \n",
      "3. [OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools (arXiv:2508.05650v1)](http://arxiv.org/abs/2508.05650v1)  \n",
      "4. [RAG for Geoscience: What We Expect, Gaps and Opportunities (arXiv:2508.11246v1)](http://arxiv.org/abs/2508.11246v1)  \n",
      "5. [Optimizing and Evaluating Enterprise RAG: A Content Design Perspective (arXiv:2410.12812v1)](http://arxiv.org/abs/2410.12812v1)  \n",
      "6. [How does modular RAG improve upon naive RAG? (adasci.org)](https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/)  \n",
      "7. [IBM Think â€“ RAG Techniques](https://www.ibm.com/think/topics/rag-techniques)  \n",
      "8. [Medium â€“ What are Naive RAG, Advanced RAG, Modular RAG Paradigms?](https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e)  \n",
      "9. [Opus Intelligence â€“ The One About RAG](https://opusintelligence.com/white-papers/the-one-about-rag)  \n",
      "\n",
      "### Comprehensive Analysis\n",
      "\n",
      "#### Background: From Naive RAG to Modular RAG\n",
      "\n",
      "**Naive RAG:**  \n",
      "The first generation of RAG systems adhered to a rigid, sequential pipeline: chunk documents, index them via vector databases, retrieve the top-K based on simple similarity, and pass these as context to an LLM. This â€œretrieve-then-generateâ€ model was efficient for single-hop and factoid tasks but was increasingly found wanting as tasks grew more complex and users demanded more control, explainability, and domain sensitivity [2][6]. Primary limitations of Naive RAG included:\n",
      "- **Shallow Query Understanding:** Simple similarity cannot robustly capture nuanced domain relationships.\n",
      "- **Retrieval Redundancy:** Excess retrieval often led to noisy inputs and LLM confusion, increasing hallucination risk.\n",
      "- **Static Process:** The pipeline lacked flexibilityâ€”there were few opportunities for iterative refinement or adaptive strategy selection [2][6][8].\n",
      "\n",
      "#### Modular RAG: Architectural Flexibility and Specialization\n",
      "\n",
      "**Key Innovations:**\n",
      "- **Decomposition into Modules:**  \n",
      "  Modular RAG divides the RAG workflow into independent, specialized modules (retriever, generator, selector, router, scheduler, memory, evaluator, etc.), allowing developers to design bespoke data flows and replace components as new techniques emerge [2][6][7].\n",
      "  \n",
      "- **Routing, Scheduling, and Fusion:**  \n",
      "  Advanced modular systems introduce operators for conditional routing (different branches for entity-based queries vs. extractive QA), fusion (aggregating multiple retrieved sources), and scheduling (orchestrating the timing and parallelism of retrieval/generation cycles).\n",
      "\n",
      "- **Support for Multiple Patterns:**  \n",
      "  Modular RAG explicitly supports architectures beyond linear pipelines:  \n",
      "  - **Linear:** Standard retrieve-generate.\n",
      "  - **Conditional:** Branches based on query type or data modality.\n",
      "  - **Branching/Looping:** Iterative approaches for multi-hop reasoning or evidence accumulation [2].\n",
      "\n",
      "**Benefits:**\n",
      "- **Flexibility:** Different models or retrievers can be plugged in for different deployment requirements or data modalities.\n",
      "- **Scalability:** Systems are designed to adapt as data grows or as requirements changeâ€”modules can be scaled independently.\n",
      "- **Robustness and Explainability:** Modular design allows targeted evaluation and improvement of weak links in the pipeline, aiding troubleshooting and compliance (e.g., tracking which retrieved documents led to an answer).\n",
      "\n",
      "#### Advanced Retrieval and Reasoning\n",
      "\n",
      "**Iterative, Feedback-Driven Retrieval:**  \n",
      "State-of-the-art frameworks like Vendi-RAG exemplify the dynamic interplay of diversity and quality in retrieval:\n",
      "- **Vendi Score:** A flexible, similarity-based diversity metric ensures that retrieved contexts are semantically diverse, mitigating redundancy [1].\n",
      "- **LLM Judge:** An LLM-driven evaluator scores the quality of generated answers. The retrieval module uses this feedback to reweight its tradeoff between relevance and diversity, iteratively improving both answer accuracy and retrieval breadth.\n",
      "- **Multi-Hop Reasoning:** Vendi-RAGâ€™s dynamic adjustment of retrieval strategy is particularly potent in multi-hop QA, where answers require the synthesis of information from multiple sources, as shown in their reported accuracy gains (+4.2% on HotpotQA, for example) compared to even the strongest existing baselines [1].\n",
      "\n",
      "**Practical Modules:**\n",
      "- **Chunk Optimization:** Modular RAG systems support fine-grained chunking strategies, optimizing for information density and contextual relevance [8].\n",
      "- **Memory Modules:** Advanced systems maintain memory of previous queries and answers to enable context retention and iterative problem-solving, further distinguishing them from the statelessness of Naive RAG [8].\n",
      "- **Multi-Modal and Domain-Specific Support:**  \n",
      "  For fields like geoscience, modular architectures enable retrieval from heterogeneous sources (e.g., images, equations, simulations) and enforce domain-specific constraints, orchestrating â€œretrieve â†’ reason â†’ generate â†’ verifyâ€ workflows for trustworthy outputs [4].\n",
      "\n",
      "#### Evaluation, Efficiency, and Real-World Deployment\n",
      "\n",
      "**Challenges in Evaluation:**  \n",
      "Despite technical progress, evaluation remains a weak link:\n",
      "- **Domain Variability:** As OmniBench-RAG demonstrates, RAG improves some domains (e.g., culture) dramatically but can even decrease performance in others (e.g., mathematics). Domain-aware and fine-grained (sub-document) metrics are essential [3].\n",
      "- **Human-in-the-Loop:** For enterprise QA, automated benchmarks are often insufficientâ€”flexible, human-in-the-lead evaluation strategies are essential to monitor and iteratively improve real-world deployments, particularly for novel or high-stakes queries [5].\n",
      "\n",
      "**Adaptation to Industrial Constraints:**  \n",
      "Modular and optimized RAG architectures are enabling practical deployments in resource-constrained environments (offline PDF chatbots in the automotive industry, for instance), requiring custom embedding, retrieval, and compression modules to balance speed, memory, and privacy constraints [4][5].\n",
      "\n",
      "**Scalability and Interoperability:**  \n",
      "Modular frameworks allow models, retrievers, evaluators, and other system components to be updated, scaled, or replaced with minimal disruption, supporting rapid iteration and cross-team collaboration, as highlighted in both open-source and enterprise case studies [2][5][6][7].\n",
      "\n",
      "#### Implications for Deep Learning and Future Directions\n",
      "\n",
      "- **Generalization and Trustworthiness:** By enabling granular control and transparent evaluation, modular RAG systems are set to become foundational in the push towards safer, more reliable LLM-powered applications.\n",
      "- **Integration with Reasoning and Verification:** The shift toward workflows that incorporate reasoning and verification (not just retrieval and generation) bridges retrieval-based AI systems and scientific/technical domains requiring rigorous, multi-source, and explainable knowledge synthesis [1][4].\n",
      "- **Continuous Evolution:** The field is rapidly moving towards frameworks that support new operators, data modalities, and evaluation paradigms, underscoring the practical and conceptual transformation from monolithic pipelines to adaptive AI ecosystems [2][4][6][8].\n",
      "\n",
      "### Sources\n",
      "\n",
      "[1] http://arxiv.org/abs/2502.11228v2  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[3] http://arxiv.org/abs/2508.05650v1  \n",
      "[4] http://arxiv.org/abs/2508.11246v1  \n",
      "[5] http://arxiv.org/abs/2410.12812v1  \n",
      "[6] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[7] https://www.ibm.com/think/topics/rag-techniques  \n",
      "[8] https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e  \n",
      "[9] https://opusintelligence.com/white-papers/the-one-about-rag\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mwrite_section\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## Unlocking the Empirical Advantages of Modular RAG: Performance, Adaptivity, and Fine-Tuning Insights\n",
      "\n",
      "### Summary\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) has solidified its position as a cornerstone technique for enhancing Large Language Models (LLMs), providing crucial gains in knowledge retrieval, accuracy, and reduction of hallucination. However, as demands for real-world deployments intensify and use cases diversifyâ€”ranging from customer support to reasoning-over-knowledge-intensive tasksâ€”traditional RAG approaches reveal persistent challenges. These include limited adaptability, inflexible architectures, and significant difficulties in evaluation, especially across diverse domains and metrics such as system latency, modular adaptivity, and retrieval quality.\n",
      "\n",
      "Recent research contributions bring a new wave of innovation to the field, particularly with modular RAG paradigms and benchmarking frameworks:\n",
      "\n",
      "1. **Modular RAG** enables RAG systems to be decomposed into independent, reconfigurable modulesâ€”akin to building with LEGO blocksâ€”facilitating sophisticated architectures with routing, scheduling, and fusion operations. This shift from a naive, linear \"retrieve-then-generate\" model to a modular approach enhances adaptability, maintainability, and extensibility across varied workflows and domains, opening new possibilities for fine-tuning performance and outcome metrics [1][2].\n",
      "2. **OmniBench-RAG** addresses the critical evaluation gap by introducing a comprehensive, automated, multi-domain benchmarking platform. It quantifies RAGâ€™s true empirical gains using standardized metrics for both accuracy and efficiency, exposing substantial performance variability across model sizes and knowledge domains [1].\n",
      "\n",
      "Novel and surprising insights from these sources include:\n",
      "- RAG can yield outstanding accuracy improvements for smaller LLMs (e.g., Llama-3.2-3B-Instruct) but shows diminishing returns in state-of-the-art models with large native context windows (e.g., GPT-4o).\n",
      "- Domain dependency is pronounced, with significant gains in domains like culture, but possible accuracy declines in areas such as mathematicsâ€”demonstrating the need for granular, domain-aware assessment [1].\n",
      "- Modular RAG frameworks not only enhance adaptivity but also address previously underexplored dimensions such as computational trade-offs and fine-grained control at module and pipeline levels [2].\n",
      "\n",
      "**Sources:**\n",
      "1. http://arxiv.org/abs/2508.05650v1 (OmniBench-RAG)\n",
      "2. http://arxiv.org/abs/2407.21059v1 (Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks)\n",
      "3. https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
      "4. https://www.ibm.com/think/topics/rag-techniques\n",
      "\n",
      "### Comprehensive Analysis\n",
      "\n",
      "#### 1. Modular RAG: Architecture and Adaptivity\n",
      "\n",
      "##### 1.1 From Naive to Modular RAG: Rationale and Evolution\n",
      "\n",
      "Traditional (Naive) RAG approaches center on a simple workflow: retrieve relevant documents based on surface-level similarity and pass them directly to LLMs for generation. This direct, often monolithic flow leads to:\n",
      "- Redundant or noisy retrievals, which can interfere with the LLMâ€™s reasoning and even increase hallucination risk [2].\n",
      "- Limited adaptability to novel task requirements or integration with evolving model architectures.\n",
      "- Static, coarse integration between retrieval and generation, making competency in handling domain-specific, multi-step, or complex reasoning tasks suboptimal [2][3].\n",
      "\n",
      "In contrast, **Modular RAG** breaks the process into independently addressable modules, such as advanced retrieval (with conditional logic), generation, memory, fusion, and even dynamic routing or scheduling. This modularization allows:\n",
      "- **Seamless integration** of various retrievers and LLMs or auxiliary modules.\n",
      "- **Configurable pipelines** that support custom flows (linear, conditional, branching, looping), enabling better alignment with use cases like conditional QA, multi-hop reasoning, or personalized recommendations [2][3].\n",
      "- **Fine-tuning and upgrading** of individual modules without reengineering the entire systemâ€”essential for enterprise and research deployment.\n",
      "\n",
      "*Example:* In customer support systems, modular RAG allows inserting a memory module to reference previous interactions, improving the coherence of responses [3].\n",
      "\n",
      "##### 1.2 Performance Gains and System Metrics\n",
      "\n",
      "Modular RAG facilitates improvements in key metrics:\n",
      "- **Retrieval Quality:** By enabling advanced chunking, adaptive filtering, and fusion mechanisms, system designers can select the most relevant information, reducing noisy or redundant context inputs [2][3]. Dynamic chunk optimization is often used during the knowledge base preparation phase to boost retrieval granularity [3].\n",
      "- **System Latency and Efficiency:** Modular workflows can parallelize or optimize specific sub-tasks (such as concurrent candidate retrieval plus multi-stage re-ranking), thereby reducing end-to-end latency for time-critical applications [2].\n",
      "- **Adaptivity:** Modular RAG shines in its ability to adapt to:\n",
      "  - **Evolving external knowledge sources** (e.g., integrating real-time web data vs. static documentation);\n",
      "  - **Changing task requirements** (e.g., switching retrievers for unstructured vs. structured domains);\n",
      "  - **Scaling** (e.g., adding or removing modules to fit deployment requirements) [2][4].\n",
      "\n",
      "#### 2. Empirical Evaluation: Insights from OmniBench-RAG\n",
      "\n",
      "##### 2.1 Benchmarking the Performance Landscape\n",
      "\n",
      "The **OmniBench-RAG** platform responds to urgent calls for standardized, reproducible RAG evaluation by offering:\n",
      "- **Multi-domain coverage:** Performance is measured in nine diverse fields, including culture, geography, health, mathematics, and more [1].\n",
      "- **Dual-metric framework:**\n",
      "  - *Improvements*: Quantifies accuracy gains attributable to RAG methods.\n",
      "  - *Transformation*: Captures changes in computational efficiency between pre-RAG and post-RAG instantiations.\n",
      "  - These allow for rigorous, apples-to-apples comparisons across LLMs and RAG designs [1].\n",
      "\n",
      "- **Automatic test generation and modular pipelines:** Tests are dynamically created, probing model capabilities in both fact extraction and complex reasoning, supporting modular experimentation [1].\n",
      "\n",
      "##### 2.2 Diagnostic Findings: Where RAG Succeeds and Fails\n",
      "\n",
      "- **Model-dependent gains:** OmniBench-RAGâ€™s results reveal that smaller LLMs benefit most from RAG augmentations. For example, Llama-3.2-3B-Instruct achieved up to a 38% accuracy increase with RAG, whereas \"giant\" models like GPT-4o, which natively support vast context windows, showed reduced marginal gains [1].\n",
      "  - *Interpretation:* As LLMs grow in size and context capacity, external retrieval becomes less critical for many tasksâ€”yet still vital where up-to-date or domain-specific information is essential.\n",
      "\n",
      "- **Domain sensitivity:** The platform exposes wide swings in RAG's effectiveness by field. Some domains (e.g., culture) see large empirical advances, while others (notably, mathematics) may even suffer diminished accuracy when RAG is applied. This indicates:\n",
      "  - RAGâ€™s impact is highly context-sensitive, with certain subject areas suffering from noisy or insufficiently precise retrieval.\n",
      "  - Success in one domain does not guarantee success in others, reinforcing the need for both modular adaptation and fine-grained evaluation [1].\n",
      "  \n",
      "##### 2.3 Overcoming Evaluation Gaps\n",
      "\n",
      "Existing benchmarks commonly suffer from:\n",
      "- **Lack of sub-document precision:** Coarse, document-level metrics (e.g., MRR@k) fail to reflect whether RAG systems extract specific, correct facts that influence answer accuracy.\n",
      "- **Non-standardized comparisons:** Reliance on LLM-based grading can inject randomness, undermining reproducibility.\n",
      "- **Absence of computational profiling:** Many frameworks neglect the impact of RAG on system cost and scalabilityâ€”scheduled for real-world importance in production settings.\n",
      "\n",
      "OmniBench-RAGâ€™s standardized protocol and modular, automated evaluation pipelines directly address these gaps:\n",
      "- *Dynamic test generation* injects rich, diverse queries probing a system's reasoning and document fusion capabilities.\n",
      "- *Automated resource profiling* allows practitioners to balance accuracy gains against speed and resource consumption [1].\n",
      "\n",
      "#### 3. Practical Implications: Fine-Tuning, Adaptivity, and Beyond\n",
      "\n",
      "- **Fine-tuning opportunities:** Modular RAGâ€™s separation of concerns means model tuning (e.g., re-ranking retrievers or customizing generation modules) can happen in isolation, reducing iteration cost and risk. This is particularly valuable in domains requiring regular updates and adaptation.\n",
      "- **Adaptivity for new tasks:** Enterprises can rapidly swap out underperforming or outdated components, integrate specialized retrievers for domain expansion, or deploy tailored fusion logic for complex workflowsâ€”all without complete system overhauls [2][3][4].\n",
      "- **Frameworks and Toolkits:** Open-source modular RAG frameworks (e.g., LangChain and those emerging from leading research) offer extensible, interoperable building blocks for constructing robust, high-performance retrieval-augmented AI systems [2][4].\n",
      "\n",
      "### Sources\n",
      "\n",
      "[1] http://arxiv.org/abs/2508.05650v1  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[4] https://www.ibm.com/think/topics/rag-techniques\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mconduct_interview\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## Unlocking the Empirical Advantages of Modular RAG: Performance, Adaptivity, and Fine-Tuning Insights\n",
      "\n",
      "### Summary\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) has solidified its position as a cornerstone technique for enhancing Large Language Models (LLMs), providing crucial gains in knowledge retrieval, accuracy, and reduction of hallucination. However, as demands for real-world deployments intensify and use cases diversifyâ€”ranging from customer support to reasoning-over-knowledge-intensive tasksâ€”traditional RAG approaches reveal persistent challenges. These include limited adaptability, inflexible architectures, and significant difficulties in evaluation, especially across diverse domains and metrics such as system latency, modular adaptivity, and retrieval quality.\n",
      "\n",
      "Recent research contributions bring a new wave of innovation to the field, particularly with modular RAG paradigms and benchmarking frameworks:\n",
      "\n",
      "1. **Modular RAG** enables RAG systems to be decomposed into independent, reconfigurable modulesâ€”akin to building with LEGO blocksâ€”facilitating sophisticated architectures with routing, scheduling, and fusion operations. This shift from a naive, linear \"retrieve-then-generate\" model to a modular approach enhances adaptability, maintainability, and extensibility across varied workflows and domains, opening new possibilities for fine-tuning performance and outcome metrics [1][2].\n",
      "2. **OmniBench-RAG** addresses the critical evaluation gap by introducing a comprehensive, automated, multi-domain benchmarking platform. It quantifies RAGâ€™s true empirical gains using standardized metrics for both accuracy and efficiency, exposing substantial performance variability across model sizes and knowledge domains [1].\n",
      "\n",
      "Novel and surprising insights from these sources include:\n",
      "- RAG can yield outstanding accuracy improvements for smaller LLMs (e.g., Llama-3.2-3B-Instruct) but shows diminishing returns in state-of-the-art models with large native context windows (e.g., GPT-4o).\n",
      "- Domain dependency is pronounced, with significant gains in domains like culture, but possible accuracy declines in areas such as mathematicsâ€”demonstrating the need for granular, domain-aware assessment [1].\n",
      "- Modular RAG frameworks not only enhance adaptivity but also address previously underexplored dimensions such as computational trade-offs and fine-grained control at module and pipeline levels [2].\n",
      "\n",
      "**Sources:**\n",
      "1. http://arxiv.org/abs/2508.05650v1 (OmniBench-RAG)\n",
      "2. http://arxiv.org/abs/2407.21059v1 (Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks)\n",
      "3. https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\n",
      "4. https://www.ibm.com/think/topics/rag-techniques\n",
      "\n",
      "### Comprehensive Analysis\n",
      "\n",
      "#### 1. Modular RAG: Architecture and Adaptivity\n",
      "\n",
      "##### 1.1 From Naive to Modular RAG: Rationale and Evolution\n",
      "\n",
      "Traditional (Naive) RAG approaches center on a simple workflow: retrieve relevant documents based on surface-level similarity and pass them directly to LLMs for generation. This direct, often monolithic flow leads to:\n",
      "- Redundant or noisy retrievals, which can interfere with the LLMâ€™s reasoning and even increase hallucination risk [2].\n",
      "- Limited adaptability to novel task requirements or integration with evolving model architectures.\n",
      "- Static, coarse integration between retrieval and generation, making competency in handling domain-specific, multi-step, or complex reasoning tasks suboptimal [2][3].\n",
      "\n",
      "In contrast, **Modular RAG** breaks the process into independently addressable modules, such as advanced retrieval (with conditional logic), generation, memory, fusion, and even dynamic routing or scheduling. This modularization allows:\n",
      "- **Seamless integration** of various retrievers and LLMs or auxiliary modules.\n",
      "- **Configurable pipelines** that support custom flows (linear, conditional, branching, looping), enabling better alignment with use cases like conditional QA, multi-hop reasoning, or personalized recommendations [2][3].\n",
      "- **Fine-tuning and upgrading** of individual modules without reengineering the entire systemâ€”essential for enterprise and research deployment.\n",
      "\n",
      "*Example:* In customer support systems, modular RAG allows inserting a memory module to reference previous interactions, improving the coherence of responses [3].\n",
      "\n",
      "##### 1.2 Performance Gains and System Metrics\n",
      "\n",
      "Modular RAG facilitates improvements in key metrics:\n",
      "- **Retrieval Quality:** By enabling advanced chunking, adaptive filtering, and fusion mechanisms, system designers can select the most relevant information, reducing noisy or redundant context inputs [2][3]. Dynamic chunk optimization is often used during the knowledge base preparation phase to boost retrieval granularity [3].\n",
      "- **System Latency and Efficiency:** Modular workflows can parallelize or optimize specific sub-tasks (such as concurrent candidate retrieval plus multi-stage re-ranking), thereby reducing end-to-end latency for time-critical applications [2].\n",
      "- **Adaptivity:** Modular RAG shines in its ability to adapt to:\n",
      "  - **Evolving external knowledge sources** (e.g., integrating real-time web data vs. static documentation);\n",
      "  - **Changing task requirements** (e.g., switching retrievers for unstructured vs. structured domains);\n",
      "  - **Scaling** (e.g., adding or removing modules to fit deployment requirements) [2][4].\n",
      "\n",
      "#### 2. Empirical Evaluation: Insights from OmniBench-RAG\n",
      "\n",
      "##### 2.1 Benchmarking the Performance Landscape\n",
      "\n",
      "The **OmniBench-RAG** platform responds to urgent calls for standardized, reproducible RAG evaluation by offering:\n",
      "- **Multi-domain coverage:** Performance is measured in nine diverse fields, including culture, geography, health, mathematics, and more [1].\n",
      "- **Dual-metric framework:**\n",
      "  - *Improvements*: Quantifies accuracy gains attributable to RAG methods.\n",
      "  - *Transformation*: Captures changes in computational efficiency between pre-RAG and post-RAG instantiations.\n",
      "  - These allow for rigorous, apples-to-apples comparisons across LLMs and RAG designs [1].\n",
      "\n",
      "- **Automatic test generation and modular pipelines:** Tests are dynamically created, probing model capabilities in both fact extraction and complex reasoning, supporting modular experimentation [1].\n",
      "\n",
      "##### 2.2 Diagnostic Findings: Where RAG Succeeds and Fails\n",
      "\n",
      "- **Model-dependent gains:** OmniBench-RAGâ€™s results reveal that smaller LLMs benefit most from RAG augmentations. For example, Llama-3.2-3B-Instruct achieved up to a 38% accuracy increase with RAG, whereas \"giant\" models like GPT-4o, which natively support vast context windows, showed reduced marginal gains [1].\n",
      "  - *Interpretation:* As LLMs grow in size and context capacity, external retrieval becomes less critical for many tasksâ€”yet still vital where up-to-date or domain-specific information is essential.\n",
      "\n",
      "- **Domain sensitivity:** The platform exposes wide swings in RAG's effectiveness by field. Some domains (e.g., culture) see large empirical advances, while others (notably, mathematics) may even suffer diminished accuracy when RAG is applied. This indicates:\n",
      "  - RAGâ€™s impact is highly context-sensitive, with certain subject areas suffering from noisy or insufficiently precise retrieval.\n",
      "  - Success in one domain does not guarantee success in others, reinforcing the need for both modular adaptation and fine-grained evaluation [1].\n",
      "  \n",
      "##### 2.3 Overcoming Evaluation Gaps\n",
      "\n",
      "Existing benchmarks commonly suffer from:\n",
      "- **Lack of sub-document precision:** Coarse, document-level metrics (e.g., MRR@k) fail to reflect whether RAG systems extract specific, correct facts that influence answer accuracy.\n",
      "- **Non-standardized comparisons:** Reliance on LLM-based grading can inject randomness, undermining reproducibility.\n",
      "- **Absence of computational profiling:** Many frameworks neglect the impact of RAG on system cost and scalabilityâ€”scheduled for real-world importance in production settings.\n",
      "\n",
      "OmniBench-RAGâ€™s standardized protocol and modular, automated evaluation pipelines directly address these gaps:\n",
      "- *Dynamic test generation* injects rich, diverse queries probing a system's reasoning and document fusion capabilities.\n",
      "- *Automated resource profiling* allows practitioners to balance accuracy gains against speed and resource consumption [1].\n",
      "\n",
      "#### 3. Practical Implications: Fine-Tuning, Adaptivity, and Beyond\n",
      "\n",
      "- **Fine-tuning opportunities:** Modular RAGâ€™s separation of concerns means model tuning (e.g., re-ranking retrievers or customizing generation modules) can happen in isolation, reducing iteration cost and risk. This is particularly valuable in domains requiring regular updates and adaptation.\n",
      "- **Adaptivity for new tasks:** Enterprises can rapidly swap out underperforming or outdated components, integrate specialized retrievers for domain expansion, or deploy tailored fusion logic for complex workflowsâ€”all without complete system overhauls [2][3][4].\n",
      "- **Frameworks and Toolkits:** Open-source modular RAG frameworks (e.g., LangChain and those emerging from leading research) offer extensible, interoperable building blocks for constructing robust, high-performance retrieval-augmented AI systems [2][4].\n",
      "\n",
      "### Sources\n",
      "\n",
      "[1] http://arxiv.org/abs/2508.05650v1  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[4] https://www.ibm.com/think/topics/rag-techniques\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mwrite_introduction\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mintroduction\u001b[0m:\n",
      "# Modular RAG: Transforming Retrieval-Augmented Generation for Scalable, Robust, and Adaptive AI\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) is rapidly shaping the future of large language models (LLMs), enabling systems to synthesize accurate, context-rich responses by combining generative language capabilities with real-time knowledge retrieval. However, as organizational and domain-specific requirements intensify, the limitations of traditional, \"naive\" RAG pipelinesâ€”characterized by monolithic, static architecturesâ€”become increasingly pronounced. These conventional approaches struggle with issues like shallow retrieval, limited scalability, and difficulty in adapting to complex or evolving workflows.\n",
      "\n",
      "In response, modular RAG has emerged as a transformative paradigm, reimagining RAG systems as interoperable networks of specialized, LEGO-like components. This architectural evolution allows for selective enhancement, targeted evaluation, and seamless integration of advanced operators such as routing, scheduling, and fusion modules. The report opens with an in-depth architectural analysis, charting the progression from naive linear pipelines to flexible, modular frameworks that expertly address retrieval redundancy, reasoning complexity, and explainability.\n",
      "\n",
      "Next, we explore how modular RAG underpins production-scale deployments, bolstering scalability, maintainability, and system robustnessâ€”attributes critical for enterprise and scientific applications. The discussion then turns to empirical findings, spotlighting the role of benchmarking platforms like OmniBench-RAG in rigorously assessing modular RAGâ€™s adaptability, domain sensitivity, and real-world performance. Finally, the report synthesizes these insights to identify future directions, underscoring modular RAGâ€™s pivotal role in building trustworthy, efficient, and future-proof LLM-powered systems.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mwrite_conclusion\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mconclusion\u001b[0m:\n",
      "## Conclusion\n",
      "\n",
      "The rapid evolution from traditional Naive RAG to Modular RAG marks a transformative leap in Retrieval-Augmented Generation system design and deployment. As detailed in this report, Naive RAGâ€™s simplicityâ€”while useful for initial experimentsâ€”imposes significant limitations in adaptability, scalability, and performance, especially as real-world demands and domain complexity intensify. Modular RAG decisively addresses these challenges by decomposing the RAG pipeline into interchangeable, specialized modules. This architectural shift brings profound benefits: systems become more flexible and maintainable, fine-tuning and upgrades are localized rather than disruptive, and advanced workflowsâ€”such as dynamic routing, memory, and fusionâ€”are easily composed to suit varied operational needs and domains.\n",
      "\n",
      "Empirical insights, especially from tools like OmniBench-RAG, highlight that Modular RAG not only enhances accuracy, efficiency, and robustness, but also supports nuanced, domain-specific adaptations and transparent benchmarking across knowledge domains and model types. Practical case studies underscore superior scalability and operational resilience, with modular systems excelling in mission-critical contexts such as enterprise AI and scientific research.\n",
      "\n",
      "In sum, Modular RAG represents both a conceptual and engineering blueprint for building robust, future-ready retrieval-augmented AI. As RAG systems become foundational to LLM-powered applications, modularity will be essential for meeting the demands of production environmentsâ€”facilitating continuous improvement, domain alignment, and trustworthy intelligent automation at scale.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mwrite_report\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mcontent\u001b[0m:\n",
      "## Insights\n",
      "\n",
      "### Background\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) is a paradigm that enhances Large Language Models (LLMs) by supplementing them with retrieval capabilities from external knowledge sources, addressing common LLM limitations such as outdated knowledge or hallucinated facts. The original, or \"Naive,\" RAG architecture operates via a straightforward workflow: user queries are embedded, a similarity search identifies relevant document chunks, and these are concatenated as context for the LLM to generate a response. This pipeline offers quick deployment and can deliver marked improvements for fact-based or single-hop questions. However, it suffers from several critical drawbacksâ€”including inability to handle complex reasoning, propensity for redundancy and noise in retrieval, and a lack of iterative or adaptive refinementâ€”that hamper its suitability for enterprise-scale and domain-specific tasks [1][2][3][4][5][6][7][8][9].\n",
      "\n",
      "Recognizing these limitations, the field has advanced toward \"Modular RAG,\" where the monolithic pipeline is decomposed into granular, reconfigurable, and independently upgradable modules: retrievers, selectors, memory, routing mechanisms, fusion operators, and evaluators. Each module represents a â€œLEGO blockâ€ that can be mixed, matched, and specialized for individual use cases. This transformation dovetails with modern software engineering best practices, providing the flexibility, robustness, and control necessary for deployment in dynamic, real-world environmentsâ€”from geoscience information fusion to enterprise support tools and health informatics [2][4][6][7][8][9]. The push for modularity is also driven by the need for fine-grained evaluation and reproducibility, as varied domains and evolving use cases require systems that can be adapted or audited at a component level [1][3][5].\n",
      "\n",
      "### Related Work\n",
      "\n",
      "Initial research around RAG focused on improving LLM factuality by feeding them contextually relevant retrieved knowledge chunks, typically evaluated using metrics like MRR@k or LLM-judged accuracy. Early RAG frameworks, including those popularized in open-source toolkits such as Haystack and LangChain, showcased the promise of combining information retrieval with generation but also exposed the brittleness of static, monolithic pipelines [2][7][8]. These designs were particularly weak in supporting multi-step reasoning, complex domain adaptation, and robust error handling [4][6]. Recent research has produced more expressive RAG models capable of conditional querying, multi-retriever fusion, and fine-grained memory usage [2][4][6].\n",
      "\n",
      "Benchmarks such as OmniBench-RAG represent a new generation of evaluation methodology, systematically accounting for both empirical accuracy improvements and computational efficiency across domains [1]. Likewise, state-of-the-art architectural innovationsâ€”like Vendi-RAG and Graph RAGâ€”exemplify the transition to modular, feedback-driven RAG systems that iteratively optimize between competing goals of answer quality and retrieval diversity [1][6]. In sum, recent work shifts focus from demonstrating basic feasibility to maximizing effectiveness, robustness, and maintainability across heterogeneous real-world applications.\n",
      "\n",
      "### Problem Definition\n",
      "\n",
      "The core problem motivating Modular RAG research is the inadequacy of Naive RAG architectures for production-level, knowledge-intensive, and context-rich environments. Naive RAGâ€™s limitations are threefold: (1) inflexibility in adapting retrieval and prompt composition to evolving user needs and knowledge domains, (2) systemic inefficiency and unreliabilityâ€”amplified by rigid, one-size-fits-all workflowsâ€”and (3) lack of explainability and maintainability, which complicates troubleshooting, compliance, and auditability in high-stakes use cases [2][3][4][6]. Additionally, existing evaluation routines fall short: they often do not reflect end-to-end, domain-specific, or efficiency-related success criteria, which is essential for organizations with diverse operational requirements and rapidly changing knowledge bases [1][5].\n",
      "\n",
      "Thus, the research challenge is to design RAG systems that are (a) modular and composable, (b) easily tunable and maintainable, and (c) amenable to fine-grained, reproducible evaluationâ€”thereby enabling robust, scalable, and trustworthy deployments in complex real-world scenarios.\n",
      "\n",
      "### Methodology\n",
      "\n",
      "Modular RAG introduces a design in which traditional RAGâ€™s linear sequence is dismantled into discrete, reusable modules, each optimized for a specific task: retrieval (with adaptive strategies), chunk optimization, reranking, memory/context handling, fusion of results, and advanced routing or scheduling [2][4]. Pipelines can be constructed in linear, conditional, branching, or looping forms, empowering systems to handle complex workflows such as multi-hop reasoning, record verification, and real-time query adaptation [2][6]. Each module can interface with different data modalities and sources (structured tables, images, simulations), or with domain-specific evaluators (for scientific rigor or regulatory requirements).\n",
      "\n",
      "Innovative retrieval mechanismsâ€”like Vendi Score for retrieval diversity or LLM Judgers for answer scoringâ€”are integrated as specialized modules [1]. Such feedback-driven mechanisms iteratively optimize the composition of retrieved results, striking a balance between relevance and diversity. Memory modules store previous conversation states, enhancing context persistence, while multi-modal retrieval components allow orchestration across knowledge types (text, images, equations) [2][4][6].\n",
      "\n",
      "On the evaluation side, benchmarking frameworks such as OmniBench-RAG automate testing across domains and model types, capturing both accuracy and computational resource utilization [1][5]. This allows modular adjustment and empirical calibration of system design for optimal performance and efficiency.\n",
      "\n",
      "### Implementation Details\n",
      "\n",
      "Implementation of Modular RAG involves selecting or developing a flexible, extensible framework to host interconnected modules. Popular open-source toolkits (e.g., LangChain, Haystack) have started integrating modular components to facilitate experimentation and deployment [2][4]. Each moduleâ€”retriever, reranker, generator, memory, router, etc.â€”can be versioned and independently improved. Dynamic chunk optimization is undertaken during document ingestion to maximize retrieval granularity. Custom retriever implementations (e.g., vector search, graph-based queries) are chosen based on use case specifics; modules for filtering, fusion, and reranking often employ both traditional algorithms and transformer-based approaches.\n",
      "\n",
      "Routing and scheduling logic enables dynamic branching, controlling information flow based on query complexity or detected entity type [2][4]. Redundant modules and error-handling subroutines allow for graceful degradation and failover. Computational profiling and automated telemetry built into the pipeline support iterative tuning and cost management [1][5]. Deployment in cloud or hybrid environments leverages containerization and orchestration frameworks, with scale managed at a per-module level.\n",
      "\n",
      "### Experiments\n",
      "\n",
      "Comprehensive experiments have been undertaken using standardized and automated testing pipelines such as OmniBench-RAG [1], applying Modular RAG systems to a diverse range of knowledge domains (culture, health, mathematics, etc.) and across various LLM sizes. Each domain-task pairing is evaluated using accuracy metrics (measuring factual correctness and reasoning capacity) and efficiency scores (measuring computational and latency costs). Fine-grained sub-document evaluation gauges whether retrieved chunks actually contribute to accurate answers, addressing a common blind spot in earlier, document-level metrics [1]. In addition, resources like human-in-the-loop testing are used to supplement automated evaluation, particularly for complex or ambiguous queries [5].\n",
      "\n",
      "Experiments also benchmark the impact of modular upgrades by swapping or tuning modules such as retrievers, rerankers, or evaluators to measure delta improvements on both quality and efficiency. For high-stakes applications (e.g., aviation, health), the effectiveness of specialized retrievers (e.g., Graph RAG) is compared to baseline methods, tracking both reduction in error rates and ability to handle complex, context-rich queries [6]. Modular designs facilitate rapid A/B testing and rollback, with telemetry for tracking performance regressions.\n",
      "\n",
      "### Results\n",
      "\n",
      "Results consistently validate the superiority of Modular RAG over Naive RAG in accuracy, efficiency, scalability, and maintainability:\n",
      "\n",
      "- **Empirical Performance:** Substantial accuracy gains are recorded for small to mid-sized LLMs, with improvements up to 38% in targeted domains (e.g., Llama-3.2-3B-Instruct) [1]. However, gains for very large LLMs (e.g., GPT-4o) may be marginal, as their expansive context windows render external retrieval less critical for some tasks.\n",
      "- **Domain Sensitivity:** Modular RAGâ€™s effectiveness is highly domain-dependent. Significant advances are seen in culture, history, and QA domains; however, fields like mathematics can witness flat or even negative performance impacts, highlighting that modular, domain-specific tuning and evaluation is indispensable [1][5].\n",
      "- **Efficiency and Scalability:** Modular RAG enables optimized, parallelized flowsâ€”leading to better system latency and resource utilization. Dynamic routing allows conditional logic, prioritizing resource allocation for complex or ambiguous tasks.\n",
      "- **Maintainability and Robustness:** Production deployments report order-of-magnitude improvements in ease of upgrade, extensibility, and error isolationâ€”crucial for evolving datasets, regulatory updates, or shifting user needs [2][4][5][6]. Versioned modules and deterministic evaluation routines improve compliance and auditability.\n",
      "- **Adaptivity and Fine-Tuning:** Modularization allows isolated tuning of underperforming modules, supports rapid incorporation of new retrieval techniques, and fosters extensibility toward future modalities (e.g., multimodal reasoning, real-time data fusion) [2][4].\n",
      "- **Reproducibility:** Platforms like OmniBench-RAG make benchmarking outputs deterministic and replicable, aiding both scientific research and trustworthy enterprise operation [1][5].\n",
      "\n",
      "### Sources\n",
      "\n",
      "[1] http://arxiv.org/abs/2508.05650v1  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[4] https://www.ibm.com/think/topics/rag-techniques  \n",
      "[5] http://arxiv.org/abs/2410.12812v1  \n",
      "[6] http://arxiv.org/abs/2505.13006v1  \n",
      "[7] https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e  \n",
      "[8] https://opusintelligence.com/white-papers/the-one-about-rag  \n",
      "[9] http://arxiv.org/abs/2502.11228v2\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mfinalize_report\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mfinal_report\u001b[0m:\n",
      "# Modular RAG: Transforming Retrieval-Augmented Generation for Scalable, Robust, and Adaptive AI\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) is rapidly shaping the future of large language models (LLMs), enabling systems to synthesize accurate, context-rich responses by combining generative language capabilities with real-time knowledge retrieval. However, as organizational and domain-specific requirements intensify, the limitations of traditional, \"naive\" RAG pipelinesâ€”characterized by monolithic, static architecturesâ€”become increasingly pronounced. These conventional approaches struggle with issues like shallow retrieval, limited scalability, and difficulty in adapting to complex or evolving workflows.\n",
      "\n",
      "In response, modular RAG has emerged as a transformative paradigm, reimagining RAG systems as interoperable networks of specialized, LEGO-like components. This architectural evolution allows for selective enhancement, targeted evaluation, and seamless integration of advanced operators such as routing, scheduling, and fusion modules. The report opens with an in-depth architectural analysis, charting the progression from naive linear pipelines to flexible, modular frameworks that expertly address retrieval redundancy, reasoning complexity, and explainability.\n",
      "\n",
      "Next, we explore how modular RAG underpins production-scale deployments, bolstering scalability, maintainability, and system robustnessâ€”attributes critical for enterprise and scientific applications. The discussion then turns to empirical findings, spotlighting the role of benchmarking platforms like OmniBench-RAG in rigorously assessing modular RAGâ€™s adaptability, domain sensitivity, and real-world performance. Finally, the report synthesizes these insights to identify future directions, underscoring modular RAGâ€™s pivotal role in building trustworthy, efficient, and future-proof LLM-powered systems.\n",
      "\n",
      "---\n",
      "\n",
      "## Main Idea\n",
      "\n",
      "\n",
      "\n",
      "### Background\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) is a paradigm that enhances Large Language Models (LLMs) by supplementing them with retrieval capabilities from external knowledge sources, addressing common LLM limitations such as outdated knowledge or hallucinated facts. The original, or \"Naive,\" RAG architecture operates via a straightforward workflow: user queries are embedded, a similarity search identifies relevant document chunks, and these are concatenated as context for the LLM to generate a response. This pipeline offers quick deployment and can deliver marked improvements for fact-based or single-hop questions. However, it suffers from several critical drawbacksâ€”including inability to handle complex reasoning, propensity for redundancy and noise in retrieval, and a lack of iterative or adaptive refinementâ€”that hamper its suitability for enterprise-scale and domain-specific tasks [1][2][3][4][5][6][7][8][9].\n",
      "\n",
      "Recognizing these limitations, the field has advanced toward \"Modular RAG,\" where the monolithic pipeline is decomposed into granular, reconfigurable, and independently upgradable modules: retrievers, selectors, memory, routing mechanisms, fusion operators, and evaluators. Each module represents a â€œLEGO blockâ€ that can be mixed, matched, and specialized for individual use cases. This transformation dovetails with modern software engineering best practices, providing the flexibility, robustness, and control necessary for deployment in dynamic, real-world environmentsâ€”from geoscience information fusion to enterprise support tools and health informatics [2][4][6][7][8][9]. The push for modularity is also driven by the need for fine-grained evaluation and reproducibility, as varied domains and evolving use cases require systems that can be adapted or audited at a component level [1][3][5].\n",
      "\n",
      "### Related Work\n",
      "\n",
      "Initial research around RAG focused on improving LLM factuality by feeding them contextually relevant retrieved knowledge chunks, typically evaluated using metrics like MRR@k or LLM-judged accuracy. Early RAG frameworks, including those popularized in open-source toolkits such as Haystack and LangChain, showcased the promise of combining information retrieval with generation but also exposed the brittleness of static, monolithic pipelines [2][7][8]. These designs were particularly weak in supporting multi-step reasoning, complex domain adaptation, and robust error handling [4][6]. Recent research has produced more expressive RAG models capable of conditional querying, multi-retriever fusion, and fine-grained memory usage [2][4][6].\n",
      "\n",
      "Benchmarks such as OmniBench-RAG represent a new generation of evaluation methodology, systematically accounting for both empirical accuracy improvements and computational efficiency across domains [1]. Likewise, state-of-the-art architectural innovationsâ€”like Vendi-RAG and Graph RAGâ€”exemplify the transition to modular, feedback-driven RAG systems that iteratively optimize between competing goals of answer quality and retrieval diversity [1][6]. In sum, recent work shifts focus from demonstrating basic feasibility to maximizing effectiveness, robustness, and maintainability across heterogeneous real-world applications.\n",
      "\n",
      "### Problem Definition\n",
      "\n",
      "The core problem motivating Modular RAG research is the inadequacy of Naive RAG architectures for production-level, knowledge-intensive, and context-rich environments. Naive RAGâ€™s limitations are threefold: (1) inflexibility in adapting retrieval and prompt composition to evolving user needs and knowledge domains, (2) systemic inefficiency and unreliabilityâ€”amplified by rigid, one-size-fits-all workflowsâ€”and (3) lack of explainability and maintainability, which complicates troubleshooting, compliance, and auditability in high-stakes use cases [2][3][4][6]. Additionally, existing evaluation routines fall short: they often do not reflect end-to-end, domain-specific, or efficiency-related success criteria, which is essential for organizations with diverse operational requirements and rapidly changing knowledge bases [1][5].\n",
      "\n",
      "Thus, the research challenge is to design RAG systems that are (a) modular and composable, (b) easily tunable and maintainable, and (c) amenable to fine-grained, reproducible evaluationâ€”thereby enabling robust, scalable, and trustworthy deployments in complex real-world scenarios.\n",
      "\n",
      "### Methodology\n",
      "\n",
      "Modular RAG introduces a design in which traditional RAGâ€™s linear sequence is dismantled into discrete, reusable modules, each optimized for a specific task: retrieval (with adaptive strategies), chunk optimization, reranking, memory/context handling, fusion of results, and advanced routing or scheduling [2][4]. Pipelines can be constructed in linear, conditional, branching, or looping forms, empowering systems to handle complex workflows such as multi-hop reasoning, record verification, and real-time query adaptation [2][6]. Each module can interface with different data modalities and sources (structured tables, images, simulations), or with domain-specific evaluators (for scientific rigor or regulatory requirements).\n",
      "\n",
      "Innovative retrieval mechanismsâ€”like Vendi Score for retrieval diversity or LLM Judgers for answer scoringâ€”are integrated as specialized modules [1]. Such feedback-driven mechanisms iteratively optimize the composition of retrieved results, striking a balance between relevance and diversity. Memory modules store previous conversation states, enhancing context persistence, while multi-modal retrieval components allow orchestration across knowledge types (text, images, equations) [2][4][6].\n",
      "\n",
      "On the evaluation side, benchmarking frameworks such as OmniBench-RAG automate testing across domains and model types, capturing both accuracy and computational resource utilization [1][5]. This allows modular adjustment and empirical calibration of system design for optimal performance and efficiency.\n",
      "\n",
      "### Implementation Details\n",
      "\n",
      "Implementation of Modular RAG involves selecting or developing a flexible, extensible framework to host interconnected modules. Popular open-source toolkits (e.g., LangChain, Haystack) have started integrating modular components to facilitate experimentation and deployment [2][4]. Each moduleâ€”retriever, reranker, generator, memory, router, etc.â€”can be versioned and independently improved. Dynamic chunk optimization is undertaken during document ingestion to maximize retrieval granularity. Custom retriever implementations (e.g., vector search, graph-based queries) are chosen based on use case specifics; modules for filtering, fusion, and reranking often employ both traditional algorithms and transformer-based approaches.\n",
      "\n",
      "Routing and scheduling logic enables dynamic branching, controlling information flow based on query complexity or detected entity type [2][4]. Redundant modules and error-handling subroutines allow for graceful degradation and failover. Computational profiling and automated telemetry built into the pipeline support iterative tuning and cost management [1][5]. Deployment in cloud or hybrid environments leverages containerization and orchestration frameworks, with scale managed at a per-module level.\n",
      "\n",
      "### Experiments\n",
      "\n",
      "Comprehensive experiments have been undertaken using standardized and automated testing pipelines such as OmniBench-RAG [1], applying Modular RAG systems to a diverse range of knowledge domains (culture, health, mathematics, etc.) and across various LLM sizes. Each domain-task pairing is evaluated using accuracy metrics (measuring factual correctness and reasoning capacity) and efficiency scores (measuring computational and latency costs). Fine-grained sub-document evaluation gauges whether retrieved chunks actually contribute to accurate answers, addressing a common blind spot in earlier, document-level metrics [1]. In addition, resources like human-in-the-loop testing are used to supplement automated evaluation, particularly for complex or ambiguous queries [5].\n",
      "\n",
      "Experiments also benchmark the impact of modular upgrades by swapping or tuning modules such as retrievers, rerankers, or evaluators to measure delta improvements on both quality and efficiency. For high-stakes applications (e.g., aviation, health), the effectiveness of specialized retrievers (e.g., Graph RAG) is compared to baseline methods, tracking both reduction in error rates and ability to handle complex, context-rich queries [6]. Modular designs facilitate rapid A/B testing and rollback, with telemetry for tracking performance regressions.\n",
      "\n",
      "### Results\n",
      "\n",
      "Results consistently validate the superiority of Modular RAG over Naive RAG in accuracy, efficiency, scalability, and maintainability:\n",
      "\n",
      "- **Empirical Performance:** Substantial accuracy gains are recorded for small to mid-sized LLMs, with improvements up to 38% in targeted domains (e.g., Llama-3.2-3B-Instruct) [1]. However, gains for very large LLMs (e.g., GPT-4o) may be marginal, as their expansive context windows render external retrieval less critical for some tasks.\n",
      "- **Domain Sensitivity:** Modular RAGâ€™s effectiveness is highly domain-dependent. Significant advances are seen in culture, history, and QA domains; however, fields like mathematics can witness flat or even negative performance impacts, highlighting that modular, domain-specific tuning and evaluation is indispensable [1][5].\n",
      "- **Efficiency and Scalability:** Modular RAG enables optimized, parallelized flowsâ€”leading to better system latency and resource utilization. Dynamic routing allows conditional logic, prioritizing resource allocation for complex or ambiguous tasks.\n",
      "- **Maintainability and Robustness:** Production deployments report order-of-magnitude improvements in ease of upgrade, extensibility, and error isolationâ€”crucial for evolving datasets, regulatory updates, or shifting user needs [2][4][5][6]. Versioned modules and deterministic evaluation routines improve compliance and auditability.\n",
      "- **Adaptivity and Fine-Tuning:** Modularization allows isolated tuning of underperforming modules, supports rapid incorporation of new retrieval techniques, and fosters extensibility toward future modalities (e.g., multimodal reasoning, real-time data fusion) [2][4].\n",
      "- **Reproducibility:** Platforms like OmniBench-RAG make benchmarking outputs deterministic and replicable, aiding both scientific research and trustworthy enterprise operation [1][5].\n",
      "\n",
      "### Sources\n",
      "\n",
      "[1] http://arxiv.org/abs/2508.05650v1  \n",
      "[2] http://arxiv.org/abs/2407.21059v1  \n",
      "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[4] https://www.ibm.com/think/topics/rag-techniques  \n",
      "[5] http://arxiv.org/abs/2410.12812v1  \n",
      "[6] http://arxiv.org/abs/2505.13006v1  \n",
      "[7] https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e  \n",
      "[8] https://opusintelligence.com/white-papers/the-one-about-rag  \n",
      "[9] http://arxiv.org/abs/2502.11228v2\n",
      "\n",
      "---\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The rapid evolution from traditional Naive RAG to Modular RAG marks a transformative leap in Retrieval-Augmented Generation system design and deployment. As detailed in this report, Naive RAGâ€™s simplicityâ€”while useful for initial experimentsâ€”imposes significant limitations in adaptability, scalability, and performance, especially as real-world demands and domain complexity intensify. Modular RAG decisively addresses these challenges by decomposing the RAG pipeline into interchangeable, specialized modules. This architectural shift brings profound benefits: systems become more flexible and maintainable, fine-tuning and upgrades are localized rather than disruptive, and advanced workflowsâ€”such as dynamic routing, memory, and fusionâ€”are easily composed to suit varied operational needs and domains.\n",
      "\n",
      "Empirical insights, especially from tools like OmniBench-RAG, highlight that Modular RAG not only enhances accuracy, efficiency, and robustness, but also supports nuanced, domain-specific adaptations and transparent benchmarking across knowledge domains and model types. Practical case studies underscore superior scalability and operational resilience, with modular systems excelling in mission-critical contexts such as enterprise AI and scientific research.\n",
      "\n",
      "In sum, Modular RAG represents both a conceptual and engineering blueprint for building robust, future-ready retrieval-augmented AI. As RAG systems become foundational to LLM-powered applications, modularity will be essential for meeting the demands of production environmentsâ€”facilitating continuous improvement, domain alignment, and trustworthy intelligent automation at scale.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "invoke_graph(graph, None, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca31213",
   "metadata": {},
   "source": [
    "ìµœì¢… ì™„ì„±ëœ ë³´ê³ ì„œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b46b6ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Modular RAG: Transforming Retrieval-Augmented Generation for Scalable, Robust, and Adaptive AI\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Retrieval-Augmented Generation (RAG) is rapidly shaping the future of large language models (LLMs), enabling systems to synthesize accurate, context-rich responses by combining generative language capabilities with real-time knowledge retrieval. However, as organizational and domain-specific requirements intensify, the limitations of traditional, \"naive\" RAG pipelinesâ€”characterized by monolithic, static architecturesâ€”become increasingly pronounced. These conventional approaches struggle with issues like shallow retrieval, limited scalability, and difficulty in adapting to complex or evolving workflows.\n",
       "\n",
       "In response, modular RAG has emerged as a transformative paradigm, reimagining RAG systems as interoperable networks of specialized, LEGO-like components. This architectural evolution allows for selective enhancement, targeted evaluation, and seamless integration of advanced operators such as routing, scheduling, and fusion modules. The report opens with an in-depth architectural analysis, charting the progression from naive linear pipelines to flexible, modular frameworks that expertly address retrieval redundancy, reasoning complexity, and explainability.\n",
       "\n",
       "Next, we explore how modular RAG underpins production-scale deployments, bolstering scalability, maintainability, and system robustnessâ€”attributes critical for enterprise and scientific applications. The discussion then turns to empirical findings, spotlighting the role of benchmarking platforms like OmniBench-RAG in rigorously assessing modular RAGâ€™s adaptability, domain sensitivity, and real-world performance. Finally, the report synthesizes these insights to identify future directions, underscoring modular RAGâ€™s pivotal role in building trustworthy, efficient, and future-proof LLM-powered systems.\n",
       "\n",
       "---\n",
       "\n",
       "## Main Idea\n",
       "\n",
       "\n",
       "\n",
       "### Background\n",
       "\n",
       "Retrieval-Augmented Generation (RAG) is a paradigm that enhances Large Language Models (LLMs) by supplementing them with retrieval capabilities from external knowledge sources, addressing common LLM limitations such as outdated knowledge or hallucinated facts. The original, or \"Naive,\" RAG architecture operates via a straightforward workflow: user queries are embedded, a similarity search identifies relevant document chunks, and these are concatenated as context for the LLM to generate a response. This pipeline offers quick deployment and can deliver marked improvements for fact-based or single-hop questions. However, it suffers from several critical drawbacksâ€”including inability to handle complex reasoning, propensity for redundancy and noise in retrieval, and a lack of iterative or adaptive refinementâ€”that hamper its suitability for enterprise-scale and domain-specific tasks [1][2][3][4][5][6][7][8][9].\n",
       "\n",
       "Recognizing these limitations, the field has advanced toward \"Modular RAG,\" where the monolithic pipeline is decomposed into granular, reconfigurable, and independently upgradable modules: retrievers, selectors, memory, routing mechanisms, fusion operators, and evaluators. Each module represents a â€œLEGO blockâ€ that can be mixed, matched, and specialized for individual use cases. This transformation dovetails with modern software engineering best practices, providing the flexibility, robustness, and control necessary for deployment in dynamic, real-world environmentsâ€”from geoscience information fusion to enterprise support tools and health informatics [2][4][6][7][8][9]. The push for modularity is also driven by the need for fine-grained evaluation and reproducibility, as varied domains and evolving use cases require systems that can be adapted or audited at a component level [1][3][5].\n",
       "\n",
       "### Related Work\n",
       "\n",
       "Initial research around RAG focused on improving LLM factuality by feeding them contextually relevant retrieved knowledge chunks, typically evaluated using metrics like MRR@k or LLM-judged accuracy. Early RAG frameworks, including those popularized in open-source toolkits such as Haystack and LangChain, showcased the promise of combining information retrieval with generation but also exposed the brittleness of static, monolithic pipelines [2][7][8]. These designs were particularly weak in supporting multi-step reasoning, complex domain adaptation, and robust error handling [4][6]. Recent research has produced more expressive RAG models capable of conditional querying, multi-retriever fusion, and fine-grained memory usage [2][4][6].\n",
       "\n",
       "Benchmarks such as OmniBench-RAG represent a new generation of evaluation methodology, systematically accounting for both empirical accuracy improvements and computational efficiency across domains [1]. Likewise, state-of-the-art architectural innovationsâ€”like Vendi-RAG and Graph RAGâ€”exemplify the transition to modular, feedback-driven RAG systems that iteratively optimize between competing goals of answer quality and retrieval diversity [1][6]. In sum, recent work shifts focus from demonstrating basic feasibility to maximizing effectiveness, robustness, and maintainability across heterogeneous real-world applications.\n",
       "\n",
       "### Problem Definition\n",
       "\n",
       "The core problem motivating Modular RAG research is the inadequacy of Naive RAG architectures for production-level, knowledge-intensive, and context-rich environments. Naive RAGâ€™s limitations are threefold: (1) inflexibility in adapting retrieval and prompt composition to evolving user needs and knowledge domains, (2) systemic inefficiency and unreliabilityâ€”amplified by rigid, one-size-fits-all workflowsâ€”and (3) lack of explainability and maintainability, which complicates troubleshooting, compliance, and auditability in high-stakes use cases [2][3][4][6]. Additionally, existing evaluation routines fall short: they often do not reflect end-to-end, domain-specific, or efficiency-related success criteria, which is essential for organizations with diverse operational requirements and rapidly changing knowledge bases [1][5].\n",
       "\n",
       "Thus, the research challenge is to design RAG systems that are (a) modular and composable, (b) easily tunable and maintainable, and (c) amenable to fine-grained, reproducible evaluationâ€”thereby enabling robust, scalable, and trustworthy deployments in complex real-world scenarios.\n",
       "\n",
       "### Methodology\n",
       "\n",
       "Modular RAG introduces a design in which traditional RAGâ€™s linear sequence is dismantled into discrete, reusable modules, each optimized for a specific task: retrieval (with adaptive strategies), chunk optimization, reranking, memory/context handling, fusion of results, and advanced routing or scheduling [2][4]. Pipelines can be constructed in linear, conditional, branching, or looping forms, empowering systems to handle complex workflows such as multi-hop reasoning, record verification, and real-time query adaptation [2][6]. Each module can interface with different data modalities and sources (structured tables, images, simulations), or with domain-specific evaluators (for scientific rigor or regulatory requirements).\n",
       "\n",
       "Innovative retrieval mechanismsâ€”like Vendi Score for retrieval diversity or LLM Judgers for answer scoringâ€”are integrated as specialized modules [1]. Such feedback-driven mechanisms iteratively optimize the composition of retrieved results, striking a balance between relevance and diversity. Memory modules store previous conversation states, enhancing context persistence, while multi-modal retrieval components allow orchestration across knowledge types (text, images, equations) [2][4][6].\n",
       "\n",
       "On the evaluation side, benchmarking frameworks such as OmniBench-RAG automate testing across domains and model types, capturing both accuracy and computational resource utilization [1][5]. This allows modular adjustment and empirical calibration of system design for optimal performance and efficiency.\n",
       "\n",
       "### Implementation Details\n",
       "\n",
       "Implementation of Modular RAG involves selecting or developing a flexible, extensible framework to host interconnected modules. Popular open-source toolkits (e.g., LangChain, Haystack) have started integrating modular components to facilitate experimentation and deployment [2][4]. Each moduleâ€”retriever, reranker, generator, memory, router, etc.â€”can be versioned and independently improved. Dynamic chunk optimization is undertaken during document ingestion to maximize retrieval granularity. Custom retriever implementations (e.g., vector search, graph-based queries) are chosen based on use case specifics; modules for filtering, fusion, and reranking often employ both traditional algorithms and transformer-based approaches.\n",
       "\n",
       "Routing and scheduling logic enables dynamic branching, controlling information flow based on query complexity or detected entity type [2][4]. Redundant modules and error-handling subroutines allow for graceful degradation and failover. Computational profiling and automated telemetry built into the pipeline support iterative tuning and cost management [1][5]. Deployment in cloud or hybrid environments leverages containerization and orchestration frameworks, with scale managed at a per-module level.\n",
       "\n",
       "### Experiments\n",
       "\n",
       "Comprehensive experiments have been undertaken using standardized and automated testing pipelines such as OmniBench-RAG [1], applying Modular RAG systems to a diverse range of knowledge domains (culture, health, mathematics, etc.) and across various LLM sizes. Each domain-task pairing is evaluated using accuracy metrics (measuring factual correctness and reasoning capacity) and efficiency scores (measuring computational and latency costs). Fine-grained sub-document evaluation gauges whether retrieved chunks actually contribute to accurate answers, addressing a common blind spot in earlier, document-level metrics [1]. In addition, resources like human-in-the-loop testing are used to supplement automated evaluation, particularly for complex or ambiguous queries [5].\n",
       "\n",
       "Experiments also benchmark the impact of modular upgrades by swapping or tuning modules such as retrievers, rerankers, or evaluators to measure delta improvements on both quality and efficiency. For high-stakes applications (e.g., aviation, health), the effectiveness of specialized retrievers (e.g., Graph RAG) is compared to baseline methods, tracking both reduction in error rates and ability to handle complex, context-rich queries [6]. Modular designs facilitate rapid A/B testing and rollback, with telemetry for tracking performance regressions.\n",
       "\n",
       "### Results\n",
       "\n",
       "Results consistently validate the superiority of Modular RAG over Naive RAG in accuracy, efficiency, scalability, and maintainability:\n",
       "\n",
       "- **Empirical Performance:** Substantial accuracy gains are recorded for small to mid-sized LLMs, with improvements up to 38% in targeted domains (e.g., Llama-3.2-3B-Instruct) [1]. However, gains for very large LLMs (e.g., GPT-4o) may be marginal, as their expansive context windows render external retrieval less critical for some tasks.\n",
       "- **Domain Sensitivity:** Modular RAGâ€™s effectiveness is highly domain-dependent. Significant advances are seen in culture, history, and QA domains; however, fields like mathematics can witness flat or even negative performance impacts, highlighting that modular, domain-specific tuning and evaluation is indispensable [1][5].\n",
       "- **Efficiency and Scalability:** Modular RAG enables optimized, parallelized flowsâ€”leading to better system latency and resource utilization. Dynamic routing allows conditional logic, prioritizing resource allocation for complex or ambiguous tasks.\n",
       "- **Maintainability and Robustness:** Production deployments report order-of-magnitude improvements in ease of upgrade, extensibility, and error isolationâ€”crucial for evolving datasets, regulatory updates, or shifting user needs [2][4][5][6]. Versioned modules and deterministic evaluation routines improve compliance and auditability.\n",
       "- **Adaptivity and Fine-Tuning:** Modularization allows isolated tuning of underperforming modules, supports rapid incorporation of new retrieval techniques, and fosters extensibility toward future modalities (e.g., multimodal reasoning, real-time data fusion) [2][4].\n",
       "- **Reproducibility:** Platforms like OmniBench-RAG make benchmarking outputs deterministic and replicable, aiding both scientific research and trustworthy enterprise operation [1][5].\n",
       "\n",
       "### Sources\n",
       "\n",
       "[1] http://arxiv.org/abs/2508.05650v1  \n",
       "[2] http://arxiv.org/abs/2407.21059v1  \n",
       "[3] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
       "[4] https://www.ibm.com/think/topics/rag-techniques  \n",
       "[5] http://arxiv.org/abs/2410.12812v1  \n",
       "[6] http://arxiv.org/abs/2505.13006v1  \n",
       "[7] https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e  \n",
       "[8] https://opusintelligence.com/white-papers/the-one-about-rag  \n",
       "[9] http://arxiv.org/abs/2502.11228v2\n",
       "\n",
       "---\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The rapid evolution from traditional Naive RAG to Modular RAG marks a transformative leap in Retrieval-Augmented Generation system design and deployment. As detailed in this report, Naive RAGâ€™s simplicityâ€”while useful for initial experimentsâ€”imposes significant limitations in adaptability, scalability, and performance, especially as real-world demands and domain complexity intensify. Modular RAG decisively addresses these challenges by decomposing the RAG pipeline into interchangeable, specialized modules. This architectural shift brings profound benefits: systems become more flexible and maintainable, fine-tuning and upgrades are localized rather than disruptive, and advanced workflowsâ€”such as dynamic routing, memory, and fusionâ€”are easily composed to suit varied operational needs and domains.\n",
       "\n",
       "Empirical insights, especially from tools like OmniBench-RAG, highlight that Modular RAG not only enhances accuracy, efficiency, and robustness, but also supports nuanced, domain-specific adaptations and transparent benchmarking across knowledge domains and model types. Practical case studies underscore superior scalability and operational resilience, with modular systems excelling in mission-critical contexts such as enterprise AI and scientific research.\n",
       "\n",
       "In sum, Modular RAG represents both a conceptual and engineering blueprint for building robust, future-ready retrieval-augmented AI. As RAG systems become foundational to LLM-powered applications, modularity will be essential for meeting the demands of production environmentsâ€”facilitating continuous improvement, domain alignment, and trustworthy intelligent automation at scale."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# ê·¸ë˜í”„ì˜ ìµœì¢… ìƒíƒœ ê°€ì ¸ì˜¤ê¸°\n",
    "final_state = graph.get_state(config)\n",
    "\n",
    "# ìµœì¢… ë³´ê³ ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "report = final_state.values.get(\"final_report\")\n",
    "\n",
    "# ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ìµœì¢… ë³´ê³ ì„œ ì¶œë ¥\n",
    "display(Markdown(report))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
