## 2. Transformer의 기본 구조
Transformer는 인코더(Encoder)와 디코더(Decoder)로 구성된 구조를 가집니다. 각 인코더와 디코더는 여러 층으로 구성되며, 각 층은 Attention, Feed Forward, Residual Connection, Layer Normalization이라는 주요 컴포넌트로 이루어져 있습니다. 인코더는 입력 시퀀스를 받아 정보를 추출하고, 디코더는 이 정보를 바탕으로 출력 시퀀스를 생성합니다. Encoder에서 얻어진 context 정보를 Decoder가 효과적으로 참고하기 위해 각 층의 출력값이 이용됩니다. 전통적인 신경망과 달리, 각 시퀀스 내에서 정보의 흐름이 병렬적으로 처리되며 이는 연산 효율성을 극대화합니다.
